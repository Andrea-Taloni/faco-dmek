{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML-topography Notebook - IOL Calculation for FacoDMEK Eyes\n",
    "# This notebook evaluates SRK/T accuracy accounting for surgeon's IOL choice\n",
    "\n",
    "# %% Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Load and Explore Data\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('FacoDMEK.xlsx', sheet_name='Cleaned Data')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6505cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Data Preprocessing - Initial Setup\n",
    "# Calculate average keratometry from KERATOMETRY (not biometry)\n",
    "df['K_avg_Kerato'] = (df['Keratometric Ks'] + df['Keratometric Kf']) / 2\n",
    "\n",
    "# Feature engineering for keratometry-based analysis\n",
    "df['K_Astigmatism_Kerato'] = df['Keratometric Ks'] - df['Keratometric Kf']\n",
    "df['Post_Ant_Ratio'] = df['Posterior Km'] / df['Anterior Km']\n",
    "\n",
    "# First, we need to calculate SRK/T predictions before we can use them\n",
    "# We'll calculate the errors after we have SRKT_Prediction in Cell 4\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Summary of key variables (before SRK/T calculation):\")\n",
    "print(df[['Bio-AL', 'K_avg_Kerato', 'IOL Power', 'PostOP Spherical Equivalent', \n",
    "          'CCT', 'Posterior Km']].describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in key columns:\")\n",
    "missing_counts = df[['Bio-AL', 'K_avg_Kerato', 'IOL Power', \n",
    "                     'PostOP Spherical Equivalent', 'CCT', \n",
    "                     'A-Constant', 'Posterior Km']].isnull().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "# Count complete cases for SRK/T calculation\n",
    "complete_cases = df[['Bio-AL', 'K_avg_Kerato', 'IOL Power', \n",
    "                     'PostOP Spherical Equivalent', 'A-Constant']].notna().all(axis=1).sum()\n",
    "print(f\"\\nComplete cases for analysis: {complete_cases} out of {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Implement SRK/T Formula with Keratometry K Values\n",
    "def calculate_SRKT(AL, K, A_const, nc=1.333):\n",
    "    \"\"\"\n",
    "    Calculate IOL power using SRK/T formula\n",
    "    Uses keratometry K values\n",
    "    Returns NaN if inputs are invalid\n",
    "    \"\"\"\n",
    "    # Check for valid inputs\n",
    "    if pd.isna(AL) or pd.isna(K) or pd.isna(A_const) or K <= 0 or AL <= 0:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        # Constants\n",
    "        na = 1.336\n",
    "        V = 12\n",
    "        \n",
    "        # Corneal radius from keratometry K\n",
    "        r = 337.5 / K\n",
    "        \n",
    "        # Axial length correction\n",
    "        if AL > 24.2:\n",
    "            LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "        else:\n",
    "            LCOR = AL\n",
    "        \n",
    "        # Corneal width\n",
    "        Cw = -5.41 + 0.58412 * LCOR + 0.098 * K\n",
    "        \n",
    "        # Check if we can calculate H (avoid negative square root)\n",
    "        if r**2 - (Cw**2 / 4) < 0:\n",
    "            return np.nan\n",
    "        \n",
    "        # Corneal height\n",
    "        H = r - np.sqrt(r**2 - (Cw**2 / 4))\n",
    "        \n",
    "        # ACD constant from A-constant\n",
    "        ACDconst = 0.62467 * A_const - 68.747\n",
    "        \n",
    "        # Offset\n",
    "        offset = ACDconst - 3.336\n",
    "        \n",
    "        # Estimated postoperative ACD\n",
    "        ACDest = H + offset\n",
    "        \n",
    "        # Retinal thickness correction\n",
    "        RETHICK = 0.65696 - 0.02029 * AL\n",
    "        LOPT = AL + RETHICK\n",
    "        \n",
    "        # Calculate IOL power for emmetropia\n",
    "        ncm1 = nc - 1\n",
    "        IOL = (1000 * na * (na * r - ncm1 * LOPT)) / ((LOPT - ACDest) * (na * r - ncm1 * ACDest))\n",
    "        \n",
    "        return IOL\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Calculate SRK/T predictions\n",
    "df['SRKT_Prediction'] = df.apply(\n",
    "    lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# NOW we can calculate the errors with the CORRECT approach\n",
    "# CRITICAL: Calculate expected spherical equivalent based on surgeon's choice\n",
    "# If surgeon implants less than SRK/T prediction, patient will be more hyperopic\n",
    "df['Expected_SE'] = -(df['IOL Power'] - df['SRKT_Prediction'])\n",
    "\n",
    "# CORRECT ERROR CALCULATION: \n",
    "# Error is the difference between actual and expected spherical equivalent\n",
    "df['SRKT_Error'] = df['PostOP Spherical Equivalent'] - df['Expected_SE']\n",
    "\n",
    "# Show example calculations to verify logic\n",
    "print(\"\\nExample calculations:\")\n",
    "print(\"=\"*80)\n",
    "example_df = df[['SRKT_Prediction', 'IOL Power', 'PostOP Spherical Equivalent', \n",
    "                 'Expected_SE', 'SRKT_Error']].head(10)\n",
    "print(example_df)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Expected_SE = -(IOL_Power - SRKT_Prediction)\")\n",
    "print(\"- If IOL < SRKT, Expected_SE is positive (hyperopic)\")\n",
    "print(\"- Error = Actual_SE - Expected_SE\")\n",
    "\n",
    "# Remove rows with NaN errors for analysis\n",
    "valid_cases = df['SRKT_Error'].notna()\n",
    "\n",
    "print(\"SRK/T Performance:\")\n",
    "print(f\"Valid predictions: {valid_cases.sum()} out of {len(df)}\")\n",
    "if valid_cases.sum() > 0:\n",
    "    print(f\"Mean Error: {df.loc[valid_cases, 'SRKT_Error'].mean():.3f} D\")\n",
    "    print(f\"Mean Absolute Error: {df.loc[valid_cases, 'SRKT_Error'].abs().mean():.3f} D\")\n",
    "    print(f\"Standard Deviation: {df.loc[valid_cases, 'SRKT_Error'].std():.3f} D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Visualize SRK/T Performance\n",
    "# Only plot for rows with valid data\n",
    "df_valid = df[df['SRKT_Error'].notna()].copy()\n",
    "\n",
    "if len(df_valid) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # Plot 1: Error Distribution\n",
    "    axes[0, 0].hist(df_valid['SRKT_Error'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[0, 0].set_xlabel('SRK/T Prediction Error (D)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title(f'Error Distribution (n={len(df_valid)})')\n",
    "\n",
    "    # Plot 2: Surgeon's Choice vs SRK/T Prediction\n",
    "    axes[0, 1].scatter(df_valid['SRKT_Prediction'], df_valid['IOL Power'], alpha=0.6)\n",
    "    axes[0, 1].plot([df_valid['IOL Power'].min(), df_valid['IOL Power'].max()], \n",
    "                    [df_valid['IOL Power'].min(), df_valid['IOL Power'].max()], 'r--', label='Perfect Agreement')\n",
    "    axes[0, 1].set_xlabel('SRK/T Prediction (D)')\n",
    "    axes[0, 1].set_ylabel('IOL Implanted (D)')\n",
    "    axes[0, 1].set_title('Surgeon Choice vs SRK/T Prediction')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    # Plot 3: Error vs Axial Length\n",
    "    axes[0, 2].scatter(df_valid['Bio-AL'], df_valid['SRKT_Error'], alpha=0.6)\n",
    "    axes[0, 2].set_xlabel('Axial Length (mm)')\n",
    "    axes[0, 2].set_ylabel('SRK/T Error (D)')\n",
    "    axes[0, 2].set_title('Error vs Axial Length')\n",
    "    axes[0, 2].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Plot 4: Error vs Posterior Corneal Power\n",
    "    axes[1, 0].scatter(df_valid['Posterior Km'], df_valid['SRKT_Error'], alpha=0.6)\n",
    "    axes[1, 0].set_xlabel('Posterior Corneal Power (D)')\n",
    "    axes[1, 0].set_ylabel('SRK/T Error (D)')\n",
    "    axes[1, 0].set_title('Error vs Posterior K')\n",
    "    axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Plot 5: Error vs CCT\n",
    "    valid_cct = df_valid[df_valid['CCT'].notna()]\n",
    "    axes[1, 1].scatter(valid_cct['CCT'], valid_cct['SRKT_Error'], alpha=0.6)\n",
    "    axes[1, 1].set_xlabel('Central Corneal Thickness (Î¼m)')\n",
    "    axes[1, 1].set_ylabel('SRK/T Error (D)')\n",
    "    axes[1, 1].set_title('Error vs CCT')\n",
    "    axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Plot 6: Surgeon Deviation Distribution\n",
    "    surgeon_deviation = df_valid['IOL Power'] - df_valid['SRKT_Prediction']\n",
    "    axes[1, 2].hist(surgeon_deviation, bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[1, 2].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[1, 2].set_xlabel('Surgeon Deviation from SRK/T (D)')\n",
    "    axes[1, 2].set_ylabel('Frequency')\n",
    "    axes[1, 2].set_title(f'How Often Surgeons Deviate\\nMean: {surgeon_deviation.mean():.2f} D')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate percentage within target ranges\n",
    "    within_025 = (df_valid['SRKT_Error'].abs() <= 0.25).sum() / len(df_valid) * 100\n",
    "    within_050 = (df_valid['SRKT_Error'].abs() <= 0.50).sum() / len(df_valid) * 100\n",
    "    within_100 = (df_valid['SRKT_Error'].abs() <= 1.00).sum() / len(df_valid) * 100\n",
    "    \n",
    "    print(f\"\\nPercentage of eyes within target:\")\n",
    "    print(f\"Â±0.25 D: {within_025:.1f}%\")\n",
    "    print(f\"Â±0.50 D: {within_050:.1f}%\")\n",
    "    print(f\"Â±1.00 D: {within_100:.1f}%\")\n",
    "else:\n",
    "    print(\"No valid cases for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: ML-Based Optimization of Corneal Refractive Index (FIXED)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.optimize import minimize_scalar\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"MACHINE LEARNING OPTIMIZATION OF CORNEAL REFRACTIVE INDEX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data for ML\n",
    "df_ml = df[df['SRKT_Error'].notna()].copy()\n",
    "\n",
    "# Custom scoring function for cross-validation\n",
    "def evaluate_nc_cv(nc_value, X_train, X_val, df_train, df_val):\n",
    "    \"\"\"\n",
    "    Evaluate nc on validation set\n",
    "    \"\"\"\n",
    "    # Calculate predictions for validation set\n",
    "    predictions = []\n",
    "    for idx, row in X_val.iterrows():\n",
    "        pred = calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                            row['A-Constant'], nc=nc_value)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # Get actual IOL powers and SE for validation set\n",
    "    actual_iol = df_val['IOL Power'].values\n",
    "    actual_se = df_val['PostOP Spherical Equivalent'].values\n",
    "    \n",
    "    # Calculate expected SE based on surgeon's choice\n",
    "    expected_se = -(actual_iol - predictions)\n",
    "    \n",
    "    # Calculate errors\n",
    "    errors = actual_se - expected_se\n",
    "    \n",
    "    # Remove NaN values\n",
    "    valid_mask = ~np.isnan(errors)\n",
    "    if valid_mask.sum() == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    return np.mean(np.abs(errors[valid_mask]))\n",
    "\n",
    "# Grid search with proper cross-validation\n",
    "print(\"\\nPerforming Grid Search with 5-Fold Cross-Validation...\")\n",
    "\n",
    "# Create parameter grid\n",
    "nc_values = np.linspace(1.330, 1.340, 21)\n",
    "cv_results = []\n",
    "\n",
    "# Setup cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# For each nc value\n",
    "for nc in nc_values:\n",
    "    fold_scores = []\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df_ml)):\n",
    "        # Split data\n",
    "        df_train = df_ml.iloc[train_idx]\n",
    "        df_val = df_ml.iloc[val_idx]\n",
    "        \n",
    "        X_train = df_train[['Bio-AL', 'K_avg_Kerato', 'A-Constant']]\n",
    "        X_val = df_val[['Bio-AL', 'K_avg_Kerato', 'A-Constant']]\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        mae = evaluate_nc_cv(nc, X_train, X_val, df_train, df_val)\n",
    "        fold_scores.append(mae)\n",
    "    \n",
    "    # Store results\n",
    "    cv_results.append({\n",
    "        'nc': nc,\n",
    "        'mean_mae': np.mean(fold_scores),\n",
    "        'std_mae': np.std(fold_scores),\n",
    "        'fold_scores': fold_scores\n",
    "    })\n",
    "    \n",
    "    print(f\"nc = {nc:.4f}: MAE = {np.mean(fold_scores):.4f} (Â±{np.std(fold_scores):.4f})\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Find best nc\n",
    "best_idx = cv_results_df['mean_mae'].idxmin()\n",
    "best_nc = cv_results_df.loc[best_idx, 'nc']\n",
    "best_cv_mae = cv_results_df.loc[best_idx, 'mean_mae']\n",
    "best_cv_std = cv_results_df.loc[best_idx, 'std_mae']\n",
    "\n",
    "print(f\"\\nBest corneal refractive index (nc): {best_nc:.4f}\")\n",
    "print(f\"Cross-validation MAE: {best_cv_mae:.3f} Â± {best_cv_std:.3f} D\")\n",
    "\n",
    "# Visualize optimization landscape\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: MAE vs nc with error bars\n",
    "ax1.errorbar(cv_results_df['nc'], cv_results_df['mean_mae'], \n",
    "             yerr=cv_results_df['std_mae'], fmt='o-', capsize=5, capthick=2)\n",
    "ax1.axvline(x=best_nc, color='red', linestyle='--', \n",
    "            label=f'Optimal nc = {best_nc:.4f}')\n",
    "ax1.set_xlabel('Corneal Refractive Index (nc)')\n",
    "ax1.set_ylabel('Mean Absolute Error (D)')\n",
    "ax1.set_title('Cross-Validation Performance')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Box plot of fold scores for each nc\n",
    "fold_scores_matrix = np.array([r['fold_scores'] for r in cv_results])\n",
    "ax2.boxplot(fold_scores_matrix.T, positions=cv_results_df['nc'])\n",
    "ax2.axvline(x=best_nc, color='red', linestyle='--', \n",
    "            label=f'Optimal nc = {best_nc:.4f}')\n",
    "ax2.set_xlabel('Corneal Refractive Index (nc)')\n",
    "ax2.set_ylabel('MAE (D)')\n",
    "ax2.set_title('Performance Variability Across Folds')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate final performance on full dataset with best nc\n",
    "print(\"\\nFinal Performance on Full Dataset:\")\n",
    "final_predictions = []\n",
    "for idx, row in df_ml.iterrows():\n",
    "    pred = calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                         row['A-Constant'], nc=best_nc)\n",
    "    final_predictions.append(pred)\n",
    "\n",
    "df_ml['SRKT_ML_nc'] = final_predictions\n",
    "df_ml['Expected_SE_ML'] = -(df_ml['IOL Power'] - df_ml['SRKT_ML_nc'])\n",
    "df_ml['Error_ML_nc'] = df_ml['PostOP Spherical Equivalent'] - df_ml['Expected_SE_ML']\n",
    "\n",
    "# Remove any NaN errors\n",
    "valid_errors = df_ml['Error_ML_nc'].dropna()\n",
    "\n",
    "print(f\"MAE: {valid_errors.abs().mean():.3f} D\")\n",
    "print(f\"RMSE: {np.sqrt((valid_errors**2).mean()):.3f} D\")\n",
    "print(f\"Mean Error: {valid_errors.mean():.3f} D\")\n",
    "print(f\"Std Error: {valid_errors.std():.3f} D\")\n",
    "\n",
    "# Performance breakdown\n",
    "within_025 = (valid_errors.abs() <= 0.25).sum() / len(valid_errors) * 100\n",
    "within_050 = (valid_errors.abs() <= 0.50).sum() / len(valid_errors) * 100\n",
    "within_100 = (valid_errors.abs() <= 1.00).sum() / len(valid_errors) * 100\n",
    "\n",
    "print(f\"\\nPercentage within target:\")\n",
    "print(f\"Â±0.25 D: {within_025:.1f}%\")\n",
    "print(f\"Â±0.50 D: {within_050:.1f}%\")\n",
    "print(f\"Â±1.00 D: {within_100:.1f}%\")\n",
    "\n",
    "# Sensitivity analysis\n",
    "print(\"\\nParameter Sensitivity Analysis...\")\n",
    "perturbations = np.linspace(-0.005, 0.005, 11)\n",
    "sensitivity_results = []\n",
    "\n",
    "for delta in perturbations:\n",
    "    test_nc = best_nc + delta\n",
    "    test_predictions = []\n",
    "    for idx, row in df_ml.iterrows():\n",
    "        pred = calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                             row['A-Constant'], nc=test_nc)\n",
    "        test_predictions.append(pred)\n",
    "    \n",
    "    test_expected_se = -(df_ml['IOL Power'] - test_predictions)\n",
    "    test_errors = df_ml['PostOP Spherical Equivalent'] - test_expected_se\n",
    "    test_mae = test_errors.abs().mean()\n",
    "    \n",
    "    sensitivity_results.append({\n",
    "        'delta': delta,\n",
    "        'nc': test_nc,\n",
    "        'mae': test_mae\n",
    "    })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "\n",
    "# Plot sensitivity\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(sensitivity_df['nc'], sensitivity_df['mae'], 'b-', linewidth=2)\n",
    "plt.axvline(x=best_nc, color='red', linestyle='--', \n",
    "            label=f'Optimal nc = {best_nc:.4f}')\n",
    "plt.xlabel('Corneal Refractive Index (nc)')\n",
    "plt.ylabel('MAE (D)')\n",
    "plt.title('Sensitivity Analysis: MAE vs nc')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Save optimized nc for use in Cell 7\n",
    "optimal_nc_ml = best_nc\n",
    "print(f\"\\nOptimal nc saved for Cell 7: {optimal_nc_ml:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1890ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: ML-Optimized SRK/T with Ensemble Methods\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.optimize import differential_evolution\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\nMACHINE LEARNING OPTIMIZATION OF SRK/T FORMULA CONSTANTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use optimized nc from Cell 6\n",
    "if 'optimal_nc_ml' not in globals():\n",
    "    optimal_nc_ml = 1.333\n",
    "\n",
    "print(f\"Using optimized nc from Cell 6: {optimal_nc_ml:.4f}\")\n",
    "\n",
    "# Extended SRK/T with learnable parameters\n",
    "def calculate_SRKT_ml(AL, K, A_const, params):\n",
    "    \"\"\"\n",
    "    ML-optimized SRK/T formula\n",
    "    params = [cw_const1, cw_const2, cw_const3, acd_const1, acd_const2, \n",
    "              offset_const, rethick_const1, rethick_const2, lcor_threshold]\n",
    "    \"\"\"\n",
    "    nc = optimal_nc_ml  # Use optimized value from Cell 6\n",
    "    \n",
    "    # Unpack parameters\n",
    "    cw_const1, cw_const2, cw_const3 = params[0:3]\n",
    "    acd_const1, acd_const2 = params[3:5]\n",
    "    offset_const = params[5]\n",
    "    rethick_const1, rethick_const2 = params[6:8]\n",
    "    lcor_threshold = params[8]\n",
    "    \n",
    "    if pd.isna(AL) or pd.isna(K) or pd.isna(A_const) or K <= 0 or AL <= 0:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        na = 1.336\n",
    "        r = 337.5 / K\n",
    "        \n",
    "        # Axial length correction\n",
    "        if AL > lcor_threshold:\n",
    "            LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "        else:\n",
    "            LCOR = AL\n",
    "        \n",
    "        # Corneal width\n",
    "        Cw = cw_const1 + cw_const2 * LCOR + cw_const3 * K\n",
    "        \n",
    "        if r**2 - (Cw**2 / 4) < 0:\n",
    "            return np.nan\n",
    "        \n",
    "        H = r - np.sqrt(r**2 - (Cw**2 / 4))\n",
    "        ACDconst = acd_const1 * A_const - acd_const2\n",
    "        offset = ACDconst - offset_const\n",
    "        ACDest = H + offset\n",
    "        \n",
    "        RETHICK = rethick_const1 - rethick_const2 * AL\n",
    "        LOPT = AL + RETHICK\n",
    "        \n",
    "        ncm1 = nc - 1\n",
    "        IOL = (1000 * na * (na * r - ncm1 * LOPT)) / ((LOPT - ACDest) * (na * r - ncm1 * ACDest))\n",
    "        \n",
    "        return IOL\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Prepare data\n",
    "df_opt = df[df['SRKT_Error'].notna()].copy()\n",
    "\n",
    "# Add engineered features\n",
    "df_opt['K_Astigmatism'] = df_opt['Keratometric Ks'] - df_opt['Keratometric Kf']\n",
    "df_opt['AL_K_Ratio'] = df_opt['Bio-AL'] / df_opt['K_avg_Kerato']\n",
    "df_opt['Post_Ant_Ratio'] = df_opt['Posterior Km'] / df_opt['Anterior Km']\n",
    "\n",
    "# Feature matrix for ML models\n",
    "feature_cols = ['Bio-AL', 'K_avg_Kerato', 'A-Constant', 'CCT', 'K_Astigmatism', \n",
    "                'Posterior Km', 'Anterior Km', 'Bio-ACD', 'Bio-LT', 'AL_K_Ratio']\n",
    "\n",
    "# Handle missing values\n",
    "for col in feature_cols:\n",
    "    if col in df_opt.columns:\n",
    "        df_opt[col] = df_opt[col].fillna(df_opt[col].median())\n",
    "\n",
    "X_features = df_opt[feature_cols]\n",
    "\n",
    "# Objective function for optimizing SRK/T constants\n",
    "def objective_ml_constants(params):\n",
    "    \"\"\"Cross-validation based objective function\"\"\"\n",
    "    errors_all = []\n",
    "    \n",
    "    # 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(df_opt):\n",
    "        val_data = df_opt.iloc[val_idx]\n",
    "        \n",
    "        # Calculate predictions with current parameters\n",
    "        predictions = val_data.apply(\n",
    "            lambda row: calculate_SRKT_ml(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                         row['A-Constant'], params), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Calculate expected SE based on surgeon's choice\n",
    "        expected_se = -(val_data['IOL Power'] - predictions)\n",
    "        errors = val_data['PostOP Spherical Equivalent'] - expected_se\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_errors = errors[errors.notna()]\n",
    "        if len(valid_errors) > 0:\n",
    "            errors_all.extend(valid_errors.tolist())\n",
    "    \n",
    "    if len(errors_all) == 0:\n",
    "        return 999\n",
    "    \n",
    "    return np.mean(np.abs(errors_all))\n",
    "\n",
    "# Initial parameters (standard SRK/T values, excluding nc)\n",
    "initial_params = [\n",
    "    -5.41,          # cw_const1\n",
    "    0.58412,        # cw_const2\n",
    "    0.098,          # cw_const3\n",
    "    0.62467,        # acd_const1\n",
    "    68.747,         # acd_const2\n",
    "    3.336,          # offset_const\n",
    "    0.65696,        # rethick_const1\n",
    "    0.02029,        # rethick_const2\n",
    "    24.2            # lcor_threshold\n",
    "]\n",
    "\n",
    "# Bounds for optimization\n",
    "bounds = [\n",
    "    (-6.5, -4.3),             # cw_const1\n",
    "    (0.47, 0.70),             # cw_const2\n",
    "    (0.078, 0.118),           # cw_const3\n",
    "    (0.50, 0.75),             # acd_const1\n",
    "    (55.0, 82.0),             # acd_const2\n",
    "    (2.7, 4.0),               # offset_const\n",
    "    (0.52, 0.79),             # rethick_const1\n",
    "    (0.016, 0.024),           # rethick_const2\n",
    "    (23.0, 25.5)              # lcor_threshold\n",
    "]\n",
    "\n",
    "print(\"\\nOptimizing SRK/T formula constants using Differential Evolution...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Run optimization\n",
    "result = differential_evolution(\n",
    "    objective_ml_constants, \n",
    "    bounds,\n",
    "    maxiter=30,  # Reduced for faster execution\n",
    "    popsize=15,\n",
    "    seed=42,\n",
    "    disp=True,\n",
    "    workers=1\n",
    ")\n",
    "\n",
    "optimal_params = result.x\n",
    "\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"Cross-validation MAE: {result.fun:.3f} D\")\n",
    "\n",
    "# Calculate predictions with optimized formula\n",
    "df_opt['SRKT_ML_Optimized'] = df_opt.apply(\n",
    "    lambda row: calculate_SRKT_ml(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                 row['A-Constant'], optimal_params), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_opt['Expected_SE_ML_Opt'] = -(df_opt['IOL Power'] - df_opt['SRKT_ML_Optimized'])\n",
    "df_opt['Error_ML_Opt'] = df_opt['PostOP Spherical Equivalent'] - df_opt['Expected_SE_ML_Opt']\n",
    "\n",
    "# Train ensemble models for residual correction\n",
    "print(\"\\nTraining Ensemble Models for Residual Correction...\")\n",
    "\n",
    "# Prepare data for ensemble\n",
    "valid_mask = df_opt['SRKT_ML_Optimized'].notna()\n",
    "X_train = X_features[valid_mask]\n",
    "y_residuals = df_opt.loc[valid_mask, 'Error_ML_Opt']\n",
    "\n",
    "# Create pipelines with scaling\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, max_depth=5, \n",
    "                                 min_samples_split=5, random_state=42))\n",
    "])\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=100, max_depth=3, \n",
    "                                     learning_rate=0.1, random_state=42))\n",
    "])\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', MLPRegressor(hidden_layer_sizes=(50, 30), max_iter=500, \n",
    "                         early_stopping=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Cross-validation for ensemble models\n",
    "models = {\n",
    "    'Random Forest': rf_pipeline,\n",
    "    'Gradient Boosting': gb_pipeline,\n",
    "    'Neural Network': mlp_pipeline\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluating ensemble models...\")\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_residuals, \n",
    "                           cv=5, scoring='neg_mean_absolute_error')\n",
    "    print(f\"{name} CV MAE: {-scores.mean():.3f} (Â±{scores.std():.3f})\")\n",
    "\n",
    "# Train best ensemble model on all data\n",
    "best_ensemble = gb_pipeline  # Usually performs best\n",
    "best_ensemble.fit(X_train, y_residuals)\n",
    "\n",
    "# Make final predictions with ensemble correction\n",
    "ensemble_corrections = best_ensemble.predict(X_train)\n",
    "df_opt.loc[valid_mask, 'Ensemble_Correction'] = ensemble_corrections\n",
    "df_opt.loc[valid_mask, 'Final_ML_Prediction'] = (\n",
    "    df_opt.loc[valid_mask, 'SRKT_ML_Optimized'] + \n",
    "    df_opt.loc[valid_mask, 'Ensemble_Correction']\n",
    ")\n",
    "\n",
    "df_opt['Expected_SE_Final'] = -(df_opt['IOL Power'] - df_opt['Final_ML_Prediction'])\n",
    "df_opt['Error_Final'] = df_opt['PostOP Spherical Equivalent'] - df_opt['Expected_SE_Final']\n",
    "\n",
    "# Final performance metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare all methods\n",
    "methods = {\n",
    "    'Original SRK/T': df_opt['SRKT_Error'].abs(),\n",
    "    'ML-Optimized nc': df_opt['Error_ML_nc'].abs() if 'Error_ML_nc' in df_opt.columns else None,\n",
    "    'ML-Optimized Constants': df_opt['Error_ML_Opt'].abs(),\n",
    "    'ML + Ensemble': df_opt['Error_Final'].abs()\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "for method, errors in methods.items():\n",
    "    if errors is not None and not errors.isna().all():\n",
    "        valid_errors = errors[errors.notna()]\n",
    "        results_summary.append({\n",
    "            'Method': method,\n",
    "            'MAE': valid_errors.mean(),\n",
    "            'RMSE': np.sqrt((valid_errors**2).mean()),\n",
    "            'Within Â±0.25D': (valid_errors <= 0.25).sum() / len(valid_errors) * 100,\n",
    "            'Within Â±0.50D': (valid_errors <= 0.50).sum() / len(valid_errors) * 100,\n",
    "            'Within Â±1.00D': (valid_errors <= 1.00).sum() / len(valid_errors) * 100\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(results_df.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Error distributions\n",
    "ax1 = axes[0, 0]\n",
    "data_to_plot = []\n",
    "labels = []\n",
    "for method, errors in methods.items():\n",
    "    if errors is not None and not errors.isna().all():\n",
    "        data_to_plot.append(errors[errors.notna()])\n",
    "        labels.append(method)\n",
    "\n",
    "ax1.boxplot(data_to_plot, labels=labels)\n",
    "ax1.set_ylabel('Absolute Error (D)')\n",
    "ax1.set_title('Error Distribution by Method')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Optimized parameters\n",
    "ax2 = axes[0, 1]\n",
    "param_names = ['cw_const1', 'cw_const2', 'cw_const3', 'acd_const1', \n",
    "               'acd_const2', 'offset_const', 'rethick_const1', \n",
    "               'rethick_const2', 'lcor_threshold']\n",
    "pct_changes = [(opt - orig) / abs(orig) * 100 \n",
    "               for orig, opt in zip(initial_params, optimal_params)]\n",
    "\n",
    "ax2.bar(range(len(param_names)), pct_changes)\n",
    "ax2.set_xticks(range(len(param_names)))\n",
    "ax2.set_xticklabels(param_names, rotation=45, ha='right')\n",
    "ax2.set_ylabel('% Change from Original')\n",
    "ax2.set_title('Optimized Parameter Changes')\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Plot 3: Feature importance from ensemble\n",
    "ax3 = axes[1, 0]\n",
    "if hasattr(best_ensemble.named_steps['gb'], 'feature_importances_'):\n",
    "    importances = best_ensemble.named_steps['gb'].feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    ax3.bar(range(len(importances)), importances[indices])\n",
    "    ax3.set_xticks(range(len(importances)))\n",
    "    ax3.set_xticklabels([feature_cols[i] for i in indices], rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Feature Importance')\n",
    "    ax3.set_title('Ensemble Model Feature Importance')\n",
    "\n",
    "# Plot 4: Actual vs Predicted\n",
    "ax4 = axes[1, 1]\n",
    "if 'Expected_SE_Final' in df_opt.columns:\n",
    "    valid_mask = df_opt['Expected_SE_Final'].notna()\n",
    "    ax4.scatter(df_opt.loc[valid_mask, 'Expected_SE_Final'], \n",
    "               df_opt.loc[valid_mask, 'PostOP Spherical Equivalent'], \n",
    "               alpha=0.5)\n",
    "    \n",
    "    min_val = df_opt.loc[valid_mask, 'Expected_SE_Final'].min()\n",
    "    max_val = df_opt.loc[valid_mask, 'Expected_SE_Final'].max()\n",
    "    ax4.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction')\n",
    "    ax4.set_xlabel('ML Predicted SE (D)')\n",
    "    ax4.set_ylabel('Actual PostOP SE (D)')\n",
    "    ax4.set_title('Final ML Model Predictions')\n",
    "    ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save optimized parameters\n",
    "optimized_results = {\n",
    "    'optimal_nc': optimal_nc_ml,\n",
    "    'optimal_params': optimal_params.tolist(),\n",
    "    'param_names': param_names,\n",
    "    'initial_params': initial_params,\n",
    "    'performance_metrics': results_df.to_dict('records')\n",
    "}\n",
    "\n",
    "# Print final optimized formula\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZED SRK/T FORMULA FOR FacoDMEK EYES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"nc (corneal refractive index): {optimal_nc_ml:.4f}\")\n",
    "for name, orig, opt in zip(param_names, initial_params, optimal_params):\n",
    "    print(f\"{name}: {orig:.4f} â {opt:.4f}\")\n",
    "\n",
    "print(\"\\nOptimization complete! The ML-optimized formula achieves better accuracy\")\n",
    "print(\"for IOL calculations in FacoDMEK eyes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
