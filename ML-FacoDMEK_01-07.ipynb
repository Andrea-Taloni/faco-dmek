{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Enhanced Imports and Configuration\n",
    "\"\"\"\n",
    "Machine Learning Optimization for SRK/T Formula in FacoDMEK Eyes\n",
    "Required packages: pip install pandas numpy matplotlib seaborn scikit-learn scipy openpyxl scikit-optimize\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation and numerical computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, cross_val_score, \n",
    "    GridSearchCV, StratifiedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Optimization\n",
    "from scipy.optimize import minimize, differential_evolution, dual_annealing\n",
    "from scipy import stats\n",
    "\n",
    "# Bayesian optimization\n",
    "try:\n",
    "    from skopt import BayesSearchCV\n",
    "    from skopt.space import Real, Integer\n",
    "    SKOPT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: scikit-optimize not installed. Install with: pip install scikit-optimize\")\n",
    "    SKOPT_AVAILABLE = False\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Global configuration\n",
    "class Config:\n",
    "    RANDOM_SEEDS = [42, 123, 456, 789, 2024]  # Multiple seeds for analysis\n",
    "    CURRENT_SEED = 42  # Default seed for single runs\n",
    "    TEST_SIZE = 0.30  # 30% test set\n",
    "    CV_FOLDS = 3      # Cross-validation folds\n",
    "    N_BOOTSTRAP = 1000  # Bootstrap iterations\n",
    "    \n",
    "    # File paths\n",
    "    DATA_FILE = 'FacoDMEK.xlsx'\n",
    "    OUTPUT_DIR = Path('output')\n",
    "    \n",
    "    # Plotting\n",
    "    FIGURE_DPI = 100\n",
    "    FIGURE_SIZE = (10, 6)\n",
    "\n",
    "# Create output directory\n",
    "Config.OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Store results for multi-seed analysis\n",
    "all_seed_results = []\n",
    "current_seed_results = {}\n",
    "\n",
    "print(\"Enhanced ML Pipeline for FacoDMEK IOL Calculations\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Random Seeds for multi-run analysis: {Config.RANDOM_SEEDS}\")\n",
    "print(f\"Current seed: {Config.CURRENT_SEED}\")\n",
    "print(f\"Test Set Size: {Config.TEST_SIZE * 100:.0f}%\")\n",
    "print(f\"Cross-validation Folds: {Config.CV_FOLDS}\")\n",
    "print(f\"Output Directory: {Config.OUTPUT_DIR}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Data Loading and Advanced Feature Engineering\n",
    "\"\"\"Load data and create clinically meaningful features\"\"\"\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Handle data loading and feature engineering\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_data(filepath):\n",
    "        \"\"\"Load and validate data\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(filepath, sheet_name='Cleaned Data')\n",
    "            print(f\"✓ Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading data: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_features(df):\n",
    "        \"\"\"Create derived features based on clinical knowledge\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Basic derived features\n",
    "        df['K_avg_Kerato'] = (df['Keratometric Ks'] + df['Keratometric Kf']) / 2\n",
    "        df['K_Astigmatism_Kerato'] = df['Keratometric Ks'] - df['Keratometric Kf']\n",
    "        df['K_Cylinder'] = np.abs(df['K_Astigmatism_Kerato'])\n",
    "        \n",
    "        # Ratios and relationships\n",
    "        df['Post_Ant_Ratio'] = df['Posterior Km'] / df['Anterior Km']\n",
    "        df['AL_K_Ratio'] = df['Bio-AL'] / df['K_avg_Kerato']\n",
    "        \n",
    "        # Advanced features\n",
    "        df['K_Spherical_Equivalent'] = df['K_avg_Kerato'] + 0.5 * df['K_Cylinder']\n",
    "        \n",
    "        # Categorize axial length\n",
    "        df['AL_Category'] = pd.cut(\n",
    "            df['Bio-AL'], \n",
    "            bins=[0, 22, 24.5, 26, 100], \n",
    "            labels=['short', 'normal', 'long', 'very_long']\n",
    "        )\n",
    "        \n",
    "        # Additional clinical features if available\n",
    "        if 'Bio-ACD' in df.columns and 'Bio-LT' in df.columns:\n",
    "            df['Anterior_Segment_Depth'] = df['Bio-ACD'] + 0.5 * df['Bio-LT']\n",
    "            if 'Bio-AL' in df.columns:\n",
    "                df['LP_Factor'] = df['Bio-ACD'] / (df['Bio-AL'] - df['Bio-LT'])\n",
    "        \n",
    "        # CCT categories if available\n",
    "        if 'CCT' in df.columns:\n",
    "            df['CCT_Category'] = pd.cut(\n",
    "                df['CCT'],\n",
    "                bins=[0, 500, 550, 600, 1000],\n",
    "                labels=['thin', 'normal', 'thick', 'very_thick']\n",
    "            )\n",
    "            df['CCT_K_Interaction'] = df['CCT'] * df['K_avg_Kerato'] / 1000\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_feature_summary(df):\n",
    "        \"\"\"Print feature summary statistics\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        print(\"\\nFeature Summary:\")\n",
    "        print(\"-\" * 60)\n",
    "        for col in ['Bio-AL', 'K_avg_Kerato', 'CCT', 'IOL Power']:\n",
    "            if col in df.columns:\n",
    "                print(f\"{col:20s}: μ={df[col].mean():.2f}, σ={df[col].std():.2f}, \"\n",
    "                      f\"range=[{df[col].min():.1f}, {df[col].max():.1f}]\")\n",
    "\n",
    "# Load and process data\n",
    "processor = DataProcessor()\n",
    "df = processor.load_data(Config.DATA_FILE)\n",
    "df = processor.create_features(df)\n",
    "processor.get_feature_summary(df)\n",
    "\n",
    "print(f\"\\n✓ Feature engineering completed: {len(df.columns)} total features\")\n",
    "\n",
    "# Store original dataframe for multi-seed analysis\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db51fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Advanced Train/Test Split with Validation\n",
    "\"\"\"Create train/test split with proper stratification and validation\"\"\"\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"Handle data splitting with validation\"\"\"\n",
    "    \n",
    "    def __init__(self, test_size=0.3, random_state=42):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.required_cols = [\n",
    "            'Bio-AL', 'K_avg_Kerato', 'IOL Power', \n",
    "            'PostOP Spherical Equivalent', 'A-Constant'\n",
    "        ]\n",
    "    \n",
    "    def split_data(self, df):\n",
    "        \"\"\"Create train/test split with stratification\"\"\"\n",
    "        # Filter complete cases\n",
    "        df_complete = df[df[self.required_cols].notna().all(axis=1)].copy()\n",
    "        \n",
    "        print(f\"Complete cases: {len(df_complete)} / {len(df)} ({len(df_complete)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # Stratified split by AL category\n",
    "        df_train, df_test = train_test_split(\n",
    "            df_complete,\n",
    "            test_size=self.test_size,\n",
    "            random_state=self.random_state,\n",
    "            stratify=df_complete['AL_Category']\n",
    "        )\n",
    "        \n",
    "        return df_train, df_test\n",
    "    \n",
    "    def validate_split(self, df_train, df_test):\n",
    "        \"\"\"Validate the data split\"\"\"\n",
    "        print(\"\\nData Split Validation:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Training set: {len(df_train)} eyes ({len(df_train)/(len(df_train)+len(df_test))*100:.1f}%)\")\n",
    "        print(f\"Test set: {len(df_test)} eyes ({len(df_test)/(len(df_train)+len(df_test))*100:.1f}%)\")\n",
    "        \n",
    "        # Check distributions\n",
    "        print(\"\\nAL Distribution:\")\n",
    "        for name, data in [(\"Train\", df_train), (\"Test\", df_test)]:\n",
    "            dist = data['AL_Category'].value_counts(normalize=True).sort_index()\n",
    "            print(f\"{name}: \" + \" | \".join([f\"{cat}: {pct*100:.1f}%\" for cat, pct in dist.items()]))\n",
    "        \n",
    "        # Statistical tests for distribution similarity\n",
    "        for col in ['Bio-AL', 'K_avg_Kerato']:\n",
    "            stat, pval = stats.ks_2samp(df_train[col], df_test[col])\n",
    "            print(f\"\\nKS test for {col}: p={pval:.3f} {'✓' if pval > 0.05 else '✗'}\")\n",
    "\n",
    "# Split data with current seed\n",
    "np.random.seed(Config.CURRENT_SEED)\n",
    "splitter = DataSplitter(test_size=Config.TEST_SIZE, random_state=Config.CURRENT_SEED)\n",
    "df_train_val, df_test = splitter.split_data(df)\n",
    "splitter.validate_split(df_train_val, df_test)\n",
    "\n",
    "# Store for current analysis\n",
    "current_seed_results['train_size'] = len(df_train_val)\n",
    "current_seed_results['test_size'] = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4da927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Optimizable SRK/T Formula Implementation\n",
    "\"\"\"SRK/T formula with optimizable constants for FacoDMEK eyes\"\"\"\n",
    "\n",
    "import scipy.optimize as opt\n",
    "\n",
    "class OptimizableSRKT:\n",
    "    \"\"\"SRK/T formula with learnable constants\"\"\"\n",
    "    \n",
    "    # Fixed constants\n",
    "    NA = 1.336  # Aqueous/vitreous refractive index\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Standard SRK/T constants as starting points\n",
    "        self.default_constants = {\n",
    "            'keratometer_index': 337.5,      # For corneal radius calculation\n",
    "            'al_threshold': 24.2,            # AL correction threshold\n",
    "            'lcor_a': -3.446,               # AL correction coefficients\n",
    "            'lcor_b': 1.716,\n",
    "            'lcor_c': -0.0237,\n",
    "            'cw_a': -5.41,                  # Corneal width coefficients\n",
    "            'cw_b': 0.58412,\n",
    "            'cw_c': 0.098,\n",
    "            'acd_a': 0.62467,               # ACD constant coefficients\n",
    "            'acd_b': -68.747,\n",
    "            'offset': -3.336,               # ACD offset\n",
    "            'ret_a': 0.65696,               # Retinal thickness coefficients\n",
    "            'ret_b': -0.02029,\n",
    "            'nc': 1.333,                    # Corneal refractive index\n",
    "            'multiplier': 1000              # Final calculation multiplier\n",
    "        }\n",
    "        \n",
    "        # Initialize with default values\n",
    "        self.constants = self.default_constants.copy()\n",
    "        \n",
    "    def calculate(self, AL, K, A_const, constants_dict=None):\n",
    "        \"\"\"Calculate IOL power with given or current constants\"\"\"\n",
    "        \n",
    "        # Use provided constants or current ones\n",
    "        c = constants_dict if constants_dict else self.constants\n",
    "        \n",
    "        # Input validation\n",
    "        if any(pd.isna([AL, K, A_const])) or K <= 0 or AL <= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        try:\n",
    "            # 1. Corneal radius\n",
    "            r = c['keratometer_index'] / K\n",
    "            \n",
    "            # 2. Axial length correction\n",
    "            if AL > c['al_threshold']:\n",
    "                LCOR = c['lcor_a'] + c['lcor_b'] * AL + c['lcor_c'] * AL**2\n",
    "            else:\n",
    "                LCOR = AL\n",
    "            \n",
    "            # 3. Corneal width\n",
    "            Cw = c['cw_a'] + c['cw_b'] * LCOR + c['cw_c'] * K\n",
    "            \n",
    "            # 4. Corneal height\n",
    "            discriminant = r**2 - (Cw**2 / 4)\n",
    "            if discriminant < 0:\n",
    "                return np.nan\n",
    "            H = r - np.sqrt(discriminant)\n",
    "            \n",
    "            # 5. ACD estimation\n",
    "            ACDconst = c['acd_a'] * A_const + c['acd_b']\n",
    "            ACDest = H + ACDconst + c['offset']\n",
    "            \n",
    "            # 6. Retinal thickness\n",
    "            RETHICK = c['ret_a'] + c['ret_b'] * AL\n",
    "            LOPT = AL + RETHICK\n",
    "            \n",
    "            # 7. IOL power calculation\n",
    "            ncm1 = c['nc'] - 1\n",
    "            numerator = c['multiplier'] * self.NA * (self.NA * r - ncm1 * LOPT)\n",
    "            denominator = (LOPT - ACDest) * (self.NA * r - ncm1 * ACDest)\n",
    "            \n",
    "            if denominator == 0:\n",
    "                return np.nan\n",
    "                \n",
    "            IOL = numerator / denominator\n",
    "            \n",
    "            # Sanity check\n",
    "            if not (-10 < IOL < 40):\n",
    "                return np.nan\n",
    "                \n",
    "            return IOL\n",
    "            \n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    def calculate_error(self, row, constants_dict=None):\n",
    "        \"\"\"Calculate prediction error for a single case\"\"\"\n",
    "        iol_pred = self.calculate(\n",
    "            row['Bio-AL'], \n",
    "            row['K_avg_Kerato'], \n",
    "            row['A-Constant'],\n",
    "            constants_dict\n",
    "        )\n",
    "        \n",
    "        if pd.isna(iol_pred):\n",
    "            return np.nan\n",
    "        \n",
    "        expected_se = -(row['IOL Power'] - iol_pred)\n",
    "        error = row['PostOP Spherical Equivalent'] - expected_se\n",
    "        \n",
    "        return error\n",
    "    \n",
    "    def objective_function(self, constants_array, param_names, df_train):\n",
    "        \"\"\"Objective function for optimization (minimize MAE)\"\"\"\n",
    "        \n",
    "        # Convert array to dictionary\n",
    "        constants_dict = self.constants.copy()\n",
    "        for i, param in enumerate(param_names):\n",
    "            constants_dict[param] = constants_array[i]\n",
    "        \n",
    "        # Calculate errors for all training cases\n",
    "        errors = df_train.apply(\n",
    "            lambda row: self.calculate_error(row, constants_dict),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Return MAE (excluding NaN values)\n",
    "        valid_errors = errors.dropna()\n",
    "        if len(valid_errors) == 0:\n",
    "            return 1e6  # Penalty for invalid constants\n",
    "        \n",
    "        return valid_errors.abs().mean()\n",
    "    \n",
    "    def optimize_constants(self, df_train, constants_to_optimize=None, method='differential_evolution'):\n",
    "        \"\"\"\n",
    "        Optimize selected constants using scipy optimization\n",
    "        PRESERVES SIGN: Negative constants stay negative, positive stay positive\n",
    "        \"\"\"\n",
    "        \n",
    "        if constants_to_optimize is None:\n",
    "            # Default: optimize the most impactful constants\n",
    "            constants_to_optimize = [\n",
    "                'nc',          # Corneal refractive index\n",
    "                'cw_a',        # Corneal width intercept\n",
    "                'cw_b',        # Corneal width AL coefficient\n",
    "                'cw_c',        # Corneal width K coefficient\n",
    "                'offset',      # ACD offset\n",
    "                'ret_a',       # Retinal thickness intercept\n",
    "                'ret_b'        # Retinal thickness AL coefficient\n",
    "            ]\n",
    "        \n",
    "        print(f\"\\nOptimizing {len(constants_to_optimize)} constants:\")\n",
    "        for const in constants_to_optimize:\n",
    "            print(f\"  - {const}: {self.constants[const]:.5f} (initial)\")\n",
    "        \n",
    "        # Set up bounds for each parameter\n",
    "        bounds = []\n",
    "        initial_values = []\n",
    "        \n",
    "        for param in constants_to_optimize:\n",
    "            val = self.constants[param]\n",
    "            \n",
    "            # Set reasonable bounds that PRESERVE THE SIGN\n",
    "            if param == 'nc':\n",
    "                # nc is always positive (refractive index)\n",
    "                bounds.append((1.325, 1.340))\n",
    "                \n",
    "            elif param == 'al_threshold':\n",
    "                # AL threshold is positive\n",
    "                bounds.append((23.0, 25.5))\n",
    "                \n",
    "            elif param == 'keratometer_index':\n",
    "                # Always positive\n",
    "                bounds.append((335.0, 340.0))\n",
    "                \n",
    "            elif param == 'multiplier':\n",
    "                # Always positive, near 1000\n",
    "                bounds.append((950, 1050))\n",
    "                \n",
    "            else:\n",
    "                # For all other constants, preserve their original sign\n",
    "                if val < 0:\n",
    "                    # For NEGATIVE constants\n",
    "                    # Allow 30% variation but keep negative\n",
    "                    # val * 1.3 is MORE negative (smaller number)\n",
    "                    # val * 0.7 is LESS negative (larger number, closer to 0)\n",
    "                    lower_bound = val * 1.3  # More negative\n",
    "                    upper_bound = val * 0.7  # Less negative\n",
    "                    # Ensure lower < upper\n",
    "                    bounds.append((min(lower_bound, upper_bound), max(lower_bound, upper_bound)))\n",
    "                else:\n",
    "                    # For POSITIVE constants\n",
    "                    # Allow 30% variation but keep positive\n",
    "                    lower_bound = val * 0.7  # Smaller but positive\n",
    "                    upper_bound = val * 1.3  # Larger\n",
    "                    bounds.append((lower_bound, upper_bound))\n",
    "            \n",
    "            initial_values.append(val)\n",
    "        \n",
    "        # Print bounds for verification\n",
    "        print(\"\\nParameter bounds (preserving original signs):\")\n",
    "        for i, (param, bound) in enumerate(zip(constants_to_optimize, bounds)):\n",
    "            original = self.constants[param]\n",
    "            print(f\"  {param}: {original:.5f} → [{bound[0]:.5f}, {bound[1]:.5f}]\")\n",
    "            \n",
    "            # Verify bounds are correct\n",
    "            assert bound[0] < bound[1], f\"Lower bound must be less than upper bound for {param}\"\n",
    "            \n",
    "            # Verify sign preservation\n",
    "            if original < 0:\n",
    "                assert bound[1] <= 0, f\"{param} should stay negative!\"\n",
    "            elif original > 0:\n",
    "                assert bound[0] >= 0, f\"{param} should stay positive!\"\n",
    "        \n",
    "        # Optimization\n",
    "        if method == 'differential_evolution':\n",
    "            print(\"\\nUsing Differential Evolution (global optimization)...\")\n",
    "            result = opt.differential_evolution(\n",
    "                self.objective_function,\n",
    "                bounds,\n",
    "                args=(constants_to_optimize, df_train),\n",
    "                maxiter=100,\n",
    "                popsize=15,\n",
    "                tol=0.0001,\n",
    "                seed=42,\n",
    "                disp=True\n",
    "            )\n",
    "        \n",
    "        elif method == 'basinhopping':\n",
    "            print(\"\\nUsing Basin-hopping (global optimization)...\")\n",
    "            result = opt.basinhopping(\n",
    "                self.objective_function,\n",
    "                initial_values,\n",
    "                minimizer_kwargs={\n",
    "                    'method': 'L-BFGS-B',\n",
    "                    'args': (constants_to_optimize, df_train),\n",
    "                    'bounds': bounds\n",
    "                },\n",
    "                niter=100,\n",
    "                seed=42\n",
    "            )\n",
    "        \n",
    "        else:  # method == 'minimize'\n",
    "            print(\"\\nUsing L-BFGS-B (local optimization)...\")\n",
    "            result = opt.minimize(\n",
    "                self.objective_function,\n",
    "                initial_values,\n",
    "                args=(constants_to_optimize, df_train),\n",
    "                method='L-BFGS-B',\n",
    "                bounds=bounds,\n",
    "                options={'maxiter': 1000}\n",
    "            )\n",
    "        \n",
    "        # Update constants with optimized values\n",
    "        print(f\"\\nOptimization complete! Success: {result.success}\")\n",
    "        print(f\"Final MAE: {result.fun:.4f} D\")\n",
    "        print(\"\\nOptimized constants:\")\n",
    "        \n",
    "        for i, param in enumerate(constants_to_optimize):\n",
    "            old_val = self.constants[param]\n",
    "            new_val = result.x[i]\n",
    "            self.constants[param] = new_val\n",
    "            change = (new_val - old_val) / abs(old_val) * 100 if old_val != 0 else 0\n",
    "            print(f\"  {param}: {old_val:.5f} → {new_val:.5f} ({change:+.1f}%)\")\n",
    "            \n",
    "            # Verify sign was preserved\n",
    "            if old_val < 0:\n",
    "                assert new_val < 0, f\"{param} changed sign!\"\n",
    "            elif old_val > 0:\n",
    "                assert new_val > 0, f\"{param} changed sign!\"\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize and test\n",
    "print(\"Creating Optimizable SRK/T Formula...\")\n",
    "opt_srkt = OptimizableSRKT()\n",
    "\n",
    "# Calculate baseline with standard constants\n",
    "df_train_val['SRKT_Baseline'] = df_train_val.apply(\n",
    "    lambda row: opt_srkt.calculate(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_train_val['SRKT_Error_Baseline'] = df_train_val.apply(\n",
    "    lambda row: opt_srkt.calculate_error(row),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "baseline_mae = df_train_val['SRKT_Error_Baseline'].abs().mean()\n",
    "print(f\"\\nBaseline MAE (standard SRK/T): {baseline_mae:.3f} D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Optimize SRK/T Constants for FacoDMEK\n",
    "\"\"\"Find optimal SRK/T constants using machine learning optimization\"\"\"\n",
    "\n",
    "# Prepare training data\n",
    "df_opt_train = df_train_val[df_train_val['SRKT_Error_Baseline'].notna()].copy()\n",
    "print(f\"Training on {len(df_opt_train)} complete cases\")\n",
    "\n",
    "# Choose which constants to optimize\n",
    "OPTIMIZATION_LEVELS = {\n",
    "    'conservative': ['nc', 'offset'],  # Just 2 parameters\n",
    "    'moderate': ['nc', 'cw_a', 'cw_b', 'cw_c', 'offset'],  # 5 parameters\n",
    "    'aggressive': ['nc', 'cw_a', 'cw_b', 'cw_c', 'offset', 'ret_a', 'ret_b', 'acd_a', 'acd_b'],  # 9 parameters\n",
    "    'comprehensive': ['nc', 'lcor_a', 'lcor_b', 'lcor_c', 'cw_a', 'cw_b', 'cw_c', \n",
    "                     'offset', 'ret_a', 'ret_b', 'acd_a', 'acd_b']  # 12 parameters\n",
    "}\n",
    "\n",
    "# Select optimization level\n",
    "optimization_level = 'moderate'  # You can change this\n",
    "constants_to_optimize = OPTIMIZATION_LEVELS[optimization_level]\n",
    "\n",
    "print(f\"\\nOptimization level: {optimization_level}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Optimize constants using differential evolution (global optimization)\n",
    "result = opt_srkt.optimize_constants(\n",
    "    df_opt_train,\n",
    "    constants_to_optimize=constants_to_optimize,\n",
    "    method='differential_evolution'  # Best for finding global optimum\n",
    ")\n",
    "\n",
    "# Calculate performance with optimized constants\n",
    "df_opt_train['SRKT_Optimized'] = df_opt_train.apply(\n",
    "    lambda row: opt_srkt.calculate(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_opt_train['SRKT_Error_Optimized'] = df_opt_train.apply(\n",
    "    lambda row: opt_srkt.calculate_error(row),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Performance summary\n",
    "optimized_mae = df_opt_train['SRKT_Error_Optimized'].abs().mean()\n",
    "optimized_std = df_opt_train['SRKT_Error_Optimized'].abs().std()\n",
    "improvement = (baseline_mae - optimized_mae) / baseline_mae * 100\n",
    "\n",
    "print(f\"\\nTraining Set Performance Summary:\")\n",
    "print(f\"  Standard SRK/T MAE: {baseline_mae:.3f} D\")\n",
    "print(f\"  Optimized Formula MAE: {optimized_mae:.3f} D\")\n",
    "print(f\"  Improvement: {improvement:.1f}%\")\n",
    "print(f\"  SD of absolute error: {optimized_std:.3f} D\")\n",
    "\n",
    "# Within target analysis\n",
    "abs_errors = df_opt_train['SRKT_Error_Optimized'].abs()\n",
    "within_025 = (abs_errors <= 0.25).mean() * 100\n",
    "within_050 = (abs_errors <= 0.50).mean() * 100\n",
    "within_100 = (abs_errors <= 1.00).mean() * 100\n",
    "\n",
    "print(f\"\\nClinical Accuracy (Training):\")\n",
    "print(f\"  Within ±0.25 D: {within_025:.1f}%\")\n",
    "print(f\"  Within ±0.50 D: {within_050:.1f}%\")\n",
    "print(f\"  Within ±1.00 D: {within_100:.1f}%\")\n",
    "\n",
    "# Save the optimized formula\n",
    "model_info = {\n",
    "    'formula': opt_srkt,\n",
    "    'formula_constants': opt_srkt.constants.copy(),\n",
    "    'optimization_level': optimization_level,\n",
    "    'constants_optimized': constants_to_optimize,\n",
    "    'baseline_mae': baseline_mae,\n",
    "    'optimized_mae': optimized_mae,\n",
    "    'random_seed': Config.CURRENT_SEED\n",
    "}\n",
    "\n",
    "# Export the new formula\n",
    "def FacoDMEK_IOL_Formula(AL, K, A_const):\n",
    "    \"\"\"\n",
    "    Optimized IOL formula for FacoDMEK eyes\n",
    "    Based on SRK/T with ML-optimized constants\n",
    "    \"\"\"\n",
    "    return opt_srkt.calculate(AL, K, A_const)\n",
    "\n",
    "print(\"\\n✓ FacoDMEK IOL Formula created successfully!\")\n",
    "print(\"\\nOptimized Formula Constants:\")\n",
    "print(\"-\" * 60)\n",
    "for param in constants_to_optimize:\n",
    "    original = opt_srkt.default_constants[param]\n",
    "    optimized = opt_srkt.constants[param]\n",
    "    change = (optimized - original) / abs(original) * 100\n",
    "    print(f\"{param:15s}: {original:8.5f} → {optimized:8.5f} ({change:+6.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: Test Set Evaluation - Optimized Formula Only\n",
    "\"\"\"Evaluate the optimized formula on held-out test set\"\"\"\n",
    "\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Standard SRK/T calculator for comparison\n",
    "class SRKTCalculator:\n",
    "    \"\"\"Standard SRK/T for comparison\"\"\"\n",
    "    NA = 1.336\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate(AL, K, A_const, nc=1.333):\n",
    "        \"\"\"Standard SRK/T calculation\"\"\"\n",
    "        if any(pd.isna([AL, K, A_const])) or K <= 0 or AL <= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        try:\n",
    "            r = 337.5 / K\n",
    "            \n",
    "            if AL > 24.2:\n",
    "                LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "            else:\n",
    "                LCOR = AL\n",
    "            \n",
    "            Cw = -5.41 + 0.58412 * LCOR + 0.098 * K\n",
    "            \n",
    "            discriminant = r**2 - (Cw**2 / 4)\n",
    "            if discriminant < 0:\n",
    "                return np.nan\n",
    "            H = r - np.sqrt(discriminant)\n",
    "            \n",
    "            ACDconst = 0.62467 * A_const - 68.747\n",
    "            offset = ACDconst - 3.336\n",
    "            ACDest = H + offset\n",
    "            \n",
    "            RETHICK = 0.65696 - 0.02029 * AL\n",
    "            LOPT = AL + RETHICK\n",
    "            \n",
    "            ncm1 = nc - 1\n",
    "            numerator = 1000 * SRKTCalculator.NA * (SRKTCalculator.NA * r - ncm1 * LOPT)\n",
    "            denominator = (LOPT - ACDest) * (SRKTCalculator.NA * r - ncm1 * ACDest)\n",
    "            \n",
    "            if denominator == 0:\n",
    "                return np.nan\n",
    "                \n",
    "            IOL = numerator / denominator\n",
    "            \n",
    "            if not (-10 < IOL < 40):\n",
    "                return np.nan\n",
    "                \n",
    "            return IOL\n",
    "            \n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_error(row, nc=1.333):\n",
    "        \"\"\"Calculate prediction error\"\"\"\n",
    "        iol_pred = SRKTCalculator.calculate(\n",
    "            row['Bio-AL'], \n",
    "            row['K_avg_Kerato'], \n",
    "            row['A-Constant'], \n",
    "            nc\n",
    "        )\n",
    "        \n",
    "        if pd.isna(iol_pred):\n",
    "            return np.nan\n",
    "        \n",
    "        expected_se = -(row['IOL Power'] - iol_pred)\n",
    "        error = row['PostOP Spherical Equivalent'] - expected_se\n",
    "        \n",
    "        return error\n",
    "\n",
    "# Calculate errors with standard SRK/T\n",
    "df_test['Error_Standard'] = df_test.apply(\n",
    "    lambda row: SRKTCalculator.calculate_error(row, nc=1.333),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate errors with optimized formula\n",
    "df_test['Error_Optimized'] = df_test.apply(\n",
    "    lambda row: opt_srkt.calculate_error(row),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate predictions for analysis\n",
    "df_test['IOL_Standard'] = df_test.apply(\n",
    "    lambda row: SRKTCalculator.calculate(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant'], nc=1.333),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_test['IOL_Optimized'] = df_test.apply(\n",
    "    lambda row: opt_srkt.calculate(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Performance metrics\n",
    "def calculate_metrics(errors):\n",
    "    abs_errors = errors.abs()\n",
    "    return {\n",
    "        'n': len(errors),\n",
    "        'mae': abs_errors.mean(),\n",
    "        'median_ae': abs_errors.median(),\n",
    "        'std': abs_errors.std(),\n",
    "        'rmse': np.sqrt((errors ** 2).mean()),\n",
    "        'max_error': abs_errors.max(),\n",
    "        'within_025': (abs_errors <= 0.25).mean() * 100,\n",
    "        'within_050': (abs_errors <= 0.50).mean() * 100,\n",
    "        'within_100': (abs_errors <= 1.00).mean() * 100\n",
    "    }\n",
    "\n",
    "standard_metrics = calculate_metrics(df_test['Error_Standard'].dropna())\n",
    "optimized_metrics = calculate_metrics(df_test['Error_Optimized'].dropna())\n",
    "\n",
    "# Display results\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Metric':<20} {'Standard SRK/T':<15} {'Optimized Formula':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'MAE (D)':<20} {standard_metrics['mae']:<15.3f} {optimized_metrics['mae']:<15.3f}\")\n",
    "print(f\"{'Median AE (D)':<20} {standard_metrics['median_ae']:<15.3f} {optimized_metrics['median_ae']:<15.3f}\")\n",
    "print(f\"{'SD (D)':<20} {standard_metrics['std']:<15.3f} {optimized_metrics['std']:<15.3f}\")\n",
    "print(f\"{'RMSE (D)':<20} {standard_metrics['rmse']:<15.3f} {optimized_metrics['rmse']:<15.3f}\")\n",
    "print(f\"{'Within ±0.25 D (%)':<20} {standard_metrics['within_025']:<15.1f} {optimized_metrics['within_025']:<15.1f}\")\n",
    "print(f\"{'Within ±0.50 D (%)':<20} {standard_metrics['within_050']:<15.1f} {optimized_metrics['within_050']:<15.1f}\")\n",
    "print(f\"{'Within ±1.00 D (%)':<20} {standard_metrics['within_100']:<15.1f} {optimized_metrics['within_100']:<15.1f}\")\n",
    "\n",
    "improvement = (standard_metrics['mae'] - optimized_metrics['mae']) / standard_metrics['mae'] * 100\n",
    "print(f\"\\nImprovement: {improvement:.1f}%\")\n",
    "\n",
    "# Statistical significance test\n",
    "from scipy import stats\n",
    "\n",
    "# Paired t-test\n",
    "common_idx = df_test['Error_Standard'].notna() & df_test['Error_Optimized'].notna()\n",
    "errors_standard = df_test.loc[common_idx, 'Error_Standard'].abs()\n",
    "errors_optimized = df_test.loc[common_idx, 'Error_Optimized'].abs()\n",
    "\n",
    "t_stat, p_value = stats.ttest_rel(errors_standard, errors_optimized)\n",
    "print(f\"\\nPaired t-test: p = {p_value:.4f}\")\n",
    "print(f\"Significant improvement: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. Error distributions\n",
    "ax = axes[0, 0]\n",
    "ax.boxplot([errors_standard, errors_optimized], labels=['Standard SRK/T', 'Optimized Formula'])\n",
    "ax.set_ylabel('Absolute Error (D)')\n",
    "ax.set_title('Error Distribution Comparison')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Scatter plot: Standard vs Optimized predictions\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(df_test['IOL_Standard'], df_test['IOL_Optimized'], alpha=0.6)\n",
    "ax.plot([10, 30], [10, 30], 'r--', label='Identity line')\n",
    "ax.set_xlabel('Standard SRK/T IOL (D)')\n",
    "ax.set_ylabel('Optimized Formula IOL (D)')\n",
    "ax.set_title('IOL Power: Standard vs Optimized')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Error vs Axial Length\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(df_test['Bio-AL'], df_test['Error_Standard'].abs(), alpha=0.5, label='Standard')\n",
    "ax.scatter(df_test['Bio-AL'], df_test['Error_Optimized'].abs(), alpha=0.5, label='Optimized')\n",
    "ax.set_xlabel('Axial Length (mm)')\n",
    "ax.set_ylabel('Absolute Error (D)')\n",
    "ax.set_title('Error vs Axial Length')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Bland-Altman plot\n",
    "ax = axes[1, 1]\n",
    "mean_iol = (df_test['IOL_Standard'] + df_test['IOL_Optimized']) / 2\n",
    "diff_iol = df_test['IOL_Optimized'] - df_test['IOL_Standard']\n",
    "ax.scatter(mean_iol, diff_iol, alpha=0.6)\n",
    "ax.axhline(y=diff_iol.mean(), color='r', linestyle='-', label=f'Mean: {diff_iol.mean():.3f}')\n",
    "ax.axhline(y=diff_iol.mean() + 1.96*diff_iol.std(), color='r', linestyle='--', label='±1.96 SD')\n",
    "ax.axhline(y=diff_iol.mean() - 1.96*diff_iol.std(), color='r', linestyle='--')\n",
    "ax.set_xlabel('Mean IOL Power (D)')\n",
    "ax.set_ylabel('Difference (Optimized - Standard) (D)')\n",
    "ax.set_title('Bland-Altman Plot')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.OUTPUT_DIR / f'formula_evaluation_seed{Config.CURRENT_SEED}.png', dpi=Config.FIGURE_DPI)\n",
    "plt.show()\n",
    "\n",
    "# Print final formula\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FACODMEK IOL FORMULA (OPTIMIZED)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nFormula structure: Same as SRK/T\")\n",
    "print(\"Optimized constants:\")\n",
    "for param, value in opt_srkt.constants.items():\n",
    "    if param in constants_to_optimize:\n",
    "        original = opt_srkt.default_constants[param]\n",
    "        print(f\"  {param}: {value:.5f} (was {original:.5f})\")\n",
    "\n",
    "# Save formula constants\n",
    "constants_df = pd.DataFrame([\n",
    "    {'parameter': k, 'original': opt_srkt.default_constants[k], 'optimized': v} \n",
    "    for k, v in opt_srkt.constants.items()\n",
    "])\n",
    "constants_df.to_csv(Config.OUTPUT_DIR / f'facodmek_formula_seed{Config.CURRENT_SEED}.csv', index=False)\n",
    "print(f\"\\n✓ Formula saved to: {Config.OUTPUT_DIR / f'facodmek_formula_seed{Config.CURRENT_SEED}.csv'}\")\n",
    "\n",
    "# Store results\n",
    "current_seed_results.update({\n",
    "    'test_standard_mae': standard_metrics['mae'],\n",
    "    'test_optimized_mae': optimized_metrics['mae'],\n",
    "    'test_final_mae': optimized_metrics['mae'],  # Same as optimized (no ensemble)\n",
    "    'test_final_within_050': optimized_metrics['within_050'],\n",
    "    'test_final_within_100': optimized_metrics['within_100'],\n",
    "    'improvement_percent': improvement,\n",
    "    'p_value': p_value,\n",
    "    'seed': Config.CURRENT_SEED\n",
    "})\n",
    "\n",
    "# Add to all results\n",
    "all_seed_results.append(current_seed_results.copy())\n",
    "\n",
    "print(\"\\n✓ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab36b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 8: Multi-Seed Analysis Runner\n",
    "\"\"\"Run the complete analysis for multiple seeds\"\"\"\n",
    "\n",
    "# Check if you want to run multi-seed analysis\n",
    "RUN_MULTI_SEED = True  # Set to True to run analysis for all seeds\n",
    "\n",
    "if RUN_MULTI_SEED:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STARTING MULTI-SEED ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Clear previous results\n",
    "    all_seed_results = []\n",
    "    all_formula_constants = {}\n",
    "    \n",
    "    for seed_idx, seed in enumerate(Config.RANDOM_SEEDS):\n",
    "        print(f\"\\n{'#'*80}\")\n",
    "        print(f\"RUNNING SEED {seed_idx + 1}/{len(Config.RANDOM_SEEDS)}: {seed}\")\n",
    "        print(f\"{'#'*80}\")\n",
    "        \n",
    "        # Update current seed\n",
    "        Config.CURRENT_SEED = seed\n",
    "        np.random.seed(seed)\n",
    "        current_seed_results = {'seed': seed}\n",
    "        \n",
    "        # 1. Split data\n",
    "        splitter = DataSplitter(test_size=Config.TEST_SIZE, random_state=seed)\n",
    "        df_train_val, df_test = splitter.split_data(df_original)\n",
    "        \n",
    "        # 2. Create optimizable formula\n",
    "        opt_srkt = OptimizableSRKT()\n",
    "        \n",
    "        # Calculate baseline with standard constants\n",
    "        df_train_val['SRKT_Baseline'] = df_train_val.apply(\n",
    "            lambda row: opt_srkt.calculate(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']),\n",
    "            axis=1\n",
    "        )\n",
    "        df_train_val['SRKT_Error_Baseline'] = df_train_val.apply(\n",
    "            lambda row: opt_srkt.calculate_error(row),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        baseline_mae = df_train_val['SRKT_Error_Baseline'].abs().mean()\n",
    "        \n",
    "        # 3. Optimize formula constants\n",
    "        df_opt_train = df_train_val[df_train_val['SRKT_Error_Baseline'].notna()].copy()\n",
    "        \n",
    "        # Choose optimization level\n",
    "        optimization_level = 'moderate'  # Can be 'conservative', 'moderate', 'aggressive'\n",
    "        OPTIMIZATION_LEVELS = {\n",
    "            'conservative': ['nc', 'offset'],\n",
    "            'moderate': ['nc', 'cw_a', 'cw_b', 'cw_c', 'offset'],\n",
    "            'aggressive': ['nc', 'cw_a', 'cw_b', 'cw_c', 'offset', 'ret_a', 'ret_b', 'acd_a', 'acd_b']\n",
    "        }\n",
    "        constants_to_optimize = OPTIMIZATION_LEVELS[optimization_level]\n",
    "        \n",
    "        # Optimize\n",
    "        result = opt_srkt.optimize_constants(\n",
    "            df_opt_train,\n",
    "            constants_to_optimize=constants_to_optimize,\n",
    "            method='differential_evolution'\n",
    "        )\n",
    "        \n",
    "        # Store optimized constants\n",
    "        all_formula_constants[seed] = opt_srkt.constants.copy()\n",
    "        \n",
    "        # Calculate performance with optimized constants\n",
    "        df_opt_train['SRKT_Optimized'] = df_opt_train.apply(\n",
    "            lambda row: opt_srkt.calculate(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']),\n",
    "            axis=1\n",
    "        )\n",
    "        df_opt_train['SRKT_Error_Optimized'] = df_opt_train.apply(\n",
    "            lambda row: opt_srkt.calculate_error(row),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        optimized_mae = df_opt_train['SRKT_Error_Optimized'].abs().mean()\n",
    "        \n",
    "        # 4. Test evaluation\n",
    "        df_test['Error_Standard'] = df_test.apply(\n",
    "            lambda row: SRKTCalculator.calculate_error(row, nc=1.333),\n",
    "            axis=1\n",
    "        )\n",
    "        df_test['Error_Optimized'] = df_test.apply(\n",
    "            lambda row: opt_srkt.calculate_error(row),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Calculate metrics\n",
    "        standard_metrics = calculate_metrics(df_test['Error_Standard'].dropna())\n",
    "        optimized_metrics = calculate_metrics(df_test['Error_Optimized'].dropna())\n",
    "        \n",
    "        # Collect results\n",
    "        current_seed_results.update({\n",
    "            'optimal_nc': opt_srkt.constants['nc'],\n",
    "            'train_baseline_mae': baseline_mae,\n",
    "            'train_optimized_mae': optimized_mae,\n",
    "            'test_standard_mae': standard_metrics['mae'],\n",
    "            'test_optimized_mae': optimized_metrics['mae'],\n",
    "            'test_final_mae': optimized_metrics['mae'],\n",
    "            'test_final_within_050': optimized_metrics['within_050'],\n",
    "            'test_final_within_100': optimized_metrics['within_100'],\n",
    "            'improvement_percent': ((standard_metrics['mae'] - optimized_metrics['mae']) / \n",
    "                                  standard_metrics['mae'] * 100)\n",
    "        })\n",
    "        \n",
    "        all_seed_results.append(current_seed_results)\n",
    "        \n",
    "        print(f\"\\nSeed {seed} Results:\")\n",
    "        print(f\"  Optimal nc: {opt_srkt.constants['nc']:.5f}\")\n",
    "        print(f\"  Test MAE: {current_seed_results['test_optimized_mae']:.3f} D\")\n",
    "        print(f\"  Improvement: {current_seed_results['improvement_percent']:.1f}%\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    multi_seed_df = pd.DataFrame(all_seed_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MULTI-SEED ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n1. FORMULA CONSTANTS ACROSS SEEDS:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Analyze constant variations\n",
    "    constant_stats = {}\n",
    "    for param in constants_to_optimize:\n",
    "        values = [all_formula_constants[seed][param] for seed in Config.RANDOM_SEEDS]\n",
    "        constant_stats[param] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values),\n",
    "            'min': np.min(values),\n",
    "            'max': np.max(values)\n",
    "        }\n",
    "        print(f\"\\n{param}:\")\n",
    "        print(f\"  Mean: {constant_stats[param]['mean']:.5f}\")\n",
    "        print(f\"  Std:  {constant_stats[param]['std']:.5f}\")\n",
    "        print(f\"  Range: [{constant_stats[param]['min']:.5f}, {constant_stats[param]['max']:.5f}]\")\n",
    "    \n",
    "    print(\"\\n2. TEST SET MAE ACROSS SEEDS:\")\n",
    "    print(\"-\" * 60)\n",
    "    for method in ['test_standard_mae', 'test_optimized_mae']:\n",
    "        method_name = method.replace('test_', '').replace('_mae', '').replace('_', ' ').title()\n",
    "        print(f\"\\n{method_name}:\")\n",
    "        print(f\"  Mean: {multi_seed_df[method].mean():.3f} D\")\n",
    "        print(f\"  Std:  {multi_seed_df[method].std():.3f} D\")\n",
    "        print(f\"  Range: [{multi_seed_df[method].min():.3f}, {multi_seed_df[method].max():.3f}]\")\n",
    "    \n",
    "    print(\"\\n3. IMPROVEMENT PERCENTAGE:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Mean: {multi_seed_df['improvement_percent'].mean():.1f}%\")\n",
    "    print(f\"Std:  {multi_seed_df['improvement_percent'].std():.1f}%\")\n",
    "    print(f\"Range: [{multi_seed_df['improvement_percent'].min():.1f}%, {multi_seed_df['improvement_percent'].max():.1f}%]\")\n",
    "    \n",
    "    print(\"\\n4. CLINICAL ACCURACY (Optimized Formula):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Within ±0.50D: {multi_seed_df['test_final_within_050'].mean():.1f}% (±{multi_seed_df['test_final_within_050'].std():.1f}%)\")\n",
    "    print(f\"Within ±1.00D: {multi_seed_df['test_final_within_100'].mean():.1f}% (±{multi_seed_df['test_final_within_100'].std():.1f}%)\")\n",
    "    \n",
    "    # Save results\n",
    "    multi_seed_df.to_csv(Config.OUTPUT_DIR / 'multi_seed_results_facodmek.csv', index=False)\n",
    "    print(f\"\\n✓ Results saved to: {Config.OUTPUT_DIR / 'multi_seed_results_facodmek.csv'}\")\n",
    "    \n",
    "    # Save average formula constants\n",
    "    avg_constants = {}\n",
    "    for param in opt_srkt.default_constants.keys():\n",
    "        values = [all_formula_constants[seed][param] for seed in Config.RANDOM_SEEDS]\n",
    "        avg_constants[param] = np.mean(values)\n",
    "    \n",
    "    avg_constants_df = pd.DataFrame([\n",
    "        {'parameter': k, 'value': v, 'std': constant_stats.get(k, {}).get('std', 0)} \n",
    "        for k, v in avg_constants.items()\n",
    "    ])\n",
    "    avg_constants_df.to_csv(Config.OUTPUT_DIR / 'facodmek_formula_average_constants.csv', index=False)\n",
    "    print(f\"✓ Average formula constants saved to: {Config.OUTPUT_DIR / 'facodmek_formula_average_constants.csv'}\")\n",
    "    \n",
    "    # Display full table\n",
    "    print(\"\\nDETAILED RESULTS BY SEED:\")\n",
    "    print(\"=\"*80)\n",
    "    print(multi_seed_df.to_string(index=False, float_format=lambda x: f'{x:.3f}' if x < 10 else f'{x:.1f}'))\n",
    "    \n",
    "else:\n",
    "    print(\"\\nMulti-seed analysis not run. Set RUN_MULTI_SEED=True in Cell 8 to run it.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
