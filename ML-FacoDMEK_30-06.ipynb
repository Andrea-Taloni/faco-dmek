{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7578e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Enhanced Imports and Configuration\n",
    "\"\"\"\n",
    "Machine Learning Optimization for SRK/T Formula in FacoDMEK Eyes\n",
    "Required packages: pip install pandas numpy matplotlib seaborn scikit-learn scipy openpyxl scikit-optimize\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation and numerical computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, cross_val_score, \n",
    "    GridSearchCV, StratifiedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Optimization\n",
    "from scipy.optimize import minimize, differential_evolution, dual_annealing\n",
    "from scipy import stats\n",
    "\n",
    "# Bayesian optimization\n",
    "try:\n",
    "    from skopt import BayesSearchCV\n",
    "    from skopt.space import Real, Integer\n",
    "    SKOPT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: scikit-optimize not installed. Install with: pip install scikit-optimize\")\n",
    "    SKOPT_AVAILABLE = False\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Global configuration\n",
    "class Config:\n",
    "    RANDOM_SEED = 42  # Change for different results\n",
    "    TEST_SIZE = 0.30  # 30% test set\n",
    "    CV_FOLDS = 3      # Cross-validation folds\n",
    "    N_BOOTSTRAP = 1000  # Bootstrap iterations\n",
    "    \n",
    "    # File paths\n",
    "    DATA_FILE = 'FacoDMEK.xlsx'\n",
    "    OUTPUT_DIR = Path('output')\n",
    "    \n",
    "    # Plotting\n",
    "    FIGURE_DPI = 100\n",
    "    FIGURE_SIZE = (10, 6)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(Config.RANDOM_SEED)\n",
    "\n",
    "# Create output directory\n",
    "Config.OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Enhanced ML Pipeline for FacoDMEK IOL Calculations\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Random Seed: {Config.RANDOM_SEED}\")\n",
    "print(f\"Test Set Size: {Config.TEST_SIZE * 100:.0f}%\")\n",
    "print(f\"Cross-validation Folds: {Config.CV_FOLDS}\")\n",
    "print(f\"Output Directory: {Config.OUTPUT_DIR}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e64b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Data Loading and Advanced Feature Engineering\n",
    "\"\"\"Load data and create clinically meaningful features\"\"\"\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Handle data loading and feature engineering\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_data(filepath):\n",
    "        \"\"\"Load and validate data\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(filepath, sheet_name='Cleaned Data')\n",
    "            print(f\"✓ Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading data: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_features(df):\n",
    "        \"\"\"Create derived features based on clinical knowledge\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Basic derived features\n",
    "        df['K_avg_Kerato'] = (df['Keratometric Ks'] + df['Keratometric Kf']) / 2\n",
    "        df['K_Astigmatism_Kerato'] = df['Keratometric Ks'] - df['Keratometric Kf']\n",
    "        df['K_Cylinder'] = np.abs(df['K_Astigmatism_Kerato'])\n",
    "        \n",
    "        # Ratios and relationships\n",
    "        df['Post_Ant_Ratio'] = df['Posterior Km'] / df['Anterior Km']\n",
    "        df['AL_K_Ratio'] = df['Bio-AL'] / df['K_avg_Kerato']\n",
    "        \n",
    "        # Advanced features\n",
    "        df['K_Spherical_Equivalent'] = df['K_avg_Kerato'] + 0.5 * df['K_Cylinder']\n",
    "        \n",
    "        # Categorize axial length\n",
    "        df['AL_Category'] = pd.cut(\n",
    "            df['Bio-AL'], \n",
    "            bins=[0, 22, 24.5, 26, 100], \n",
    "            labels=['short', 'normal', 'long', 'very_long']\n",
    "        )\n",
    "        \n",
    "        # Additional clinical features if available\n",
    "        if 'Bio-ACD' in df.columns and 'Bio-LT' in df.columns:\n",
    "            df['Anterior_Segment_Depth'] = df['Bio-ACD'] + 0.5 * df['Bio-LT']\n",
    "            if 'Bio-AL' in df.columns:\n",
    "                df['LP_Factor'] = df['Bio-ACD'] / (df['Bio-AL'] - df['Bio-LT'])\n",
    "        \n",
    "        # CCT categories if available\n",
    "        if 'CCT' in df.columns:\n",
    "            df['CCT_Category'] = pd.cut(\n",
    "                df['CCT'],\n",
    "                bins=[0, 500, 550, 600, 1000],\n",
    "                labels=['thin', 'normal', 'thick', 'very_thick']\n",
    "            )\n",
    "            df['CCT_K_Interaction'] = df['CCT'] * df['K_avg_Kerato'] / 1000\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_feature_summary(df):\n",
    "        \"\"\"Print feature summary statistics\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        print(\"\\nFeature Summary:\")\n",
    "        print(\"-\" * 60)\n",
    "        for col in ['Bio-AL', 'K_avg_Kerato', 'CCT', 'IOL Power']:\n",
    "            if col in df.columns:\n",
    "                print(f\"{col:20s}: μ={df[col].mean():.2f}, σ={df[col].std():.2f}, \"\n",
    "                      f\"range=[{df[col].min():.1f}, {df[col].max():.1f}]\")\n",
    "\n",
    "# Load and process data\n",
    "processor = DataProcessor()\n",
    "df = processor.load_data(Config.DATA_FILE)\n",
    "df = processor.create_features(df)\n",
    "processor.get_feature_summary(df)\n",
    "\n",
    "print(f\"\\n✓ Feature engineering completed: {len(df.columns)} total features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4328ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Advanced Train/Test Split with Validation\n",
    "\"\"\"Create train/test split with proper stratification and validation\"\"\"\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"Handle data splitting with validation\"\"\"\n",
    "    \n",
    "    def __init__(self, test_size=0.3, random_state=42):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.required_cols = [\n",
    "            'Bio-AL', 'K_avg_Kerato', 'IOL Power', \n",
    "            'PostOP Spherical Equivalent', 'A-Constant'\n",
    "        ]\n",
    "    \n",
    "    def split_data(self, df):\n",
    "        \"\"\"Create train/test split with stratification\"\"\"\n",
    "        # Filter complete cases\n",
    "        df_complete = df[df[self.required_cols].notna().all(axis=1)].copy()\n",
    "        \n",
    "        print(f\"Complete cases: {len(df_complete)} / {len(df)} ({len(df_complete)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # Stratified split by AL category\n",
    "        df_train, df_test = train_test_split(\n",
    "            df_complete,\n",
    "            test_size=self.test_size,\n",
    "            random_state=self.random_state,\n",
    "            stratify=df_complete['AL_Category']\n",
    "        )\n",
    "        \n",
    "        return df_train, df_test\n",
    "    \n",
    "    def validate_split(self, df_train, df_test):\n",
    "        \"\"\"Validate the data split\"\"\"\n",
    "        print(\"\\nData Split Validation:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Training set: {len(df_train)} eyes ({len(df_train)/(len(df_train)+len(df_test))*100:.1f}%)\")\n",
    "        print(f\"Test set: {len(df_test)} eyes ({len(df_test)/(len(df_train)+len(df_test))*100:.1f}%)\")\n",
    "        \n",
    "        # Check distributions\n",
    "        print(\"\\nAL Distribution:\")\n",
    "        for name, data in [(\"Train\", df_train), (\"Test\", df_test)]:\n",
    "            dist = data['AL_Category'].value_counts(normalize=True).sort_index()\n",
    "            print(f\"{name}: \" + \" | \".join([f\"{cat}: {pct*100:.1f}%\" for cat, pct in dist.items()]))\n",
    "        \n",
    "        # Statistical tests for distribution similarity\n",
    "        for col in ['Bio-AL', 'K_avg_Kerato']:\n",
    "            stat, pval = stats.ks_2samp(df_train[col], df_test[col])\n",
    "            print(f\"\\nKS test for {col}: p={pval:.3f} {'✓' if pval > 0.05 else '✗'}\")\n",
    "\n",
    "# Split data\n",
    "splitter = DataSplitter(test_size=Config.TEST_SIZE, random_state=Config.RANDOM_SEED)\n",
    "df_train_val, df_test = splitter.split_data(df)\n",
    "splitter.validate_split(df_train_val, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Optimized SRK/T Formula Implementation\n",
    "\"\"\"Enhanced SRK/T formula with safety checks and validation\"\"\"\n",
    "\n",
    "class SRKTCalculator:\n",
    "    \"\"\"SRK/T IOL power calculation with enhancements\"\"\"\n",
    "    \n",
    "    # Standard constants\n",
    "    NA = 1.336  # Aqueous/vitreous refractive index\n",
    "    VERTEX = 12.0  # Vertex distance in mm\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate(AL, K, A_const, nc=1.333):\n",
    "        \"\"\"\n",
    "        Calculate IOL power using SRK/T formula\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        AL : float - Axial length (mm)\n",
    "        K : float - Average keratometry (D)\n",
    "        A_const : float - A-constant\n",
    "        nc : float - Corneal refractive index (default: 1.333)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        float - IOL power for emmetropia (D)\n",
    "        \"\"\"\n",
    "        # Input validation\n",
    "        if any(pd.isna([AL, K, A_const])) or K <= 0 or AL <= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        # Bounds checking\n",
    "        if not (15 < AL < 35) or not (35 < K < 55):\n",
    "            return np.nan\n",
    "        \n",
    "        try:\n",
    "            # Corneal radius\n",
    "            r = 337.5 / K\n",
    "            \n",
    "            # Axial length correction\n",
    "            if AL > 24.2:\n",
    "                LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "            else:\n",
    "                LCOR = AL\n",
    "            \n",
    "            # Corneal width\n",
    "            Cw = -5.41 + 0.58412 * LCOR + 0.098 * K\n",
    "            \n",
    "            # Safety check for corneal height calculation\n",
    "            discriminant = r**2 - (Cw**2 / 4)\n",
    "            if discriminant < 0:\n",
    "                return np.nan\n",
    "            \n",
    "            # Corneal height\n",
    "            H = r - np.sqrt(discriminant)\n",
    "            \n",
    "            # ACD estimation\n",
    "            ACDconst = 0.62467 * A_const - 68.747\n",
    "            offset = ACDconst - 3.336\n",
    "            ACDest = H + offset\n",
    "            \n",
    "            # Retinal thickness\n",
    "            RETHICK = 0.65696 - 0.02029 * AL\n",
    "            LOPT = AL + RETHICK\n",
    "            \n",
    "            # IOL power calculation\n",
    "            ncm1 = nc - 1\n",
    "            numerator = 1000 * SRKTCalculator.NA * (SRKTCalculator.NA * r - ncm1 * LOPT)\n",
    "            denominator = (LOPT - ACDest) * (SRKTCalculator.NA * r - ncm1 * ACDest)\n",
    "            \n",
    "            if denominator == 0:\n",
    "                return np.nan\n",
    "                \n",
    "            IOL = numerator / denominator\n",
    "            \n",
    "            # Sanity check on IOL power\n",
    "            if not (-10 < IOL < 40):\n",
    "                return np.nan\n",
    "                \n",
    "            return IOL\n",
    "            \n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_error(row, nc=1.333):\n",
    "        \"\"\"Calculate prediction error for a single case\"\"\"\n",
    "        iol_pred = SRKTCalculator.calculate(\n",
    "            row['Bio-AL'], \n",
    "            row['K_avg_Kerato'], \n",
    "            row['A-Constant'], \n",
    "            nc\n",
    "        )\n",
    "        \n",
    "        if pd.isna(iol_pred):\n",
    "            return np.nan\n",
    "        \n",
    "        expected_se = -(row['IOL Power'] - iol_pred)\n",
    "        error = row['PostOP Spherical Equivalent'] - expected_se\n",
    "        \n",
    "        return error\n",
    "\n",
    "# Calculate baseline performance\n",
    "print(\"\\nCalculating baseline SRK/T performance...\")\n",
    "df_train_val['SRKT_Baseline'] = df_train_val.apply(\n",
    "    lambda row: SRKTCalculator.calculate(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_train_val['SRKT_Error'] = df_train_val.apply(\n",
    "    lambda row: SRKTCalculator.calculate_error(row),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Performance metrics\n",
    "valid_errors = df_train_val['SRKT_Error'].dropna()\n",
    "baseline_mae = valid_errors.abs().mean()\n",
    "baseline_std = valid_errors.abs().std()\n",
    "\n",
    "print(f\"\\nBaseline Performance:\")\n",
    "print(f\"  MAE: {baseline_mae:.3f} D\")\n",
    "print(f\"  SD:  {baseline_std:.3f} D\")\n",
    "print(f\"  n:   {len(valid_errors)} eyes\")\n",
    "print(f\"\\nTarget: Beat {baseline_mae - 0.05:.3f} D for clinical significance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Optimized NC Parameter Search\n",
    "\"\"\"Grid search optimization for corneal refractive index\"\"\"\n",
    "\n",
    "class NCOptimizer:\n",
    "    \"\"\"Optimize corneal refractive index using cross-validation\"\"\"\n",
    "    \n",
    "    def __init__(self, nc_range=(1.330, 1.338), n_points=41):\n",
    "        self.nc_range = nc_range\n",
    "        self.nc_values = np.linspace(nc_range[0], nc_range[1], n_points)\n",
    "        self.results = None\n",
    "        \n",
    "    def objective_function(self, nc, df, cv_folds=3, random_state=42):\n",
    "        \"\"\"Calculate CV score for given nc value\"\"\"\n",
    "        kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(df):\n",
    "            val_data = df.iloc[val_idx]\n",
    "            \n",
    "            # Calculate errors for validation fold\n",
    "            errors = val_data.apply(\n",
    "                lambda row: SRKTCalculator.calculate_error(row, nc=nc),\n",
    "                axis=1\n",
    "            ).dropna()\n",
    "            \n",
    "            if len(errors) > 0:\n",
    "                fold_scores.append(errors.abs().mean())\n",
    "        \n",
    "        return np.mean(fold_scores) if fold_scores else np.inf\n",
    "    \n",
    "    def optimize(self, df_train):\n",
    "        \"\"\"Find optimal nc value\"\"\"\n",
    "        print(f\"Testing {len(self.nc_values)} nc values from {self.nc_range[0]} to {self.nc_range[1]}\")\n",
    "        \n",
    "        # Filter training data\n",
    "        df_opt = df_train[df_train['SRKT_Error'].notna()].copy()\n",
    "        \n",
    "        # Calculate scores\n",
    "        scores = []\n",
    "        for i, nc in enumerate(self.nc_values):\n",
    "            score = self.objective_function(nc, df_opt, cv_folds=Config.CV_FOLDS, \n",
    "                                          random_state=Config.RANDOM_SEED)\n",
    "            scores.append(score)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Progress: {i+1}/{len(self.nc_values)}\")\n",
    "        \n",
    "        # Find optimal value\n",
    "        scores = np.array(scores)\n",
    "        best_idx = np.argmin(scores)\n",
    "        self.optimal_nc = self.nc_values[best_idx]\n",
    "        self.optimal_score = scores[best_idx]\n",
    "        self.results = pd.DataFrame({'nc': self.nc_values, 'cv_mae': scores})\n",
    "        \n",
    "        return self.optimal_nc, self.optimal_score\n",
    "    \n",
    "    def plot_results(self, save_path=None):\n",
    "        \"\"\"Visualize optimization results\"\"\"\n",
    "        if self.results is None:\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=Config.FIGURE_SIZE)\n",
    "        \n",
    "        # Main plot\n",
    "        plt.plot(self.results['nc'], self.results['cv_mae'], 'b-', linewidth=2, label='CV MAE')\n",
    "        plt.scatter(self.optimal_nc, self.optimal_score, s=200, c='red', \n",
    "                   marker='*', zorder=5, label=f'Optimal: nc={self.optimal_nc:.5f}')\n",
    "        \n",
    "        # Reference line\n",
    "        plt.axvline(x=1.333, color='gray', linestyle='--', alpha=0.5, label='Standard nc=1.333')\n",
    "        \n",
    "        # Formatting\n",
    "        plt.xlabel('Corneal Refractive Index (nc)')\n",
    "        plt.ylabel('Cross-Validation MAE (D)')\n",
    "        plt.title('NC Parameter Optimization for FacoDMEK Eyes')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add text box with results\n",
    "        textstr = f'Optimal nc: {self.optimal_nc:.5f}\\nCV MAE: {self.optimal_score:.3f} D'\n",
    "        plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes,\n",
    "                fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Optimize nc\n",
    "optimizer = NCOptimizer(nc_range=(1.330, 1.338), n_points=41)\n",
    "df_opt_train = df_train_val[df_train_val['SRKT_Error'].notna()].copy()\n",
    "\n",
    "optimal_nc, optimal_score = optimizer.optimize(df_opt_train)\n",
    "\n",
    "print(f\"\\n✓ Optimization Complete!\")\n",
    "print(f\"  Optimal nc: {optimal_nc:.5f}\")\n",
    "print(f\"  CV MAE: {optimal_score:.3f} D\")\n",
    "\n",
    "# Visualize\n",
    "optimizer.plot_results(save_path=Config.OUTPUT_DIR / 'nc_optimization.png')\n",
    "\n",
    "# Apply optimal nc\n",
    "df_opt_train['Error_ML_nc'] = df_opt_train.apply(\n",
    "    lambda row: SRKTCalculator.calculate_error(row, nc=optimal_nc),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "ml_nc_mae = df_opt_train['Error_ML_nc'].abs().mean()\n",
    "improvement = (baseline_mae - ml_nc_mae) / baseline_mae * 100\n",
    "\n",
    "print(f\"\\nTraining Set Performance:\")\n",
    "print(f\"  Baseline MAE: {baseline_mae:.3f} D\")\n",
    "print(f\"  Optimized MAE: {ml_nc_mae:.3f} D\")\n",
    "print(f\"  Improvement: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1715b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: Advanced Ensemble with Bayesian Optimization\n",
    "\"\"\"Build optimized ensemble model for residual error correction\"\"\"\n",
    "\n",
    "class EnsembleBuilder:\n",
    "    \"\"\"Build and optimize ensemble model\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_cols=None, use_bayesian=True):\n",
    "        self.feature_cols = feature_cols or [\n",
    "            'Bio-AL', 'K_avg_Kerato', 'A-Constant', 'K_Cylinder',\n",
    "            'Post_Ant_Ratio', 'AL_K_Ratio', 'CCT'\n",
    "        ]\n",
    "        self.use_bayesian = use_bayesian and SKOPT_AVAILABLE\n",
    "        self.models = {}\n",
    "        self.ensemble = None\n",
    "        self.imputer = KNNImputer(n_neighbors=5)\n",
    "        \n",
    "    def add_optional_features(self, df):\n",
    "        \"\"\"Add optional features if available\"\"\"\n",
    "        optional_features = [\n",
    "            'Posterior Km', 'Anterior Km', 'Bio-ACD', 'Bio-LT',\n",
    "            'Anterior_Segment_Depth', 'LP_Factor', 'CCT_K_Interaction'\n",
    "        ]\n",
    "        \n",
    "        for feat in optional_features:\n",
    "            if feat in df.columns and feat not in self.feature_cols:\n",
    "                self.feature_cols.append(feat)\n",
    "        \n",
    "        return self.feature_cols\n",
    "    \n",
    "    def prepare_features(self, df, fit_imputer=True):\n",
    "        \"\"\"Prepare features with imputation\"\"\"\n",
    "        X = df[self.feature_cols].copy()\n",
    "        \n",
    "        if fit_imputer:\n",
    "            X_imputed = self.imputer.fit_transform(X)\n",
    "        else:\n",
    "            X_imputed = self.imputer.transform(X)\n",
    "        \n",
    "        return pd.DataFrame(X_imputed, columns=self.feature_cols, index=X.index)\n",
    "    \n",
    "    def create_base_models(self):\n",
    "        \"\"\"Create base model pipelines\"\"\"\n",
    "        models = {\n",
    "            'ridge': Pipeline([\n",
    "                ('scaler', RobustScaler()),\n",
    "                ('model', Ridge())\n",
    "            ]),\n",
    "            'huber': Pipeline([\n",
    "                ('scaler', RobustScaler()),\n",
    "                ('model', HuberRegressor())\n",
    "            ]),\n",
    "            'rf': Pipeline([\n",
    "                ('scaler', RobustScaler()),\n",
    "                ('model', RandomForestRegressor(random_state=Config.RANDOM_SEED))\n",
    "            ]),\n",
    "            'elastic': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', ElasticNet(random_state=Config.RANDOM_SEED))\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def get_search_spaces(self):\n",
    "        \"\"\"Define hyperparameter search spaces\"\"\"\n",
    "        return {\n",
    "            'ridge': {\n",
    "                'model__alpha': Real(0.1, 100.0, prior='log-uniform')\n",
    "            },\n",
    "            'huber': {\n",
    "                'model__epsilon': Real(1.0, 2.0),\n",
    "                'model__alpha': Real(0.001, 0.1, prior='log-uniform')\n",
    "            },\n",
    "            'rf': {\n",
    "                'model__n_estimators': Integer(10, 50),\n",
    "                'model__max_depth': Integer(2, 5),\n",
    "                'model__min_samples_split': Integer(10, 30),\n",
    "                'model__min_samples_leaf': Integer(5, 20)\n",
    "            },\n",
    "            'elastic': {\n",
    "                'model__alpha': Real(0.01, 1.0, prior='log-uniform'),\n",
    "                'model__l1_ratio': Real(0.1, 0.9)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def optimize_models(self, X_train, y_train):\n",
    "        \"\"\"Optimize individual models\"\"\"\n",
    "        base_models = self.create_base_models()\n",
    "        \n",
    "        if self.use_bayesian:\n",
    "            print(\"Using Bayesian optimization for hyperparameter tuning...\")\n",
    "            search_spaces = self.get_search_spaces()\n",
    "            \n",
    "            for name, model in base_models.items():\n",
    "                print(f\"\\nOptimizing {name}...\")\n",
    "                \n",
    "                optimizer = BayesSearchCV(\n",
    "                    model,\n",
    "                    search_spaces[name],\n",
    "                    n_iter=20 if name != 'rf' else 30,\n",
    "                    cv=Config.CV_FOLDS,\n",
    "                    scoring='neg_mean_absolute_error',\n",
    "                    n_jobs=-1,\n",
    "                    random_state=Config.RANDOM_SEED\n",
    "                )\n",
    "                \n",
    "                optimizer.fit(X_train, y_train)\n",
    "                self.models[name] = optimizer.best_estimator_\n",
    "                \n",
    "                print(f\"  Best params: {optimizer.best_params_}\")\n",
    "                print(f\"  Best CV MAE: {-optimizer.best_score_:.3f}\")\n",
    "        else:\n",
    "            print(\"Using default hyperparameters...\")\n",
    "            # Use reasonable defaults\n",
    "            defaults = {\n",
    "                'ridge': {'model__alpha': 10.0},\n",
    "                'huber': {'model__epsilon': 1.5, 'model__alpha': 0.01},\n",
    "                'rf': {'model__n_estimators': 20, 'model__max_depth': 3},\n",
    "                'elastic': {'model__alpha': 0.1, 'model__l1_ratio': 0.5}\n",
    "            }\n",
    "            \n",
    "            for name, model in base_models.items():\n",
    "                model.set_params(**defaults[name])\n",
    "                model.fit(X_train, y_train)\n",
    "                self.models[name] = model\n",
    "                \n",
    "                # Calculate CV score\n",
    "                cv_scores = cross_val_score(\n",
    "                    model, X_train, y_train,\n",
    "                    cv=Config.CV_FOLDS,\n",
    "                    scoring='neg_mean_absolute_error'\n",
    "                )\n",
    "                print(f\"{name}: CV MAE = {-cv_scores.mean():.3f}\")\n",
    "    \n",
    "    def create_ensemble(self, X_train, y_train):\n",
    "        \"\"\"Create and train ensemble\"\"\"\n",
    "        # Optimize individual models\n",
    "        self.optimize_models(X_train, y_train)\n",
    "        \n",
    "        # Create voting ensemble\n",
    "        self.ensemble = VotingRegressor([\n",
    "            (name, model) for name, model in self.models.items()\n",
    "        ])\n",
    "        \n",
    "        # Train ensemble\n",
    "        self.ensemble.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        cv_scores = cross_val_score(\n",
    "            self.ensemble, X_train, y_train,\n",
    "            cv=Config.CV_FOLDS,\n",
    "            scoring='neg_mean_absolute_error'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nEnsemble CV MAE: {-cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "        \n",
    "        return self.ensemble\n",
    "    \n",
    "    def optimize_dampening(self, X_train, y_train, df_train, nc_predictions):\n",
    "        \"\"\"Find optimal dampening factor\"\"\"\n",
    "        dampening_range = np.arange(0.3, 0.8, 0.1)\n",
    "        best_dampening = 0.5\n",
    "        best_mae = float('inf')\n",
    "        \n",
    "        print(\"\\nOptimizing dampening factor...\")\n",
    "        \n",
    "        # Get ensemble predictions\n",
    "        ensemble_corrections = self.ensemble.predict(X_train)\n",
    "        \n",
    "        for damp in dampening_range:\n",
    "            # Apply dampened corrections\n",
    "            final_predictions = nc_predictions + damp * ensemble_corrections\n",
    "            \n",
    "            # Calculate error\n",
    "            expected_se = -(df_train['IOL Power'] - final_predictions)\n",
    "            errors = df_train['PostOP Spherical Equivalent'] - expected_se\n",
    "            mae = errors.abs().mean()\n",
    "            \n",
    "            print(f\"  Dampening {damp:.1f}: MAE = {mae:.3f}\")\n",
    "            \n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_dampening = damp\n",
    "        \n",
    "        return best_dampening, ensemble_corrections\n",
    "\n",
    "# Build ensemble\n",
    "print(\"\\nBuilding ML Ensemble...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "builder = EnsembleBuilder()\n",
    "builder.add_optional_features(df_opt_train)\n",
    "\n",
    "print(f\"Using {len(builder.feature_cols)} features:\")\n",
    "for i, feat in enumerate(builder.feature_cols, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "# Prepare data\n",
    "X_train = builder.prepare_features(df_opt_train, fit_imputer=True)\n",
    "y_residuals = df_opt_train['Error_ML_nc']\n",
    "\n",
    "# Build ensemble\n",
    "ensemble = builder.create_ensemble(X_train, y_residuals)\n",
    "\n",
    "# Optimize dampening\n",
    "nc_predictions = df_opt_train.apply(\n",
    "    lambda row: SRKTCalculator.calculate(\n",
    "        row['Bio-AL'], row['K_avg_Kerato'], \n",
    "        row['A-Constant'], nc=optimal_nc\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "best_dampening, ensemble_corrections = builder.optimize_dampening(\n",
    "    X_train, y_residuals, df_opt_train, nc_predictions\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Best dampening factor: {best_dampening:.1f}\")\n",
    "\n",
    "# Apply final corrections\n",
    "df_opt_train['SRKT_Final'] = nc_predictions + best_dampening * ensemble_corrections\n",
    "df_opt_train['Error_Final'] = df_opt_train.apply(\n",
    "    lambda row: row['PostOP Spherical Equivalent'] - (-(row['IOL Power'] - row['SRKT_Final'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Final performance\n",
    "final_mae = df_opt_train['Error_Final'].abs().mean()\n",
    "total_improvement = (baseline_mae - final_mae) / baseline_mae * 100\n",
    "\n",
    "print(f\"\\nFinal Training Performance:\")\n",
    "print(f\"  MAE: {final_mae:.3f} D\")\n",
    "print(f\"  Total improvement: {total_improvement:.1f}%\")\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'optimal_nc': optimal_nc,\n",
    "    'ensemble': ensemble,\n",
    "    'builder': builder,\n",
    "    'dampening_factor': best_dampening,\n",
    "    'random_seed': Config.RANDOM_SEED,\n",
    "    'feature_cols': builder.feature_cols,\n",
    "    'imputer': builder.imputer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: Comprehensive Test Set Evaluation\n",
    "\"\"\"Evaluate all models on held-out test set\"\"\"\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation and comparison\"\"\"\n",
    "    \n",
    "    def __init__(self, model_info):\n",
    "        self.model_info = model_info\n",
    "        self.results = {}\n",
    "        \n",
    "    def calculate_clinical_metrics(self, errors):\n",
    "        \"\"\"Calculate comprehensive clinical metrics\"\"\"\n",
    "        abs_errors = errors.abs()\n",
    "        \n",
    "        return {\n",
    "            'n': len(errors),\n",
    "            'mae': abs_errors.mean(),\n",
    "            'median_ae': abs_errors.median(),\n",
    "            'std': abs_errors.std(),\n",
    "            'rmse': np.sqrt((errors ** 2).mean()),\n",
    "            'max_error': abs_errors.max(),\n",
    "            'within_025': (abs_errors <= 0.25).mean() * 100,\n",
    "            'within_050': (abs_errors <= 0.50).mean() * 100,\n",
    "            'within_100': (abs_errors <= 1.00).mean() * 100,\n",
    "            'within_200': (abs_errors <= 2.00).mean() * 100\n",
    "        }\n",
    "    \n",
    "    def bootstrap_confidence_interval(self, errors1, errors2, n_bootstrap=1000):\n",
    "        \"\"\"Calculate bootstrap confidence intervals for paired differences\"\"\"\n",
    "        np.random.seed(Config.RANDOM_SEED)\n",
    "        \n",
    "        # Align indices\n",
    "        common_idx = errors1.index.intersection(errors2.index)\n",
    "        e1 = errors1[common_idx].values\n",
    "        e2 = errors2[common_idx].values\n",
    "        \n",
    "        # Observed difference\n",
    "        observed_diff = np.mean(e1) - np.mean(e2)\n",
    "        \n",
    "        # Bootstrap\n",
    "        bootstrap_diffs = []\n",
    "        n_samples = len(e1)\n",
    "        \n",
    "        for _ in range(n_bootstrap):\n",
    "            idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            boot_diff = np.mean(e1[idx]) - np.mean(e2[idx])\n",
    "            bootstrap_diffs.append(boot_diff)\n",
    "        \n",
    "        bootstrap_diffs = np.array(bootstrap_diffs)\n",
    "        \n",
    "        # Statistics\n",
    "        ci_lower = np.percentile(bootstrap_diffs, 2.5)\n",
    "        ci_upper = np.percentile(bootstrap_diffs, 97.5)\n",
    "        p_value = np.sum(bootstrap_diffs <= 0) / n_bootstrap * 2\n",
    "        p_value = min(p_value, 1.0)\n",
    "        \n",
    "        return {\n",
    "            'difference': observed_diff,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'p_value': p_value,\n",
    "            'bootstrap_diffs': bootstrap_diffs\n",
    "        }\n",
    "    \n",
    "    def evaluate_all_models(self, df_test):\n",
    "        \"\"\"Evaluate all model variants\"\"\"\n",
    "        print(\"\\nEvaluating models on test set...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        df_eval = df_test.copy()\n",
    "        \n",
    "        # 1. Baseline SRK/T\n",
    "        print(\"1. Baseline SRK/T (nc=1.333)...\")\n",
    "        df_eval['Error_Baseline'] = df_eval.apply(\n",
    "            lambda row: SRKTCalculator.calculate_error(row, nc=1.333),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 2. Optimized NC\n",
    "        print(\"2. ML-Optimized NC...\")\n",
    "        df_eval['Error_ML_nc'] = df_eval.apply(\n",
    "            lambda row: SRKTCalculator.calculate_error(row, nc=self.model_info['optimal_nc']),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 3. ML + Ensemble\n",
    "        print(\"3. ML + Ensemble...\")\n",
    "        \n",
    "        # Prepare features\n",
    "        builder = self.model_info['builder']\n",
    "        X_test = builder.prepare_features(df_eval, fit_imputer=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        nc_predictions = df_eval.apply(\n",
    "            lambda row: SRKTCalculator.calculate(\n",
    "                row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                row['A-Constant'], nc=self.model_info['optimal_nc']\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        ensemble_corrections = self.model_info['ensemble'].predict(X_test)\n",
    "        final_predictions = nc_predictions + self.model_info['dampening_factor'] * ensemble_corrections\n",
    "        \n",
    "        df_eval['SRKT_Final'] = final_predictions\n",
    "        df_eval['Error_Final'] = df_eval.apply(\n",
    "            lambda row: row['PostOP Spherical Equivalent'] - (-(row['IOL Power'] - row['SRKT_Final'])),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Calculate metrics for each method\n",
    "        methods = {\n",
    "            'Baseline SRK/T': df_eval['Error_Baseline'],\n",
    "            'ML-Optimized NC': df_eval['Error_ML_nc'],\n",
    "            'ML + Ensemble': df_eval['Error_Final']\n",
    "        }\n",
    "        \n",
    "        results_summary = []\n",
    "        for method, errors in methods.items():\n",
    "            metrics = self.calculate_clinical_metrics(errors.dropna())\n",
    "            metrics['Method'] = method\n",
    "            results_summary.append(metrics)\n",
    "            self.results[method] = metrics\n",
    "        \n",
    "        # Create results dataframe\n",
    "        self.results_df = pd.DataFrame(results_summary)\n",
    "        \n",
    "        # Reorder columns\n",
    "        col_order = ['Method', 'n', 'mae', 'median_ae', 'std', 'rmse', \n",
    "                     'within_025', 'within_050', 'within_100', 'max_error']\n",
    "        self.results_df = self.results_df[col_order]\n",
    "        \n",
    "        return df_eval, self.results_df\n",
    "    \n",
    "    def perform_statistical_tests(self, df_eval):\n",
    "        \"\"\"Perform comprehensive statistical testing\"\"\"\n",
    "        print(\"\\nStatistical Testing:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        baseline_errors = df_eval['Error_Baseline'].abs().dropna()\n",
    "        ml_nc_errors = df_eval['Error_ML_nc'].abs().dropna()\n",
    "        final_errors = df_eval['Error_Final'].abs().dropna()\n",
    "        \n",
    "        # Bootstrap tests\n",
    "        tests = [\n",
    "            (\"ML-NC vs Baseline\", baseline_errors, ml_nc_errors),\n",
    "            (\"ML+Ensemble vs Baseline\", baseline_errors, final_errors),\n",
    "            (\"ML+Ensemble vs ML-NC\", ml_nc_errors, final_errors)\n",
    "        ]\n",
    "        \n",
    "        test_results = []\n",
    "        for name, errors1, errors2 in tests:\n",
    "            result = self.bootstrap_confidence_interval(errors1, errors2)\n",
    "            \n",
    "            print(f\"\\n{name}:\")\n",
    "            print(f\"  Difference: {result['difference']:.4f} D\")\n",
    "            print(f\"  95% CI: [{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]\")\n",
    "            print(f\"  p-value: {result['p_value']:.4f}\")\n",
    "            print(f\"  Significant: {'Yes ✓' if result['p_value'] < 0.05 else 'No ✗'}\")\n",
    "            \n",
    "            test_results.append({\n",
    "                'comparison': name,\n",
    "                **result\n",
    "            })\n",
    "        \n",
    "        # Additional tests\n",
    "        from scipy.stats import ttest_rel, wilcoxon\n",
    "        \n",
    "        common_idx = baseline_errors.index.intersection(final_errors.index)\n",
    "        if len(common_idx) > 0:\n",
    "            # Paired t-test\n",
    "            t_stat, p_ttest = ttest_rel(\n",
    "                baseline_errors[common_idx], \n",
    "                final_errors[common_idx]\n",
    "            )\n",
    "            \n",
    "            # Wilcoxon signed-rank test\n",
    "            w_stat, p_wilcoxon = wilcoxon(\n",
    "                baseline_errors[common_idx], \n",
    "                final_errors[common_idx]\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nAdditional tests (ML+Ensemble vs Baseline):\")\n",
    "            print(f\"  Paired t-test p-value: {p_ttest:.4f}\")\n",
    "            print(f\"  Wilcoxon test p-value: {p_wilcoxon:.4f}\")\n",
    "        \n",
    "        return test_results\n",
    "    \n",
    "    def create_visualizations(self, df_eval, save_dir=None):\n",
    "        \"\"\"Create comprehensive visualization suite\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('Test Set Evaluation Results', fontsize=16)\n",
    "        \n",
    "        # 1. Error distributions\n",
    "        ax = axes[0, 0]\n",
    "        error_data = [\n",
    "            df_eval['Error_Baseline'].abs().dropna(),\n",
    "            df_eval['Error_ML_nc'].abs().dropna(),\n",
    "            df_eval['Error_Final'].abs().dropna()\n",
    "        ]\n",
    "        bp = ax.boxplot(error_data, labels=['Baseline', 'ML-NC', 'ML+Ensemble'], patch_artist=True)\n",
    "        colors = ['lightblue', 'lightgreen', 'gold']\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        ax.set_ylabel('Absolute Error (D)')\n",
    "        ax.set_title('Error Distributions')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. MAE comparison\n",
    "        ax = axes[0, 1]\n",
    "        methods = self.results_df['Method'].values\n",
    "        maes = self.results_df['mae'].values\n",
    "        bars = ax.bar(range(len(methods)), maes, color=colors)\n",
    "        ax.set_xticks(range(len(methods)))\n",
    "        ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "        ax.set_ylabel('MAE (D)')\n",
    "        ax.set_title('Mean Absolute Error')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, mae in zip(bars, maes):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                   f'{mae:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 3. Clinical accuracy\n",
    "        ax = axes[0, 2]\n",
    "        x = np.arange(len(methods))\n",
    "        width = 0.25\n",
    "        \n",
    "        within_025 = self.results_df['within_025'].values\n",
    "        within_050 = self.results_df['within_050'].values\n",
    "        within_100 = self.results_df['within_100'].values\n",
    "        \n",
    "        ax.bar(x - width, within_025, width, label='±0.25D', color='darkgreen')\n",
    "        ax.bar(x, within_050, width, label='±0.50D', color='orange')\n",
    "        ax.bar(x + width, within_100, width, label='±1.00D', color='blue')\n",
    "        \n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "        ax.set_ylabel('Percentage (%)')\n",
    "        ax.set_title('Clinical Accuracy')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 4. Scatter plot - Final model\n",
    "        ax = axes[1, 0]\n",
    "        predicted = df_eval['SRKT_Final'].dropna()\n",
    "        actual = df_eval.loc[predicted.index, 'IOL Power']\n",
    "        \n",
    "        ax.scatter(actual, predicted, alpha=0.6, color='gold')\n",
    "        \n",
    "        # Add perfect prediction line\n",
    "        lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "            np.max([ax.get_xlim(), ax.get_ylim()])\n",
    "        ]\n",
    "        ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "        \n",
    "        ax.set_xlabel('Actual IOL Power (D)')\n",
    "        ax.set_ylabel('Predicted IOL Power (D)')\n",
    "        ax.set_title('ML+Ensemble: Predicted vs Actual')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Error vs AL\n",
    "        ax = axes[1, 1]\n",
    "        al = df_eval['Bio-AL']\n",
    "        errors = df_eval['Error_Final'].abs()\n",
    "        \n",
    "        ax.scatter(al, errors, alpha=0.6, color='gold')\n",
    "        ax.set_xlabel('Axial Length (mm)')\n",
    "        ax.set_ylabel('Absolute Error (D)')\n",
    "        ax.set_title('Error vs Axial Length')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add trend line\n",
    "        z = np.polyfit(al.dropna(), errors.dropna(), 2)\n",
    "        p = np.poly1d(z)\n",
    "        x_trend = np.linspace(al.min(), al.max(), 100)\n",
    "        ax.plot(x_trend, p(x_trend), 'r-', alpha=0.8)\n",
    "        \n",
    "        # 6. Improvement summary\n",
    "        ax = axes[1, 2]\n",
    "        baseline_mae = self.results_df.loc[0, 'mae']\n",
    "        improvements = []\n",
    "        \n",
    "        for _, row in self.results_df.iterrows():\n",
    "            imp = (baseline_mae - row['mae']) / baseline_mae * 100\n",
    "            improvements.append(imp)\n",
    "        \n",
    "        bars = ax.bar(range(len(methods)), improvements, color=colors)\n",
    "        ax.set_xticks(range(len(methods)))\n",
    "        ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "        ax.set_ylabel('Improvement (%)')\n",
    "        ax.set_title('Relative Performance Improvement')\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, imp in zip(bars, improvements):\n",
    "            if imp != 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                       f'{imp:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_dir:\n",
    "            plt.savefig(save_dir / 'test_evaluation.png', dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Evaluate models\n",
    "evaluator = ModelEvaluator(model_info)\n",
    "df_test_eval, results_df = evaluator.evaluate_all_models(df_test)\n",
    "\n",
    "print(\"\\nTest Set Results Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string(index=False, float_format=lambda x: f'{x:.3f}' if x < 10 else f'{x:.1f}'))\n",
    "\n",
    "# Statistical testing\n",
    "test_results = evaluator.perform_statistical_tests(df_test_eval)\n",
    "\n",
    "# Visualizations\n",
    "fig = evaluator.create_visualizations(df_test_eval, save_dir=Config.OUTPUT_DIR)\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test set size: {len(df_test)} eyes\")\n",
    "print(f\"Best method: {results_df.loc[results_df['mae'].idxmin(), 'Method']}\")\n",
    "print(f\"Best MAE: {results_df['mae'].min():.3f} D\")\n",
    "print(f\"Improvement: {(results_df.iloc[0]['mae'] - results_df['mae'].min()) / results_df.iloc[0]['mae'] * 100:.1f}%\")\n",
    "print(f\"Random seed: {Config.RANDOM_SEED}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
