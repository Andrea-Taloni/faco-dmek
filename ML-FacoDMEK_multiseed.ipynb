{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff30ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Enhanced Imports with Multi-Seed Analysis Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy import stats\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MULTIPLE SEEDS FOR ROBUST ANALYSIS\n",
    "SEEDS = [42, 123, 456, 789, 1001, 2024, 3141, 5555, 8888, 9999]\n",
    "\n",
    "print(\"Enhanced ML Analysis for FacoDMEK Eyes - EXTENDED BOUNDS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Testing {len(SEEDS)} different random seeds for robust results\")\n",
    "print(f\"Seeds: {SEEDS}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nWARNING: Using extended parameter bounds\")\n",
    "print(\"This may lead to better results but also higher overfitting risk\")\n",
    "print(\"Multi-seed validation is crucial!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Storage for results across seeds\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8541af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Load Data with Proper Feature Engineering\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('FacoDMEK.xlsx', sheet_name='Cleaned Data')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "\n",
    "# Calculate derived features\n",
    "df['K_avg_Kerato'] = (df['Keratometric Ks'] + df['Keratometric Kf']) / 2\n",
    "df['K_Astigmatism_Kerato'] = df['Keratometric Ks'] - df['Keratometric Kf']\n",
    "df['Post_Ant_Ratio'] = df['Posterior Km'] / df['Anterior Km']\n",
    "df['AL_K_Ratio'] = df['Bio-AL'] / df['K_avg_Kerato']\n",
    "df['K_Cylinder'] = np.abs(df['K_Astigmatism_Kerato'])\n",
    "df['AL_Category'] = pd.cut(df['Bio-AL'], bins=[0, 22, 24.5, 26, 100], \n",
    "                           labels=['short', 'normal', 'long', 'very_long'])\n",
    "\n",
    "print(f\"\\nFeature engineering completed\")\n",
    "\n",
    "# Prepare complete cases\n",
    "required_cols = ['Bio-AL', 'K_avg_Kerato', 'IOL Power', \n",
    "                 'PostOP Spherical Equivalent', 'A-Constant']\n",
    "df_complete = df[df[required_cols].notna().all(axis=1)].copy()\n",
    "\n",
    "print(f\"\\nComplete cases for analysis: {len(df_complete)} out of {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d02bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Run Complete Analysis with EXTENDED PARAMETER BOUNDS\n",
    "print(\"MULTI-SEED ROBUST ANALYSIS WITH EXTENDED BOUNDS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define SRK/T function\n",
    "def calculate_SRKT(AL, K, A_const, nc=1.333):\n",
    "    \"\"\"Standard SRK/T formula\"\"\"\n",
    "    if pd.isna(AL) or pd.isna(K) or pd.isna(A_const) or K <= 0 or AL <= 0:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        na = 1.336\n",
    "        r = 337.5 / K\n",
    "        \n",
    "        if AL > 24.2:\n",
    "            LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "        else:\n",
    "            LCOR = AL\n",
    "        \n",
    "        Cw = -5.41 + 0.58412 * LCOR + 0.098 * K\n",
    "        \n",
    "        if r**2 - (Cw**2 / 4) < 0:\n",
    "            return np.nan\n",
    "        \n",
    "        H = r - np.sqrt(r**2 - (Cw**2 / 4))\n",
    "        ACDconst = 0.62467 * A_const - 68.747\n",
    "        offset = ACDconst - 3.336\n",
    "        ACDest = H + offset\n",
    "        \n",
    "        RETHICK = 0.65696 - 0.02029 * AL\n",
    "        LOPT = AL + RETHICK\n",
    "        \n",
    "        ncm1 = nc - 1\n",
    "        IOL = (1000 * na * (na * r - ncm1 * LOPT)) / ((LOPT - ACDest) * (na * r - ncm1 * ACDest))\n",
    "        \n",
    "        return IOL\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Extended SRK/T with all parameters\n",
    "def calculate_SRKT_ml(AL, K, A_const, params):\n",
    "    \"\"\"ML-optimized SRK/T formula with extended parameters\"\"\"\n",
    "    nc = params[0]\n",
    "    cw_const1, cw_const2, cw_const3 = params[1:4]\n",
    "    acd_const1, acd_const2 = params[4:6]\n",
    "    offset_const = params[6]\n",
    "    rethick_const1, rethick_const2 = params[7:9]\n",
    "    \n",
    "    if pd.isna(AL) or pd.isna(K) or pd.isna(A_const) or K <= 0 or AL <= 0:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        na = 1.336\n",
    "        r = 337.5 / K\n",
    "        \n",
    "        if AL > 24.2:\n",
    "            LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "        else:\n",
    "            LCOR = AL\n",
    "        \n",
    "        Cw = cw_const1 + cw_const2 * LCOR + cw_const3 * K\n",
    "        \n",
    "        if r**2 - (Cw**2 / 4) < 0:\n",
    "            return np.nan\n",
    "        \n",
    "        H = r - np.sqrt(r**2 - (Cw**2 / 4))\n",
    "        ACDconst = acd_const1 * A_const - acd_const2\n",
    "        offset = ACDconst - offset_const\n",
    "        ACDest = H + offset\n",
    "        \n",
    "        RETHICK = rethick_const1 - rethick_const2 * AL\n",
    "        LOPT = AL + RETHICK\n",
    "        \n",
    "        ncm1 = nc - 1\n",
    "        IOL = (1000 * na * (na * r - ncm1 * LOPT)) / ((LOPT - ACDest) * (na * r - ncm1 * ACDest))\n",
    "        \n",
    "        return IOL\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Storage for seed-specific results\n",
    "seed_results = []\n",
    "\n",
    "# Run analysis for each seed\n",
    "for seed_idx, SEED in enumerate(SEEDS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ANALYZING SEED {seed_idx+1}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Set seed\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    # Split data\n",
    "    df_train_val, df_test = train_test_split(\n",
    "        df_complete, \n",
    "        test_size=0.30,\n",
    "        random_state=SEED,\n",
    "        stratify=df_complete['AL_Category']\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(df_train_val)} eyes, Test: {len(df_test)} eyes\")\n",
    "    \n",
    "    # Calculate baseline performance on training data\n",
    "    df_train_val['SRKT_Baseline'] = df_train_val.apply(\n",
    "        lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']), \n",
    "        axis=1\n",
    "    )\n",
    "    df_train_val['Expected_SE'] = -(df_train_val['IOL Power'] - df_train_val['SRKT_Baseline'])\n",
    "    df_train_val['SRKT_Error'] = df_train_val['PostOP Spherical Equivalent'] - df_train_val['Expected_SE']\n",
    "    \n",
    "    baseline_mae_train = df_train_val['SRKT_Error'].abs().mean()\n",
    "    \n",
    "    # Optimize nc using EXTENDED RANGE\n",
    "    print(\"Optimizing nc with EXTENDED range...\")\n",
    "    df_opt_train = df_train_val[df_train_val['SRKT_Error'].notna()].copy()\n",
    "    \n",
    "    # EXTENDED NC RANGE: 1.325 to 1.345 (was 1.330 to 1.338)\n",
    "    nc_range = np.arange(1.325, 1.345, 0.0002)\n",
    "    best_nc = 1.333\n",
    "    best_nc_mae = 999\n",
    "    \n",
    "    for nc in nc_range:\n",
    "        predictions = df_opt_train.apply(\n",
    "            lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                     row['A-Constant'], nc=nc), \n",
    "            axis=1\n",
    "        )\n",
    "        expected_se = -(df_opt_train['IOL Power'] - predictions)\n",
    "        errors = (df_opt_train['PostOP Spherical Equivalent'] - expected_se).abs()\n",
    "        mae = errors.mean()\n",
    "        \n",
    "        if mae < best_nc_mae:\n",
    "            best_nc_mae = mae\n",
    "            best_nc = nc\n",
    "    \n",
    "    print(f\"Optimal nc: {best_nc:.5f} (range tested: {nc_range[0]:.3f}-{nc_range[-1]:.3f})\")\n",
    "    \n",
    "    # Optimize all parameters with EXTENDED BOUNDS\n",
    "    print(\"Optimizing all parameters with EXTENDED bounds...\")\n",
    "    \n",
    "    def objective_all_constants(params):\n",
    "        errors_all = []\n",
    "        for idx, row in df_opt_train.iterrows():\n",
    "            pred = calculate_SRKT_ml(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                    row['A-Constant'], params)\n",
    "            if not np.isnan(pred):\n",
    "                expected_se = -(row['IOL Power'] - pred)\n",
    "                error = abs(row['PostOP Spherical Equivalent'] - expected_se)\n",
    "                errors_all.append(error)\n",
    "        \n",
    "        if not errors_all:\n",
    "            return 999\n",
    "            \n",
    "        mae = np.mean(errors_all)\n",
    "        \n",
    "        # STRONGER regularization for extended bounds\n",
    "        standard_params = [1.333, -5.41, 0.58412, 0.098, 0.62467, 68.747, 3.336, 0.65696, 0.02029]\n",
    "        penalty = 0\n",
    "        for i, (p, s) in enumerate(zip(params, standard_params)):\n",
    "            if i == 0:  # nc - moderate penalty\n",
    "                penalty += 0.5 * ((p - s) / s) ** 2\n",
    "            else:  # other parameters - stronger penalty\n",
    "                penalty += 2.0 * ((p - s) / s) ** 2\n",
    "        \n",
    "        return mae + penalty\n",
    "    \n",
    "    # EXTENDED BOUNDS - much wider ranges\n",
    "    bounds = [\n",
    "        (1.325, 1.345),      # nc - extended from (1.330, 1.338)\n",
    "        (-6.5, -4.3),        # cw_const1 - extended from (-5.6, -5.2)\n",
    "        (0.50, 0.68),        # cw_const2 - extended from (0.56, 0.61)\n",
    "        (0.070, 0.130),      # cw_const3 - extended from (0.093, 0.103)\n",
    "        (0.55, 0.70),        # acd_const1 - extended from (0.61, 0.64)\n",
    "        (60.0, 77.0),        # acd_const2 - extended from (67.0, 70.5)\n",
    "        (2.5, 4.2),          # offset_const - extended from (3.2, 3.5)\n",
    "        (0.55, 0.75),        # rethick_const1 - extended from (0.64, 0.67)\n",
    "        (0.015, 0.025)       # rethick_const2 - extended from (0.019, 0.022)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nExtended bounds being used:\")\n",
    "    param_names = ['nc', 'cw_const1', 'cw_const2', 'cw_const3', 'acd_const1', \n",
    "                   'acd_const2', 'offset_const', 'rethick_const1', 'rethick_const2']\n",
    "    for i, (name, (low, high)) in enumerate(zip(param_names, bounds)):\n",
    "        print(f\"  {name}: [{low:.3f}, {high:.3f}]\")\n",
    "    \n",
    "    result_de = differential_evolution(\n",
    "        objective_all_constants, \n",
    "        bounds,\n",
    "        maxiter=50,      # More iterations for extended space\n",
    "        popsize=20,      # Larger population\n",
    "        seed=SEED,\n",
    "        mutation=(0.5, 1.5),  # More exploration\n",
    "        recombination=0.8,\n",
    "        disp=False\n",
    "    )\n",
    "    \n",
    "    optimal_params_all = result_de.x\n",
    "    \n",
    "    # Train ensemble with stronger regularization\n",
    "    print(\"Training ensemble with regularization...\")\n",
    "    feature_cols = ['Bio-AL', 'K_avg_Kerato', 'A-Constant', 'K_Cylinder', \n",
    "                    'Post_Ant_Ratio', 'AL_K_Ratio', 'CCT']\n",
    "    \n",
    "    # Add additional features if available\n",
    "    for col in ['Posterior Km', 'Anterior Km', 'Bio-ACD', 'Bio-LT']:\n",
    "        if col in df_opt_train.columns:\n",
    "            feature_cols.append(col)\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    X_train_imputed = imputer.fit_transform(df_opt_train[feature_cols])\n",
    "    \n",
    "    # Calculate residuals to predict\n",
    "    df_opt_train['SRKT_ML_nc'] = df_opt_train.apply(\n",
    "        lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                  row['A-Constant'], nc=best_nc), \n",
    "        axis=1\n",
    "    )\n",
    "    df_opt_train['Expected_SE_ML_nc'] = -(df_opt_train['IOL Power'] - df_opt_train['SRKT_ML_nc'])\n",
    "    df_opt_train['Error_ML_nc'] = df_opt_train['PostOP Spherical Equivalent'] - df_opt_train['Expected_SE_ML_nc']\n",
    "    \n",
    "    y_residuals = df_opt_train['Error_ML_nc'].values\n",
    "    \n",
    "    # Create ensemble with STRONGER regularization\n",
    "    ensemble = VotingRegressor([\n",
    "        ('ridge', Pipeline([\n",
    "            ('scaler', RobustScaler()),\n",
    "            ('ridge', Ridge(alpha=50.0))  # Increased from 10.0\n",
    "        ])),\n",
    "        ('huber', Pipeline([\n",
    "            ('scaler', RobustScaler()),\n",
    "            ('huber', HuberRegressor(epsilon=2.0, alpha=0.1))  # Increased regularization\n",
    "        ])),\n",
    "        ('rf', Pipeline([\n",
    "            ('scaler', RobustScaler()),\n",
    "            ('rf', RandomForestRegressor(n_estimators=10, max_depth=2,  # Simpler model\n",
    "                                       min_samples_split=20, min_samples_leaf=15,\n",
    "                                       random_state=SEED))\n",
    "        ]))\n",
    "    ])\n",
    "    \n",
    "    ensemble.fit(X_train_imputed, y_residuals)\n",
    "    \n",
    "    # TEST SET EVALUATION\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    df_test_eval = df_test.copy()\n",
    "    \n",
    "    # Baseline\n",
    "    df_test_eval['SRKT_Baseline'] = df_test_eval.apply(\n",
    "        lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], row['A-Constant']), \n",
    "        axis=1\n",
    "    )\n",
    "    df_test_eval['Expected_SE_Baseline'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_Baseline'])\n",
    "    df_test_eval['Error_Baseline'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_Baseline']\n",
    "    \n",
    "    # ML-optimized nc\n",
    "    df_test_eval['SRKT_ML_nc'] = df_test_eval.apply(\n",
    "        lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                  row['A-Constant'], nc=best_nc), \n",
    "        axis=1\n",
    "    )\n",
    "    df_test_eval['Expected_SE_ML_nc'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_ML_nc'])\n",
    "    df_test_eval['Error_ML_nc'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_ML_nc']\n",
    "    \n",
    "    # Fully optimized\n",
    "    df_test_eval['SRKT_ML_Full'] = df_test_eval.apply(\n",
    "        lambda row: calculate_SRKT_ml(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                     row['A-Constant'], optimal_params_all), \n",
    "        axis=1\n",
    "    )\n",
    "    df_test_eval['Expected_SE_ML_Full'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_ML_Full'])\n",
    "    df_test_eval['Error_ML_Full'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_ML_Full']\n",
    "    \n",
    "    # Ensemble with conservative dampening (0.3 instead of 0.5)\n",
    "    X_test_imputed = imputer.transform(df_test_eval[feature_cols])\n",
    "    ensemble_corrections = ensemble.predict(X_test_imputed)\n",
    "    df_test_eval['SRKT_Final'] = df_test_eval['SRKT_ML_nc'] + 0.3 * ensemble_corrections\n",
    "    df_test_eval['Expected_SE_Final'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_Final'])\n",
    "    df_test_eval['Error_Final'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_Final']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae_baseline = df_test_eval['Error_Baseline'].abs().mean()\n",
    "    mae_nc = df_test_eval['Error_ML_nc'].abs().mean()\n",
    "    mae_full = df_test_eval['Error_ML_Full'].abs().mean()\n",
    "    mae_ensemble = df_test_eval['Error_Final'].abs().mean()\n",
    "    \n",
    "    # Store results\n",
    "    seed_results.append({\n",
    "        'seed': SEED,\n",
    "        'train_size': len(df_train_val),\n",
    "        'test_size': len(df_test),\n",
    "        'optimal_nc': best_nc,\n",
    "        'mae_baseline': mae_baseline,\n",
    "        'mae_nc': mae_nc,\n",
    "        'mae_full': mae_full,\n",
    "        'mae_ensemble': mae_ensemble,\n",
    "        'improvement_nc': (mae_baseline - mae_nc) / mae_baseline * 100,\n",
    "        'improvement_full': (mae_baseline - mae_full) / mae_baseline * 100,\n",
    "        'improvement_ensemble': (mae_baseline - mae_ensemble) / mae_baseline * 100,\n",
    "        'optimal_params': optimal_params_all.tolist()\n",
    "    })\n",
    "    \n",
    "    print(f\"Test MAE - Baseline: {mae_baseline:.3f}, ML-nc: {mae_nc:.3f}, \"\n",
    "          f\"ML-Full: {mae_full:.3f}, Ensemble: {mae_ensemble:.3f}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(seed_results)\n",
    "\n",
    "# Save detailed results\n",
    "results_df.to_csv('extended_bounds_results.csv', index=False)\n",
    "print(f\"\\nDetailed results saved to: extended_bounds_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67472663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Comprehensive Analysis of Extended Bounds Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-SEED ANALYSIS RESULTS - EXTENDED BOUNDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display all results\n",
    "print(\"\\nDetailed results for each seed:\")\n",
    "display_cols = ['seed', 'mae_baseline', 'mae_nc', 'mae_full', 'mae_ensemble', \n",
    "                'improvement_nc', 'improvement_full', 'improvement_ensemble']\n",
    "print(results_df[display_cols].to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS ACROSS ALL SEEDS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_stats = results_df[['mae_baseline', 'mae_nc', 'mae_full', 'mae_ensemble', \n",
    "                            'improvement_nc', 'improvement_full', 'improvement_ensemble']].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Key metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY PERFORMANCE METRICS (Mean ± Std)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics = {\n",
    "    'Baseline SRK/T': results_df['mae_baseline'],\n",
    "    'ML-Optimized nc': results_df['mae_nc'],\n",
    "    'ML-Optimized Full': results_df['mae_full'],\n",
    "    'ML + Ensemble': results_df['mae_ensemble']\n",
    "}\n",
    "\n",
    "for method, values in metrics.items():\n",
    "    print(f\"{method:20s}: MAE = {values.mean():.3f} ± {values.std():.3f} D \"\n",
    "          f\"[{values.min():.3f}, {values.max():.3f}]\")\n",
    "\n",
    "print(\"\\nIMPROVEMENT OVER BASELINE:\")\n",
    "improvements = {\n",
    "    'NC optimization': results_df['improvement_nc'],\n",
    "    'Full optimization': results_df['improvement_full'],\n",
    "    'With ensemble': results_df['improvement_ensemble']\n",
    "}\n",
    "\n",
    "for method, values in improvements.items():\n",
    "    print(f\"{method:20s}: {values.mean():.1f}% ± {values.std():.1f}% \"\n",
    "          f\"[{values.min():.1f}%, {values.max():.1f}%]\")\n",
    "\n",
    "# Check for overfitting signs\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERFITTING CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate coefficient of variation\n",
    "for method, values in metrics.items():\n",
    "    cv = values.std() / values.mean() * 100\n",
    "    print(f\"{method:20s}: CV = {cv:.1f}%\")\n",
    "\n",
    "# Statistical testing\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SIGNIFICANCE (Paired t-test across seeds)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Test each method against baseline\n",
    "for method, col in [('ML-nc', 'mae_nc'), ('ML-Full', 'mae_full'), ('ML-Ensemble', 'mae_ensemble')]:\n",
    "    t_stat, p_value = ttest_rel(results_df['mae_baseline'], results_df[col])\n",
    "    mean_diff = results_df['mae_baseline'].mean() - results_df[col].mean()\n",
    "    print(f\"{method} vs Baseline: Mean diff = {mean_diff:.3f} D, \"\n",
    "          f\"t = {t_stat:.3f}, p = {p_value:.4f}, \"\n",
    "          f\"Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Optimal parameter analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMAL PARAMETER RANGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract all optimal parameters\n",
    "all_params = np.array([params for params in results_df['optimal_params']])\n",
    "param_names = ['nc', 'cw_const1', 'cw_const2', 'cw_const3', 'acd_const1', \n",
    "               'acd_const2', 'offset_const', 'rethick_const1', 'rethick_const2']\n",
    "standard_params = [1.333, -5.41, 0.58412, 0.098, 0.62467, 68.747, 3.336, 0.65696, 0.02029]\n",
    "\n",
    "print(f\"{'Parameter':15s} {'Standard':>10s} {'Mean Opt':>10s} {'Std':>8s} {'Min':>10s} {'Max':>10s} {'Change %':>10s}\")\n",
    "print(\"-\" * 85)\n",
    "for i, name in enumerate(param_names):\n",
    "    param_values = all_params[:, i]\n",
    "    mean_val = param_values.mean()\n",
    "    std_val = param_values.std()\n",
    "    min_val = param_values.min()\n",
    "    max_val = param_values.max()\n",
    "    change_pct = (mean_val - standard_params[i]) / abs(standard_params[i]) * 100\n",
    "    \n",
    "    print(f\"{name:15s} {standard_params[i]:10.5f} {mean_val:10.5f} \"\n",
    "          f\"{std_val:8.5f} {min_val:10.5f} {max_val:10.5f} {change_pct:10.2f}%\")\n",
    "\n",
    "# Warning about parameter ranges\n",
    "if any(abs((all_params[:, i].mean() - standard_params[i]) / standard_params[i]) > 0.1 \n",
    "       for i in range(len(param_names))):\n",
    "    print(\"\\nWARNING: Some parameters deviate >10% from standard values.\")\n",
    "    print(\"This may indicate overfitting. Consider clinical validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Comprehensive Visualization with Extended Bounds Analysis\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "\n",
    "# 1. MAE comparison across seeds\n",
    "ax1 = plt.subplot(4, 3, 1)\n",
    "x = np.arange(len(SEEDS))\n",
    "width = 0.2\n",
    "ax1.bar(x - 1.5*width, results_df['mae_baseline'], width, label='Baseline', color='lightblue')\n",
    "ax1.bar(x - 0.5*width, results_df['mae_nc'], width, label='ML-nc', color='lightgreen')\n",
    "ax1.bar(x + 0.5*width, results_df['mae_full'], width, label='ML-Full', color='lightcoral')\n",
    "ax1.bar(x + 1.5*width, results_df['mae_ensemble'], width, label='Ensemble', color='gold')\n",
    "ax1.set_xlabel('Seed')\n",
    "ax1.set_ylabel('MAE (D)')\n",
    "ax1.set_title('MAE Across Different Seeds (Extended Bounds)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(SEEDS, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box plot of MAE distributions\n",
    "ax2 = plt.subplot(4, 3, 2)\n",
    "data_to_plot = [results_df['mae_baseline'], results_df['mae_nc'], \n",
    "                results_df['mae_full'], results_df['mae_ensemble']]\n",
    "bp = ax2.boxplot(data_to_plot, labels=['Baseline', 'ML-nc', 'ML-Full', 'Ensemble'],\n",
    "                 patch_artist=True)\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "ax2.set_ylabel('MAE (D)')\n",
    "ax2.set_title('MAE Distribution - Extended Bounds')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Improvement percentages\n",
    "ax3 = plt.subplot(4, 3, 3)\n",
    "improvement_data = [results_df['improvement_nc'], results_df['improvement_full'], \n",
    "                   results_df['improvement_ensemble']]\n",
    "bp2 = ax3.boxplot(improvement_data, labels=['NC Only', 'Full Opt', 'Ensemble'],\n",
    "                  patch_artist=True)\n",
    "for patch, color in zip(bp2['boxes'], ['lightgreen', 'lightcoral', 'gold']):\n",
    "    patch.set_facecolor(color)\n",
    "ax3.set_ylabel('Improvement (%)')\n",
    "ax3.set_title('Improvement Distribution')\n",
    "ax3.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(y=30, color='green', linestyle='--', alpha=0.5, label='30% target')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Parameter deviation heatmap\n",
    "ax4 = plt.subplot(4, 3, 4)\n",
    "all_params = np.array([params for params in results_df['optimal_params']])\n",
    "param_deviations = np.zeros((len(SEEDS), len(param_names)))\n",
    "for i in range(len(param_names)):\n",
    "    param_deviations[:, i] = (all_params[:, i] - standard_params[i]) / abs(standard_params[i]) * 100\n",
    "\n",
    "im = ax4.imshow(param_deviations.T, cmap='RdBu_r', aspect='auto', vmin=-30, vmax=30)\n",
    "ax4.set_yticks(range(len(param_names)))\n",
    "ax4.set_yticklabels(param_names)\n",
    "ax4.set_xticks(range(len(SEEDS)))\n",
    "ax4.set_xticklabels(SEEDS, rotation=45)\n",
    "ax4.set_xlabel('Seed')\n",
    "ax4.set_title('Parameter Deviation from Standard (%)')\n",
    "plt.colorbar(im, ax=ax4, label='Deviation %')\n",
    "\n",
    "# 5. NC values across seeds with extended range\n",
    "ax5 = plt.subplot(4, 3, 5)\n",
    "ax5.scatter(SEEDS, results_df['optimal_nc'], s=100, c='blue', alpha=0.7)\n",
    "ax5.axhline(y=1.333, color='red', linestyle='--', label='Standard nc=1.333')\n",
    "ax5.axhline(y=results_df['optimal_nc'].mean(), color='green', \n",
    "            linestyle='--', label=f'Mean nc={results_df[\"optimal_nc\"].mean():.5f}')\n",
    "ax5.fill_between(SEEDS, 1.325, 1.345, alpha=0.2, color='gray', label='Extended bounds')\n",
    "ax5.set_xlabel('Seed')\n",
    "ax5.set_ylabel('Optimal nc')\n",
    "ax5.set_title('Optimal nc Values (Extended Range)')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Best vs worst seed comparison\n",
    "ax6 = plt.subplot(4, 3, 6)\n",
    "best_seed_idx = results_df['improvement_full'].idxmax()\n",
    "worst_seed_idx = results_df['improvement_full'].idxmin()\n",
    "methods = ['Baseline', 'NC', 'Full', 'Ensemble']\n",
    "best_maes = [results_df.loc[best_seed_idx, 'mae_baseline'],\n",
    "             results_df.loc[best_seed_idx, 'mae_nc'],\n",
    "             results_df.loc[best_seed_idx, 'mae_full'],\n",
    "             results_df.loc[best_seed_idx, 'mae_ensemble']]\n",
    "worst_maes = [results_df.loc[worst_seed_idx, 'mae_baseline'],\n",
    "              results_df.loc[worst_seed_idx, 'mae_nc'],\n",
    "              results_df.loc[worst_seed_idx, 'mae_full'],\n",
    "              results_df.loc[worst_seed_idx, 'mae_ensemble']]\n",
    "\n",
    "x_pos = np.arange(len(methods))\n",
    "ax6.bar(x_pos - 0.2, best_maes, 0.4, label=f'Best (Seed {results_df.loc[best_seed_idx, \"seed\"]})', \n",
    "        color='green', alpha=0.7)\n",
    "ax6.bar(x_pos + 0.2, worst_maes, 0.4, label=f'Worst (Seed {results_df.loc[worst_seed_idx, \"seed\"]})', \n",
    "        color='red', alpha=0.7)\n",
    "ax6.set_xticks(x_pos)\n",
    "ax6.set_xticklabels(methods)\n",
    "ax6.set_ylabel('MAE (D)')\n",
    "ax6.set_title('Best vs Worst Seed Performance')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 7. Stability analysis\n",
    "ax7 = plt.subplot(4, 3, 7)\n",
    "stability_metrics = []\n",
    "for col in ['mae_baseline', 'mae_nc', 'mae_full', 'mae_ensemble']:\n",
    "    cv = results_df[col].std() / results_df[col].mean() * 100\n",
    "    stability_metrics.append(cv)\n",
    "\n",
    "bars = ax7.bar(methods, stability_metrics, color=colors)\n",
    "ax7.set_ylabel('Coefficient of Variation (%)')\n",
    "ax7.set_title('Method Stability (Lower is Better)')\n",
    "ax7.axhline(y=10, color='green', linestyle='--', alpha=0.5, label='Good stability')\n",
    "ax7.axhline(y=20, color='orange', linestyle='--', alpha=0.5, label='Moderate stability')\n",
    "ax7.axhline(y=30, color='red', linestyle='--', alpha=0.5, label='Poor stability')\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 8. Improvement vs parameter deviation\n",
    "ax8 = plt.subplot(4, 3, 8)\n",
    "max_param_deviation = np.max(np.abs(param_deviations), axis=1)\n",
    "ax8.scatter(max_param_deviation, results_df['improvement_full'], s=100, alpha=0.7)\n",
    "ax8.set_xlabel('Max Parameter Deviation (%)')\n",
    "ax8.set_ylabel('Improvement (%)')\n",
    "ax8.set_title('Improvement vs Parameter Deviation')\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(max_param_deviation, results_df['improvement_full'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax8.plot(sorted(max_param_deviation), p(sorted(max_param_deviation)), \"r--\", alpha=0.8)\n",
    "\n",
    "# 9. Cumulative improvement distribution\n",
    "ax9 = plt.subplot(4, 3, 9)\n",
    "for method, col, color in [('NC', 'improvement_nc', 'green'),\n",
    "                          ('Full', 'improvement_full', 'red'),\n",
    "                          ('Ensemble', 'improvement_ensemble', 'gold')]:\n",
    "    sorted_imp = np.sort(results_df[col])\n",
    "    cumulative = np.arange(1, len(sorted_imp) + 1) / len(sorted_imp)\n",
    "    ax9.plot(sorted_imp, cumulative, label=method, color=color, linewidth=2)\n",
    "ax9.axvline(x=30, color='black', linestyle='--', alpha=0.5, label='30% target')\n",
    "ax9.set_xlabel('Improvement (%)')\n",
    "ax9.set_ylabel('Cumulative Probability')\n",
    "ax9.set_title('Probability of Achieving Improvement')\n",
    "ax9.legend()\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "# 10. Parameter correlation matrix\n",
    "ax10 = plt.subplot(4, 3, 10)\n",
    "param_corr = np.corrcoef(all_params.T)\n",
    "im = ax10.imshow(param_corr, cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
    "ax10.set_xticks(range(len(param_names)))\n",
    "ax10.set_yticks(range(len(param_names)))\n",
    "ax10.set_xticklabels(param_names, rotation=45)\n",
    "ax10.set_yticklabels(param_names)\n",
    "ax10.set_title('Parameter Correlation Matrix')\n",
    "plt.colorbar(im, ax=ax10)\n",
    "\n",
    "# 11. Summary statistics\n",
    "ax11 = plt.subplot(4, 3, 11)\n",
    "ax11.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "EXTENDED BOUNDS ANALYSIS SUMMARY (n={len(SEEDS)} seeds)\n",
    "\n",
    "Best Method: ML-Full Optimization\n",
    "MAE: {results_df['mae_full'].mean():.3f} ± {results_df['mae_full'].std():.3f} D\n",
    "Improvement: {results_df['improvement_full'].mean():.1f}% ± {results_df['improvement_full'].std():.1f}%\n",
    "Range: [{results_df['improvement_full'].min():.1f}%, {results_df['improvement_full'].max():.1f}%]\n",
    "\n",
    "Optimal nc: {results_df['optimal_nc'].mean():.5f} ± {results_df['optimal_nc'].std():.5f}\n",
    "Range tested: [1.325, 1.345] (extended from [1.330, 1.338])\n",
    "\n",
    "Success rate:\n",
    "- Improvement > 25%: {(results_df['improvement_full'] > 25).sum()}/{len(SEEDS)} seeds\n",
    "- Improvement > 30%: {(results_df['improvement_full'] > 30).sum()}/{len(SEEDS)} seeds\n",
    "- Improvement > 35%: {(results_df['improvement_full'] > 35).sum()}/{len(SEEDS)} seeds\n",
    "\n",
    "Warning: Extended bounds may increase overfitting risk\n",
    "Recommend clinical validation before implementation\n",
    "\"\"\"\n",
    "ax11.text(0.05, 0.5, summary_text, fontsize=11, verticalalignment='center',\n",
    "         fontfamily='monospace', bbox=dict(boxstyle=\"round,pad=0.5\", \n",
    "         facecolor=\"lightyellow\", alpha=0.8))\n",
    "\n",
    "# 12. Risk assessment\n",
    "ax12 = plt.subplot(4, 3, 12)\n",
    "risk_scores = []\n",
    "for idx in range(len(results_df)):\n",
    "    # Risk based on parameter deviation and stability\n",
    "    param_dev = np.max(np.abs(param_deviations[idx]))\n",
    "    improvement = results_df.loc[idx, 'improvement_full']\n",
    "    # High risk if large deviation with small improvement\n",
    "    risk = param_dev / (improvement + 10)  # Add 10 to avoid division issues\n",
    "    risk_scores.append(risk)\n",
    "\n",
    "ax12.scatter(SEEDS, risk_scores, s=100, c=risk_scores, cmap='RdYlGn_r')\n",
    "ax12.set_xlabel('Seed')\n",
    "ax12.set_ylabel('Risk Score')\n",
    "ax12.set_title('Overfitting Risk Assessment (Lower is Better)')\n",
    "ax12.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Extended Bounds Multi-Seed Analysis for FacoDMEK IOL Optimization', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f561bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: Clinical Recommendations with Extended Bounds Risk Assessment\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL RECOMMENDATIONS - EXTENDED BOUNDS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate robust estimates\n",
    "mean_baseline = results_df['mae_baseline'].mean()\n",
    "mean_optimized = results_df['mae_full'].mean()\n",
    "mean_improvement = results_df['improvement_full'].mean()\n",
    "std_improvement = results_df['improvement_full'].std()\n",
    "\n",
    "# Parameter analysis\n",
    "all_params = np.array([params for params in results_df['optimal_params']])\n",
    "param_names = ['nc', 'cw_const1', 'cw_const2', 'cw_const3', 'acd_const1', \n",
    "               'acd_const2', 'offset_const', 'rethick_const1', 'rethick_const2']\n",
    "standard_params = [1.333, -5.41, 0.58412, 0.098, 0.62467, 68.747, 3.336, 0.65696, 0.02029]\n",
    "\n",
    "print(f\"\\n1. PERFORMANCE SUMMARY:\")\n",
    "print(f\"   Standard SRK/T: MAE = {mean_baseline:.3f} D\")\n",
    "print(f\"   Optimized SRK/T: MAE = {mean_optimized:.3f} D\")\n",
    "print(f\"   Mean improvement: {mean_improvement:.1f}% ± {std_improvement:.1f}%\")\n",
    "print(f\"   Best case: {results_df['improvement_full'].max():.1f}%\")\n",
    "print(f\"   Worst case: {results_df['improvement_full'].min():.1f}%\")\n",
    "\n",
    "print(f\"\\n2. PARAMETER RECOMMENDATIONS:\")\n",
    "print(f\"   {'Parameter':15s} {'Standard':>10s} {'Recommended':>12s} {'Range':>20s}\")\n",
    "print(\"   \" + \"-\"*60)\n",
    "for i, name in enumerate(param_names):\n",
    "    param_values = all_params[:, i]\n",
    "    mean_val = param_values.mean()\n",
    "    std_val = param_values.std()\n",
    "    \n",
    "    # Flag high-risk parameters (>10% deviation)\n",
    "    deviation = abs((mean_val - standard_params[i]) / standard_params[i] * 100)\n",
    "    risk_flag = \" ⚠️\" if deviation > 10 else \"\"\n",
    "    \n",
    "    print(f\"   {name:15s} {standard_params[i]:10.5f} {mean_val:12.5f} \"\n",
    "          f\"[{mean_val-std_val:.5f}, {mean_val+std_val:.5f}]{risk_flag}\")\n",
    "\n",
    "print(f\"\\n3. RISK ASSESSMENT:\")\n",
    "max_deviations = [np.max(np.abs((all_params[i] - standard_params) / standard_params * 100)) \n",
    "                  for i in range(len(all_params))]\n",
    "avg_max_deviation = np.mean(max_deviations)\n",
    "print(f\"   Average maximum parameter deviation: {avg_max_deviation:.1f}%\")\n",
    "print(f\"   Seeds with >20% deviation: {sum(d > 20 for d in max_deviations)}/{len(SEEDS)}\")\n",
    "print(f\"   Risk level: {'HIGH' if avg_max_deviation > 20 else 'MODERATE' if avg_max_deviation > 10 else 'LOW'}\")\n",
    "\n",
    "print(f\"\\n4. IMPLEMENTATION STRATEGY:\")\n",
    "print(f\"   a) Conservative: Use nc = {results_df['optimal_nc'].mean():.5f} only\")\n",
    "print(f\"      Expected improvement: {results_df['improvement_nc'].mean():.1f}%\")\n",
    "print(f\"   b) Moderate: Use optimized parameters with <10% deviation\")\n",
    "print(f\"   c) Aggressive: Use full optimization (with clinical validation)\")\n",
    "\n",
    "print(f\"\\n5. VALIDATION REQUIREMENTS:\")\n",
    "print(f\"   ⚠️  Extended bounds require additional validation:\")\n",
    "print(f\"   - Test on independent dataset\")\n",
    "print(f\"   - Monitor first 50-100 cases closely\")\n",
    "print(f\"   - Compare with standard formula outcomes\")\n",
    "print(f\"   - Consider gradual implementation\")\n",
    "\n",
    "# Statistical significance check\n",
    "from scipy.stats import ttest_rel\n",
    "t_stat, p_value = ttest_rel(results_df['mae_baseline'], results_df['mae_full'])\n",
    "print(f\"\\n6. STATISTICAL SIGNIFICANCE:\")\n",
    "print(f\"   Paired t-test p-value: {p_value:.4f}\")\n",
    "print(f\"   Significant at α=0.05: {'Yes ✓' if p_value < 0.05 else 'No ✗'}\")\n",
    "print(f\"   Effect size (Cohen's d): {(mean_baseline - mean_optimized) / np.sqrt((results_df['mae_baseline'].std()**2 + results_df['mae_full'].std()**2) / 2):.3f}\")\n",
    "\n",
    "# Export recommendations\n",
    "recommendations = {\n",
    "    'analysis_type': 'Extended Bounds Multi-Seed',\n",
    "    'n_seeds': len(SEEDS),\n",
    "    'n_eyes': len(df_complete),\n",
    "    'performance': {\n",
    "        'baseline_mae': float(mean_baseline),\n",
    "        'optimized_mae': float(mean_optimized),\n",
    "        'mean_improvement_pct': float(mean_improvement),\n",
    "        'std_improvement_pct': float(std_improvement),\n",
    "        'p_value': float(p_value)\n",
    "    },\n",
    "    'parameters': {\n",
    "        name: {\n",
    "            'standard': float(standard_params[i]),\n",
    "            'optimized_mean': float(all_params[:, i].mean()),\n",
    "            'optimized_std': float(all_params[:, i].std()),\n",
    "            'deviation_pct': float((all_params[:, i].mean() - standard_params[i]) / abs(standard_params[i]) * 100)\n",
    "        }\n",
    "        for i, name in enumerate(param_names)\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('extended_bounds_recommendations.json', 'w') as f:\n",
    "    json.dump(recommendations, f, indent=2)\n",
    "\n",
    "print(f\"\\n7. FILES SAVED:\")\n",
    "print(f\"   - extended_bounds_results.csv\")\n",
    "print(f\"   - extended_bounds_recommendations.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6.5: Optimize ALL SRK/T Formula Constants\n",
    "print(\"\\nOPTIMIZING ALL SRK/T FORMULA CONSTANTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"This will optimize all 9 parameters, not just nc\")\n",
    "print(f\"Using random seed: {RANDOM_SEED}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extended SRK/T with learnable parameters\n",
    "def calculate_SRKT_ml(AL, K, A_const, params):\n",
    "    \"\"\"\n",
    "    ML-optimized SRK/T formula with all parameters optimizable\n",
    "    params = [nc, cw_const1, cw_const2, cw_const3, acd_const1, acd_const2, \n",
    "              offset_const, rethick_const1, rethick_const2]\n",
    "    \"\"\"\n",
    "    # Unpack all parameters\n",
    "    nc = params[0]\n",
    "    cw_const1, cw_const2, cw_const3 = params[1:4]\n",
    "    acd_const1, acd_const2 = params[4:6]\n",
    "    offset_const = params[6]\n",
    "    rethick_const1, rethick_const2 = params[7:9]\n",
    "    \n",
    "    if pd.isna(AL) or pd.isna(K) or pd.isna(A_const) or K <= 0 or AL <= 0:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        na = 1.336\n",
    "        r = 337.5 / K\n",
    "        \n",
    "        # Use standard threshold\n",
    "        if AL > 24.2:\n",
    "            LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "        else:\n",
    "            LCOR = AL\n",
    "        \n",
    "        # Optimized corneal width calculation\n",
    "        Cw = cw_const1 + cw_const2 * LCOR + cw_const3 * K\n",
    "        \n",
    "        if r**2 - (Cw**2 / 4) < 0:\n",
    "            return np.nan\n",
    "        \n",
    "        H = r - np.sqrt(r**2 - (Cw**2 / 4))\n",
    "        \n",
    "        # Optimized ACD calculation\n",
    "        ACDconst = acd_const1 * A_const - acd_const2\n",
    "        offset = ACDconst - offset_const\n",
    "        ACDest = H + offset\n",
    "        \n",
    "        # Optimized retinal thickness\n",
    "        RETHICK = rethick_const1 - rethick_const2 * AL\n",
    "        LOPT = AL + RETHICK\n",
    "        \n",
    "        ncm1 = nc - 1\n",
    "        IOL = (1000 * na * (na * r - ncm1 * LOPT)) / ((LOPT - ACDest) * (na * r - ncm1 * ACDest))\n",
    "        \n",
    "        return IOL\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Objective function for optimizing ALL constants\n",
    "def objective_all_constants(params):\n",
    "    \"\"\"Cross-validation based objective with strong regularization\"\"\"\n",
    "    errors_all = []\n",
    "    \n",
    "    # 3-fold cross-validation\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=RANDOM_SEED)  # USE VARIABLE SEED\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(df_opt_train):\n",
    "        val_data = df_opt_train.iloc[val_idx]\n",
    "        \n",
    "        predictions = val_data.apply(\n",
    "            lambda row: calculate_SRKT_ml(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                         row['A-Constant'], params), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        expected_se = -(val_data['IOL Power'] - predictions)\n",
    "        errors = val_data['PostOP Spherical Equivalent'] - expected_se\n",
    "        \n",
    "        valid_errors = errors[errors.notna()]\n",
    "        if len(valid_errors) > 0:\n",
    "            errors_all.extend(valid_errors.abs().tolist())\n",
    "    \n",
    "    if len(errors_all) == 0:\n",
    "        return 999\n",
    "    \n",
    "    mae = np.mean(errors_all)\n",
    "    \n",
    "    # Add regularization to prevent extreme values\n",
    "    # Penalize deviation from standard values\n",
    "    standard_params = [1.333, -5.41, 0.58412, 0.098, 0.62467, 68.747, 3.336, 0.65696, 0.02029]\n",
    "    penalty = 0\n",
    "    for i, (opt, std) in enumerate(zip(params, standard_params)):\n",
    "        # Different weights for different parameters\n",
    "        if i == 0:  # nc - allow more flexibility\n",
    "            penalty += 5 * ((opt - std) / std) ** 2\n",
    "        else:  # other parameters - stronger regularization\n",
    "            penalty += 20 * ((opt - std) / std) ** 2\n",
    "    \n",
    "    return mae + penalty\n",
    "\n",
    "# Initial parameters (standard SRK/T values)\n",
    "initial_params = [\n",
    "    1.333,          # nc\n",
    "    -5.41,          # cw_const1\n",
    "    0.58412,        # cw_const2\n",
    "    0.098,          # cw_const3\n",
    "    0.62467,        # acd_const1\n",
    "    68.747,         # acd_const2\n",
    "    3.336,          # offset_const\n",
    "    0.65696,        # rethick_const1\n",
    "    0.02029         # rethick_const2\n",
    "]\n",
    "\n",
    "# Bounds for optimization (tighter bounds for stability)\n",
    "bounds = [\n",
    "    (1.330, 1.340),           # nc\n",
    "    (-5.8, -5.0),             # cw_const1\n",
    "    (0.55, 0.62),             # cw_const2\n",
    "    (0.090, 0.106),           # cw_const3\n",
    "    (0.60, 0.65),             # acd_const1\n",
    "    (65.0, 72.0),             # acd_const2\n",
    "    (3.1, 3.6),               # offset_const\n",
    "    (0.63, 0.68),             # rethick_const1\n",
    "    (0.018, 0.023)            # rethick_const2\n",
    "]\n",
    "\n",
    "print(\"\\nOptimizing SRK/T formula constants using Differential Evolution...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Run optimization with more conservative settings\n",
    "result_de = differential_evolution(\n",
    "    objective_all_constants, \n",
    "    bounds,\n",
    "    maxiter=50,     # More iterations\n",
    "    popsize=15,\n",
    "    seed=RANDOM_SEED,  # USE VARIABLE SEED\n",
    "    atol=0.0001,\n",
    "    tol=0.0001,\n",
    "    disp=True,\n",
    "    workers=1,\n",
    "    strategy='best1bin',\n",
    "    mutation=(0.5, 1),  # Conservative mutation\n",
    "    recombination=0.7\n",
    ")\n",
    "\n",
    "optimal_params_all = result_de.x\n",
    "\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"Final objective value: {result_de.fun:.4f}\")\n",
    "\n",
    "# Display optimized parameters\n",
    "param_names = ['nc', 'cw_const1', 'cw_const2', 'cw_const3', 'acd_const1', \n",
    "               'acd_const2', 'offset_const', 'rethick_const1', 'rethick_const2']\n",
    "\n",
    "print(\"\\nOptimized Parameters:\")\n",
    "print(\"-\" * 60)\n",
    "for name, original, optimized in zip(param_names, initial_params, optimal_params_all):\n",
    "    change_pct = (optimized - original) / abs(original) * 100\n",
    "    print(f\"{name:20s}: {original:8.5f} → {optimized:8.5f} ({change_pct:+6.2f}%)\")\n",
    "\n",
    "# Calculate performance with fully optimized formula\n",
    "df_opt_train['SRKT_ML_Full'] = df_opt_train.apply(\n",
    "    lambda row: calculate_SRKT_ml(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                 row['A-Constant'], optimal_params_all), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_opt_train['Expected_SE_ML_Full'] = -(df_opt_train['IOL Power'] - df_opt_train['SRKT_ML_Full'])\n",
    "df_opt_train['Error_ML_Full'] = df_opt_train['PostOP Spherical Equivalent'] - df_opt_train['Expected_SE_ML_Full']\n",
    "\n",
    "# Compare performances\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SET PERFORMANCE COMPARISON:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "baseline_train_mae = df_opt_train['SRKT_Error'].abs().mean()\n",
    "nc_only_mae = df_opt_train['Error_ML_nc'].abs().mean()\n",
    "full_opt_mae = df_opt_train['Error_ML_Full'].abs().mean()\n",
    "\n",
    "print(f\"Baseline SRK/T:           MAE = {baseline_train_mae:.3f} D\")\n",
    "print(f\"Optimized nc only:        MAE = {nc_only_mae:.3f} D ({(baseline_train_mae-nc_only_mae)/baseline_train_mae*100:.1f}% improvement)\")\n",
    "print(f\"Fully optimized SRK/T:    MAE = {full_opt_mae:.3f} D ({(baseline_train_mae-full_opt_mae)/baseline_train_mae*100:.1f}% improvement)\")\n",
    "\n",
    "# Update model_info to include full optimization\n",
    "model_info['optimal_params_all'] = optimal_params_all\n",
    "model_info['param_names'] = param_names\n",
    "model_info['calculate_SRKT_ml'] = calculate_SRKT_ml\n",
    "\n",
    "print(\"\\nFull formula optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: Final Test Set Evaluation with Bootstrap Confidence Intervals\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"#\" + \" \"*30 + \"FINAL TEST SET EVALUATION\" + \" \"*24 + \"#\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\nUsing bootstrap for more reliable significance testing\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare test data\n",
    "df_test_eval = df_test.copy()\n",
    "\n",
    "# 1. Baseline SRK/T\n",
    "print(\"\\nCalculating baseline SRK/T...\")\n",
    "df_test_eval['SRKT_Baseline'] = df_test_eval.apply(\n",
    "    lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                              row['A-Constant'], nc=1.333), \n",
    "    axis=1\n",
    ")\n",
    "df_test_eval['Expected_SE_Baseline'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_Baseline'])\n",
    "df_test_eval['Error_Baseline'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_Baseline']\n",
    "\n",
    "# 2. ML-optimized nc only\n",
    "print(\"Calculating ML-optimized nc...\")\n",
    "df_test_eval['SRKT_ML_nc'] = df_test_eval.apply(\n",
    "    lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                              row['A-Constant'], nc=model_info['optimal_nc']), \n",
    "    axis=1\n",
    ")\n",
    "df_test_eval['Expected_SE_ML_nc'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_ML_nc'])\n",
    "df_test_eval['Error_ML_nc'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_ML_nc']\n",
    "\n",
    "# 3. Fully optimized SRK/T (all constants)\n",
    "print(\"Calculating fully optimized SRK/T...\")\n",
    "if 'optimal_params_all' in model_info:\n",
    "    df_test_eval['SRKT_ML_Full'] = df_test_eval.apply(\n",
    "        lambda row: calculate_SRKT_ml(row['Bio-AL'], row['K_avg_Kerato'], \n",
    "                                     row['A-Constant'], model_info['optimal_params_all']), \n",
    "        axis=1\n",
    "    )\n",
    "    df_test_eval['Expected_SE_ML_Full'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_ML_Full'])\n",
    "    df_test_eval['Error_ML_Full'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_ML_Full']\n",
    "\n",
    "# 4. ML + Ensemble\n",
    "print(\"Calculating ensemble predictions...\")\n",
    "# Prepare features using the same imputer from training\n",
    "X_test = df_test_eval[model_info['feature_cols']].copy()\n",
    "\n",
    "# Use the fitted imputer from training\n",
    "X_test_imputed = pd.DataFrame(\n",
    "    model_info['imputer'].transform(X_test),\n",
    "    columns=model_info['feature_cols'],\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Make ensemble predictions\n",
    "ensemble_corrections = model_info['ensemble'].predict(X_test_imputed)\n",
    "df_test_eval['SRKT_Final'] = (\n",
    "    df_test_eval['SRKT_ML_nc'] + \n",
    "    model_info['dampening_factor'] * ensemble_corrections\n",
    ")\n",
    "df_test_eval['Expected_SE_Final'] = -(df_test_eval['IOL Power'] - df_test_eval['SRKT_Final'])\n",
    "df_test_eval['Error_Final'] = df_test_eval['PostOP Spherical Equivalent'] - df_test_eval['Expected_SE_Final']\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "methods = {\n",
    "    'Baseline SRK/T': df_test_eval['Error_Baseline'].abs(),\n",
    "    'ML-Optimized nc': df_test_eval['Error_ML_nc'].abs(),\n",
    "}\n",
    "\n",
    "# Add fully optimized if available\n",
    "if 'Error_ML_Full' in df_test_eval.columns:\n",
    "    methods['ML-Optimized Full'] = df_test_eval['Error_ML_Full'].abs()\n",
    "\n",
    "methods['ML + Ensemble'] = df_test_eval['Error_Final'].abs()\n",
    "\n",
    "# Results summary\n",
    "results_data = []\n",
    "for method, errors in methods.items():\n",
    "    valid_errors = errors.dropna()\n",
    "    mae = valid_errors.mean()\n",
    "    std = valid_errors.std()\n",
    "    within_025 = (valid_errors <= 0.25).sum() / len(valid_errors) * 100\n",
    "    within_050 = (valid_errors <= 0.50).sum() / len(valid_errors) * 100\n",
    "    within_100 = (valid_errors <= 1.00).sum() / len(valid_errors) * 100\n",
    "    \n",
    "    results_data.append({\n",
    "        'Method': method,\n",
    "        'MAE (D)': mae,\n",
    "        'SD (D)': std,\n",
    "        '±0.25D (%)': within_025,\n",
    "        '±0.50D (%)': within_050,\n",
    "        '±1.00D (%)': within_100\n",
    "    })\n",
    "    \n",
    "results_df = pd.DataFrame(results_data)\n",
    "print(results_df.to_string(index=False, float_format=lambda x: f'{x:.3f}' if x < 10 else f'{x:.1f}'))\n",
    "\n",
    "# Bootstrap significance testing with CORRECTED function\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BOOTSTRAP SIGNIFICANCE TESTING (1000 iterations)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def bootstrap_paired_test(errors1, errors2, n_bootstrap=1000):\n",
    "    \"\"\"Bootstrap test for paired samples - RETURNS bootstrap_diffs\"\"\"\n",
    "    # Align indices\n",
    "    common_idx = errors1.index.intersection(errors2.index)\n",
    "    e1 = errors1[common_idx].values\n",
    "    e2 = errors2[common_idx].values\n",
    "    \n",
    "    # Calculate observed difference\n",
    "    observed_diff = np.mean(e1) - np.mean(e2)\n",
    "    \n",
    "    # Bootstrap\n",
    "    bootstrap_diffs = []\n",
    "    n_samples = len(e1)\n",
    "    \n",
    "    # Set seed for bootstrap\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        boot_diff = np.mean(e1[idx]) - np.mean(e2[idx])\n",
    "        bootstrap_diffs.append(boot_diff)\n",
    "    \n",
    "    bootstrap_diffs = np.array(bootstrap_diffs)\n",
    "    \n",
    "    # Calculate p-value (two-sided)\n",
    "    p_value = np.sum(bootstrap_diffs <= 0) / n_bootstrap * 2\n",
    "    p_value = min(p_value, 1.0)\n",
    "    \n",
    "    # Confidence interval\n",
    "    ci_lower = np.percentile(bootstrap_diffs, 2.5)\n",
    "    ci_upper = np.percentile(bootstrap_diffs, 97.5)\n",
    "    \n",
    "    return observed_diff, p_value, ci_lower, ci_upper, bootstrap_diffs\n",
    "\n",
    "# Test ML methods against baseline\n",
    "baseline_errors = df_test_eval['Error_Baseline'].abs().dropna()\n",
    "\n",
    "# 1. ML-nc vs Baseline\n",
    "print(\"\\n1. ML-Optimized nc vs Baseline:\")\n",
    "ml_nc_errors = df_test_eval['Error_ML_nc'].abs().dropna()\n",
    "diff_nc, p_nc, ci_lower_nc, ci_upper_nc, bootstrap_diffs_nc = bootstrap_paired_test(\n",
    "    baseline_errors, ml_nc_errors\n",
    ")\n",
    "print(f\"   Mean difference: {diff_nc:.4f} D\")\n",
    "print(f\"   95% CI: [{ci_lower_nc:.4f}, {ci_upper_nc:.4f}]\")\n",
    "print(f\"   Bootstrap p-value: {p_nc:.4f}\")\n",
    "print(f\"   Significant at α=0.05: {'Yes' if p_nc < 0.05 else 'No'}\")\n",
    "\n",
    "# 2. Fully optimized vs Baseline (if available)\n",
    "if 'Error_ML_Full' in df_test_eval.columns:\n",
    "    print(\"\\n2. Fully Optimized SRK/T vs Baseline:\")\n",
    "    ml_full_errors = df_test_eval['Error_ML_Full'].abs().dropna()\n",
    "    diff_full, p_full, ci_lower_full, ci_upper_full, bootstrap_diffs_full = bootstrap_paired_test(\n",
    "        baseline_errors, ml_full_errors\n",
    "    )\n",
    "    print(f\"   Mean difference: {diff_full:.4f} D\")\n",
    "    print(f\"   95% CI: [{ci_lower_full:.4f}, {ci_upper_full:.4f}]\")\n",
    "    print(f\"   Bootstrap p-value: {p_full:.4f}\")\n",
    "    print(f\"   Significant at α=0.05: {'Yes' if p_full < 0.05 else 'No'}\")\n",
    "\n",
    "# 3. ML+Ensemble vs Baseline\n",
    "print(\"\\n3. ML + Ensemble vs Baseline:\")\n",
    "final_errors = df_test_eval['Error_Final'].abs().dropna()\n",
    "diff_final, p_final, ci_lower_final, ci_upper_final, bootstrap_diffs = bootstrap_paired_test(\n",
    "    baseline_errors, final_errors\n",
    ")\n",
    "print(f\"   Mean difference: {diff_final:.4f} D\")\n",
    "print(f\"   95% CI: [{ci_lower_final:.4f}, {ci_upper_final:.4f}]\")\n",
    "print(f\"   Bootstrap p-value: {p_final:.4f}\")\n",
    "print(f\"   Significant at α=0.05: {'Yes' if p_final < 0.05 else 'No'}\")\n",
    "\n",
    "# Additional paired t-test for comparison\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADDITIONAL STATISTICAL TESTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paired t-test\n",
    "common_idx = baseline_errors.index.intersection(final_errors.index)\n",
    "if len(common_idx) > 0:\n",
    "    t_stat, p_ttest = ttest_rel(baseline_errors[common_idx], final_errors[common_idx])\n",
    "    print(f\"\\nPaired t-test (ML + Ensemble vs Baseline):\")\n",
    "    print(f\"   p-value: {p_ttest:.4f}\")\n",
    "    print(f\"   Significant at α=0.05: {'Yes' if p_ttest < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Wilcoxon signed-rank test\n",
    "    w_stat, p_wilcoxon = wilcoxon(baseline_errors[common_idx], final_errors[common_idx])\n",
    "    print(f\"\\nWilcoxon signed-rank test (ML + Ensemble vs Baseline):\")\n",
    "    print(f\"   p-value: {p_wilcoxon:.4f}\")\n",
    "    print(f\"   Significant at α=0.05: {'Yes' if p_wilcoxon < 0.05 else 'No'}\")\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Plot 1: Error distributions\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "data_to_plot = []\n",
    "labels = []\n",
    "for method, errors in methods.items():\n",
    "    if not errors.isna().all():\n",
    "        data_to_plot.append(errors.dropna())\n",
    "        labels.append(method)\n",
    "\n",
    "bp = ax1.boxplot(data_to_plot, labels=labels, patch_artist=True)\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold']\n",
    "for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
    "    patch.set_facecolor(color)\n",
    "ax1.set_ylabel('Absolute Error (D)')\n",
    "ax1.set_title('Test Set Error Distributions')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Bootstrap distribution (final model)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.hist(bootstrap_diffs, bins=30, alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=0, color='red', linestyle='--', label='No difference')\n",
    "ax2.axvline(x=diff_final, color='green', linestyle='-', linewidth=2, \n",
    "            label=f'Observed diff: {diff_final:.3f}')\n",
    "ax2.set_xlabel('MAE Difference (Baseline - ML+Ensemble)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Bootstrap Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Performance comparison bar chart\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "x_pos = np.arange(len(results_df))\n",
    "ax3.bar(x_pos, results_df['MAE (D)'], color=colors[:len(results_df)])\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(results_df['Method'], rotation=45, ha='right')\n",
    "ax3.set_ylabel('MAE (D)')\n",
    "ax3.set_title('Mean Absolute Error Comparison')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Percentage within target\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "width = 0.25\n",
    "x_pos = np.arange(len(results_df))\n",
    "ax4.bar(x_pos - width, results_df['±0.25D (%)'], width, label='±0.25D', color='darkgreen')\n",
    "ax4.bar(x_pos, results_df['±0.50D (%)'], width, label='±0.50D', color='orange')\n",
    "ax4.bar(x_pos + width, results_df['±1.00D (%)'], width, label='±1.00D', color='blue')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(results_df['Method'], rotation=45, ha='right')\n",
    "ax4.set_ylabel('Percentage (%)')\n",
    "ax4.set_title('Percentage Within Target Range')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 5: Scatter plot of best method\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "valid_final = df_test_eval['Expected_SE_Final'].notna()\n",
    "if valid_final.sum() > 0:\n",
    "    ax5.scatter(df_test_eval.loc[valid_final, 'Expected_SE_Final'], \n",
    "               df_test_eval.loc[valid_final, 'PostOP Spherical Equivalent'], \n",
    "               alpha=0.6, color='gold')\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = df_test_eval.loc[valid_final, 'Expected_SE_Final'].min()\n",
    "    max_val = df_test_eval.loc[valid_final, 'Expected_SE_Final'].max()\n",
    "    ax5.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction')\n",
    "    ax5.set_xlabel('Predicted SE (D)')\n",
    "    ax5.set_ylabel('Actual SE (D)')\n",
    "    ax5.set_title('ML + Ensemble: Predicted vs Actual')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Improvement summary\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "baseline_mae = results_df.loc[results_df['Method'] == 'Baseline SRK/T', 'MAE (D)'].values[0]\n",
    "improvements = []\n",
    "for _, row in results_df.iterrows():\n",
    "    improvement = (baseline_mae - row['MAE (D)']) / baseline_mae * 100\n",
    "    improvements.append(improvement)\n",
    "\n",
    "bars = ax6.bar(range(len(results_df)), improvements, color=colors[:len(results_df)])\n",
    "ax6.set_ylabel('Improvement over Baseline (%)')\n",
    "ax6.set_title('Relative Performance Improvement')\n",
    "ax6.set_xticks(range(len(results_df)))\n",
    "ax6.set_xticklabels(results_df['Method'], rotation=45, ha='right')\n",
    "ax6.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, imp in zip(bars, improvements):\n",
    "    height = bar.get_height()\n",
    "    ax6.annotate(f'{imp:.1f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3 if height > 0 else -15),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom' if height > 0 else 'top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"\\nKey findings:\")\n",
    "print(f\"1. Test set size: {len(df_test)} eyes (30% of total)\")\n",
    "print(f\"2. Best performing method: {results_df.loc[results_df['MAE (D)'].idxmin(), 'Method']}\")\n",
    "print(f\"3. Best MAE: {results_df['MAE (D)'].min():.3f} D\")\n",
    "print(f\"4. Improvement over baseline: {improvements[results_df['MAE (D)'].idxmin()]:.1f}%\")\n",
    "print(f\"5. Random seed used: {RANDOM_SEED}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542dcb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 8: Document the Optimized SRK/T Formula for FacoDMEK Eyes\n",
    "print(\"=\" * 80)\n",
    "print(\"OPTIMIZED SRK/T FORMULA FOR FacoDMEK EYES\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBased on machine learning optimization of {len(df_complete)} FacoDMEK cases\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Section 1: NC-ONLY OPTIMIZATION\n",
    "print(\"\\n1. NC-ONLY OPTIMIZATION:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Original corneal refractive index (nc): 1.3330\")\n",
    "print(f\"Optimized corneal refractive index (nc): {model_info['optimal_nc']:.5f}\")\n",
    "print(f\"Change: {(model_info['optimal_nc'] - 1.333):.5f} ({((model_info['optimal_nc'] - 1.333)/1.333 * 100):.2f}%)\")\n",
    "\n",
    "# Section 2: FULL PARAMETER OPTIMIZATION\n",
    "if 'optimal_params_all' in model_info:\n",
    "    print(\"\\n2. FULL PARAMETER OPTIMIZATION:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"All optimized SRK/T parameters:\")\n",
    "    print()\n",
    "    \n",
    "    standard_params = [1.333, -5.41, 0.58412, 0.098, 0.62467, 68.747, 3.336, 0.65696, 0.02029]\n",
    "    param_names = ['nc', 'cw_const1', 'cw_const2', 'cw_const3', 'acd_const1', \n",
    "                   'acd_const2', 'offset_const', 'rethick_const1', 'rethick_const2']\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_data = []\n",
    "    for i, name in enumerate(param_names):\n",
    "        original = standard_params[i]\n",
    "        optimized = model_info['optimal_params_all'][i]\n",
    "        change_pct = (optimized - original) / abs(original) * 100\n",
    "        comparison_data.append({\n",
    "            'Parameter': name,\n",
    "            'Standard': original,\n",
    "            'Optimized': optimized,\n",
    "            'Change (%)': change_pct\n",
    "        })\n",
    "    \n",
    "    param_df = pd.DataFrame(comparison_data)\n",
    "    print(param_df.to_string(index=False, float_format=lambda x: f'{x:.5f}' if abs(x) < 100 else f'{x:.2f}'))\n",
    "\n",
    "# Section 3: PERFORMANCE COMPARISON\n",
    "print(\"\\n3. PERFORMANCE COMPARISON (Test Set):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if 'df_test_eval' in globals():\n",
    "    baseline_mae = df_test_eval['Error_Baseline'].abs().dropna().mean()\n",
    "    nc_mae = df_test_eval['Error_ML_nc'].abs().dropna().mean()\n",
    "    \n",
    "    print(f\"Standard SRK/T (nc=1.3330):\")\n",
    "    print(f\"  MAE: {baseline_mae:.3f} D\")\n",
    "    \n",
    "    print(f\"\\nOptimized nc only (nc={model_info['optimal_nc']:.5f}):\")\n",
    "    print(f\"  MAE: {nc_mae:.3f} D\")\n",
    "    print(f\"  Improvement: {(baseline_mae - nc_mae)/baseline_mae * 100:.1f}%\")\n",
    "    \n",
    "    if 'Error_ML_Full' in df_test_eval.columns:\n",
    "        full_mae = df_test_eval['Error_ML_Full'].abs().dropna().mean()\n",
    "        print(f\"\\nFully optimized SRK/T (all parameters):\")\n",
    "        print(f\"  MAE: {full_mae:.3f} D\")\n",
    "        print(f\"  Improvement: {(baseline_mae - full_mae)/baseline_mae * 100:.1f}%\")\n",
    "    \n",
    "    if 'Error_Final' in df_test_eval.columns:\n",
    "        ensemble_mae = df_test_eval['Error_Final'].abs().dropna().mean()\n",
    "        print(f\"\\nML + Ensemble:\")\n",
    "        print(f\"  MAE: {ensemble_mae:.3f} D\")\n",
    "        print(f\"  Improvement: {(baseline_mae - ensemble_mae)/baseline_mae * 100:.1f}%\")\n",
    "\n",
    "# Section 4: FORMULA IMPLEMENTATION\n",
    "print(\"\\n4. FORMULA IMPLEMENTATION:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# For nc-only optimization\n",
    "print(\"\\nA. Simple Implementation (nc-only optimization):\")\n",
    "print(\"   Just change nc from 1.333 to {:.5f} in standard SRK/T\".format(model_info['optimal_nc']))\n",
    "\n",
    "# For full optimization\n",
    "if 'optimal_params_all' in model_info:\n",
    "    print(\"\\nB. Full Implementation (all parameters optimized):\")\n",
    "    print(\"\"\"\n",
    "def calculate_SRKT_FacoDMEK_Full(AL, K, A_const):\n",
    "    '''\n",
    "    Fully optimized SRK/T formula for FacoDMEK eyes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    AL : float - Axial Length in mm\n",
    "    K : float - Average keratometry in diopters\n",
    "    A_const : float - A-constant for the IOL\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float - Predicted IOL power for emmetropia\n",
    "    '''\n",
    "    # Optimized constants\n",
    "    nc = {:.5f}         # corneal refractive index\n",
    "    cw_const1 = {:.5f}  # corneal width constant 1\n",
    "    cw_const2 = {:.5f}  # corneal width constant 2\n",
    "    cw_const3 = {:.5f}  # corneal width constant 3\n",
    "    acd_const1 = {:.5f} # ACD constant 1\n",
    "    acd_const2 = {:.5f} # ACD constant 2\n",
    "    offset_const = {:.5f} # offset constant\n",
    "    rethick_const1 = {:.5f} # retinal thickness constant 1\n",
    "    rethick_const2 = {:.5f} # retinal thickness constant 2\n",
    "    \n",
    "    # Standard constants (unchanged)\n",
    "    na = 1.336  # aqueous/vitreous refractive index\n",
    "    \n",
    "    # Corneal radius\n",
    "    r = 337.5 / K\n",
    "    \n",
    "    # Axial length correction\n",
    "    if AL > 24.2:\n",
    "        LCOR = -3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "    else:\n",
    "        LCOR = AL\n",
    "    \n",
    "    # Corneal width\n",
    "    Cw = cw_const1 + cw_const2 * LCOR + cw_const3 * K\n",
    "    \n",
    "    # Corneal height\n",
    "    H = r - sqrt(r**2 - (Cw**2 / 4))\n",
    "    \n",
    "    # ACD calculation\n",
    "    ACDconst = acd_const1 * A_const - acd_const2\n",
    "    offset = ACDconst - offset_const\n",
    "    ACDest = H + offset\n",
    "    \n",
    "    # Retinal thickness\n",
    "    RETHICK = rethick_const1 - rethick_const2 * AL\n",
    "    LOPT = AL + RETHICK\n",
    "    \n",
    "    # IOL power calculation\n",
    "    ncm1 = nc - 1\n",
    "    IOL = (1000 * na * (na * r - ncm1 * LOPT)) / \n",
    "          ((LOPT - ACDest) * (na * r - ncm1 * ACDest))\n",
    "    \n",
    "    return IOL\n",
    "\"\"\".format(*model_info['optimal_params_all']))\n",
    "\n",
    "# Section 5: CLINICAL RECOMMENDATIONS\n",
    "print(\"\\n5. CLINICAL RECOMMENDATIONS:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "1. For quick implementation: Use nc-only optimization\n",
    "   - Simply change nc from 1.333 to {:.5f}\n",
    "   - Provides {:.1f}% improvement\n",
    "\n",
    "2. For maximum accuracy: Use fully optimized parameters\n",
    "   - Implement all parameter changes\n",
    "   - Provides {:.1f}% improvement\n",
    "\n",
    "3. For research settings: Consider ensemble approach\n",
    "   - Combines optimized formula with ML corrections\n",
    "   - Provides {:.1f}% improvement\n",
    "\n",
    "4. Important notes:\n",
    "   - Use KERATOMETRY values (not biometry K)\n",
    "   - Optimization specific to FacoDMEK eyes\n",
    "   - Based on {} training cases\n",
    "   - Validated on {} test cases\n",
    "\"\"\".format(\n",
    "    model_info['optimal_nc'],\n",
    "    (baseline_mae - nc_mae)/baseline_mae * 100 if 'nc_mae' in locals() else 0,\n",
    "    (baseline_mae - full_mae)/baseline_mae * 100 if 'full_mae' in locals() else 0,\n",
    "    (baseline_mae - ensemble_mae)/baseline_mae * 100 if 'ensemble_mae' in locals() else 0,\n",
    "    len(df_train_val),\n",
    "    len(df_test)\n",
    "))\n",
    "\n",
    "# Section 6: EXAMPLE CALCULATIONS\n",
    "print(\"\\n6. EXAMPLE CALCULATIONS:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Example case\n",
    "AL_ex = 23.5\n",
    "K_ex = 44.0\n",
    "A_const_ex = 118.7\n",
    "\n",
    "print(f\"Example case: AL={AL_ex}mm, K={K_ex}D, A-constant={A_const_ex}\")\n",
    "print()\n",
    "\n",
    "# Calculate with different methods\n",
    "iol_standard = calculate_SRKT(AL_ex, K_ex, A_const_ex, nc=1.333)\n",
    "iol_nc_opt = calculate_SRKT(AL_ex, K_ex, A_const_ex, nc=model_info['optimal_nc'])\n",
    "\n",
    "print(f\"Standard SRK/T:        {iol_standard:.2f} D\")\n",
    "print(f\"Optimized nc only:     {iol_nc_opt:.2f} D (diff: {iol_nc_opt - iol_standard:+.2f} D)\")\n",
    "\n",
    "if 'optimal_params_all' in model_info:\n",
    "    iol_full_opt = calculate_SRKT_ml(AL_ex, K_ex, A_const_ex, model_info['optimal_params_all'])\n",
    "    print(f\"Fully optimized:       {iol_full_opt:.2f} D (diff: {iol_full_opt - iol_standard:+.2f} D)\")\n",
    "\n",
    "# Section 7: SAVE FORMULA DETAILS\n",
    "print(\"\\n7. EXPORT FORMULA:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create export dictionary\n",
    "export_data = {\n",
    "    'formula_name': 'SRK/T-FacoDMEK-Optimized',\n",
    "    'optimization_date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
    "    'training_cases': len(df_train_val),\n",
    "    'test_cases': len(df_test),\n",
    "    'optimal_nc': float(model_info['optimal_nc']),\n",
    "    'baseline_mae': float(baseline_mae) if 'baseline_mae' in locals() else None,\n",
    "    'optimized_nc_mae': float(nc_mae) if 'nc_mae' in locals() else None,\n",
    "}\n",
    "\n",
    "if 'optimal_params_all' in model_info:\n",
    "    export_data['optimal_params_all'] = [float(p) for p in model_info['optimal_params_all']]\n",
    "    export_data['param_names'] = param_names\n",
    "    export_data['full_optimized_mae'] = float(full_mae) if 'full_mae' in locals() else None\n",
    "\n",
    "# Save as JSON\n",
    "import json\n",
    "with open('SRKT_FacoDMEK_optimized_formula.json', 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "# Save human-readable version\n",
    "with open('SRKT_FacoDMEK_optimized_formula.txt', 'w') as f:\n",
    "    f.write(\"OPTIMIZED SRK/T FORMULA FOR FacoDMEK EYES\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    f.write(f\"Date: {export_data['optimization_date']}\\n\")\n",
    "    f.write(f\"Training cases: {export_data['training_cases']}\\n\")\n",
    "    f.write(f\"Test cases: {export_data['test_cases']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"NC-ONLY OPTIMIZATION:\\n\")\n",
    "    f.write(f\"  nc = {export_data['optimal_nc']:.5f} (standard: 1.33300)\\n\\n\")\n",
    "    \n",
    "    if 'optimal_params_all' in model_info:\n",
    "        f.write(\"FULL PARAMETER OPTIMIZATION:\\n\")\n",
    "        for i, name in enumerate(param_names):\n",
    "            f.write(f\"  {name}: {model_info['optimal_params_all'][i]:.5f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nPERFORMANCE:\\n\")\n",
    "    f.write(f\"  Baseline MAE: {baseline_mae:.3f} D\\n\")\n",
    "    f.write(f\"  NC-optimized MAE: {nc_mae:.3f} D\\n\")\n",
    "    if 'full_mae' in locals():\n",
    "        f.write(f\"  Fully optimized MAE: {full_mae:.3f} D\\n\")\n",
    "\n",
    "print(\"\\nFormula saved to:\")\n",
    "print(\"  - SRKT_FacoDMEK_optimized_formula.json (for implementation)\")\n",
    "print(\"  - SRKT_FacoDMEK_optimized_formula.txt (human-readable)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DOCUMENTATION COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
