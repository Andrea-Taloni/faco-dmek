{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb64766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d7601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and Explore Data\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('FacoDMEK.xlsx', sheet_name='Cleaned Data')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Preprocessing with Better NaN Handling\n",
    "# Calculate average keratometry - BIOMETRY VERSION\n",
    "df['K_avg_Bio'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "# Calculate average keratometry - TOPOGRAPHY VERSION\n",
    "df['K_avg_Topo'] = (df['Keratometric Ks'] + df['Keratometric Kf']) / 2\n",
    "\n",
    "# Calculate the \"true\" IOL power that would have achieved emmetropia\n",
    "df['True_IOL'] = df['IOL Power'] - df['PostOP Spherical Equivalent']\n",
    "\n",
    "# Feature engineering\n",
    "df['Post_Ant_Ratio'] = df['Posterior Km'] / df['Anterior Km']\n",
    "df['K_Astigmatism_Bio'] = df['Bio-Ks'] - df['Bio-Kf']\n",
    "df['K_Astigmatism_Topo'] = df['Keratometric Ks'] - df['Keratometric Kf']\n",
    "df['CCT_Normalized'] = df['CCT'] / 550  # Using OCT CCT only\n",
    "df['K_Diff_Bio_Topo'] = df['K_avg_Bio'] - df['K_avg_Topo']\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Summary of key variables:\")\n",
    "print(df[['Bio-AL', 'K_avg_Bio', 'IOL Power', 'PostOP Spherical Equivalent', 'True_IOL', 'CCT']].describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in key columns:\")\n",
    "missing_counts = df[['Bio-AL', 'K_avg_Bio', 'K_avg_Topo', 'IOL Power', \n",
    "                     'PostOP Spherical Equivalent', 'True_IOL', 'CCT', 'A-Constant']].isnull().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "# Count how many complete cases we have\n",
    "complete_cases = df[['Bio-AL', 'K_avg_Bio', 'IOL Power', 'PostOP Spherical Equivalent', 'A-Constant']].notna().all(axis=1).sum()\n",
    "print(f\"\\nComplete cases for analysis: {complete_cases} out of {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Implement SRK/T Formula with NaN Handling\n",
    "def calculate_SRKT(AL, K, A_const, nc=1.333):\n",
    "    \"\"\"\n",
    "    Calculate IOL power using SRK/T formula\n",
    "    Returns NaN if inputs are invalid\n",
    "    \"\"\"\n",
    "    # Check for valid inputs\n",
    "    if pd.isna(AL) or pd.isna(K) or pd.isna(A_const) or K <= 0 or AL <= 0:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        # Constants\n",
    "        na = 1.336\n",
    "        V = 12\n",
    "        \n",
    "        # Corneal radius\n",
    "        r = 337.5 / K\n",
    "        \n",
    "        # Axial length correction\n",
    "        if AL <= 24.2:\n",
    "            LCOR = AL\n",
    "        else:\n",
    "            LCOR = 3.446 + 1.716 * AL - 0.0237 * AL**2\n",
    "        \n",
    "        # Corneal width\n",
    "        Cw = -5.41 + 0.58412 * LCOR + 0.098 * K\n",
    "        \n",
    "        # Corneal height\n",
    "        H = r - np.sqrt(r**2 - (Cw**2 / 4))\n",
    "        \n",
    "        # ACD constant from A-constant\n",
    "        ACDconst = 0.62467 * A_const - 68.747\n",
    "        \n",
    "        # Offset\n",
    "        offset = ACDconst - 3.336\n",
    "        \n",
    "        # Estimated postoperative ACD\n",
    "        ACDest = H + offset\n",
    "        \n",
    "        # Retinal thickness correction\n",
    "        RETHICK = 0.65696 - 0.02029 * AL\n",
    "        LOPT = AL + RETHICK\n",
    "        \n",
    "        # Calculate IOL power for emmetropia\n",
    "        ncm1 = nc - 1\n",
    "        IOL = (1000 * na * (na * r - ncm1 * LOPT)) / ((LOPT - ACDest) * (na * r - ncm1 * ACDest))\n",
    "        \n",
    "        return IOL\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Calculate SRK/T predictions for both versions\n",
    "# BIOMETRY VERSION\n",
    "df['SRKT_Prediction_Bio'] = df.apply(\n",
    "    lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Bio'], row['A-Constant']), \n",
    "    axis=1\n",
    ")\n",
    "df['SRKT_Error_Bio'] = df['SRKT_Prediction_Bio'] - df['True_IOL']\n",
    "\n",
    "# TOPOGRAPHY VERSION\n",
    "df['SRKT_Prediction_Topo'] = df.apply(\n",
    "    lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Topo'], row['A-Constant']), \n",
    "    axis=1\n",
    ")\n",
    "df['SRKT_Error_Topo'] = df['SRKT_Prediction_Topo'] - df['True_IOL']\n",
    "\n",
    "# Remove rows with NaN errors for analysis\n",
    "valid_bio = df['SRKT_Error_Bio'].notna()\n",
    "valid_topo = df['SRKT_Error_Topo'].notna()\n",
    "\n",
    "print(\"BIOMETRY VERSION:\")\n",
    "print(f\"Valid predictions: {valid_bio.sum()} out of {len(df)}\")\n",
    "if valid_bio.sum() > 0:\n",
    "    print(f\"Mean Error: {df.loc[valid_bio, 'SRKT_Error_Bio'].mean():.3f} D\")\n",
    "    print(f\"Mean Absolute Error: {df.loc[valid_bio, 'SRKT_Error_Bio'].abs().mean():.3f} D\")\n",
    "    print(f\"Standard Deviation: {df.loc[valid_bio, 'SRKT_Error_Bio'].std():.3f} D\")\n",
    "\n",
    "print(\"\\nTOPOGRAPHY VERSION:\")\n",
    "print(f\"Valid predictions: {valid_topo.sum()} out of {len(df)}\")\n",
    "if valid_topo.sum() > 0:\n",
    "    print(f\"Mean Error: {df.loc[valid_topo, 'SRKT_Error_Topo'].mean():.3f} D\")\n",
    "    print(f\"Mean Absolute Error: {df.loc[valid_topo, 'SRKT_Error_Topo'].abs().mean():.3f} D\")\n",
    "    print(f\"Standard Deviation: {df.loc[valid_topo, 'SRKT_Error_Topo'].std():.3f} D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c261c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualize SRK/T Performance (with NaN handling)\n",
    "# Only plot for rows with valid data\n",
    "df_valid_bio = df[df['SRKT_Error_Bio'].notna()].copy()\n",
    "df_valid_topo = df[df['SRKT_Error_Topo'].notna()].copy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Biometry Error Distribution\n",
    "if len(df_valid_bio) > 0:\n",
    "    axes[0, 0].hist(df_valid_bio['SRKT_Error_Bio'], bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[0, 0].set_xlabel('SRK/T Prediction Error (D)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title(f'Biometry Error Distribution (n={len(df_valid_bio)})')\n",
    "\n",
    "# Plot 2: Topography Error Distribution\n",
    "if len(df_valid_topo) > 0:\n",
    "    axes[0, 1].hist(df_valid_topo['SRKT_Error_Topo'], bins=20, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[0, 1].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[0, 1].set_xlabel('SRK/T Prediction Error (D)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title(f'Topography Error Distribution (n={len(df_valid_topo)})')\n",
    "\n",
    "# Plot 3: Error vs Posterior Corneal Power (Biometry)\n",
    "if len(df_valid_bio) > 0:\n",
    "    axes[1, 0].scatter(df_valid_bio['Posterior Km'], df_valid_bio['SRKT_Error_Bio'], alpha=0.6)\n",
    "    axes[1, 0].set_xlabel('Posterior Corneal Power (D)')\n",
    "    axes[1, 0].set_ylabel('SRK/T Error (D)')\n",
    "    axes[1, 0].set_title('Biometry: Error vs Posterior K')\n",
    "\n",
    "# Plot 4: Error vs CCT\n",
    "if len(df_valid_bio) > 0:\n",
    "    valid_cct = df_valid_bio[df_valid_bio['CCT'].notna()]\n",
    "    axes[1, 1].scatter(valid_cct['CCT'], valid_cct['SRKT_Error_Bio'], alpha=0.6)\n",
    "    axes[1, 1].set_xlabel('Central Corneal Thickness (μm)')\n",
    "    axes[1, 1].set_ylabel('SRK/T Error (D)')\n",
    "    axes[1, 1].set_title('Error vs CCT')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate percentage within target ranges\n",
    "if len(df_valid_bio) > 0:\n",
    "    within_025 = (df_valid_bio['SRKT_Error_Bio'].abs() <= 0.25).sum() / len(df_valid_bio) * 100\n",
    "    within_050 = (df_valid_bio['SRKT_Error_Bio'].abs() <= 0.50).sum() / len(df_valid_bio) * 100\n",
    "    within_100 = (df_valid_bio['SRKT_Error_Bio'].abs() <= 1.00).sum() / len(df_valid_bio) * 100\n",
    "    \n",
    "    print(f\"\\nBiometry - Percentage of eyes within target:\")\n",
    "    print(f\"±0.25 D: {within_025:.1f}%\")\n",
    "    print(f\"±0.50 D: {within_050:.1f}%\")\n",
    "    print(f\"±1.00 D: {within_100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f35002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Optimization Approach 1 - Optimize Corneal Refractive Index\n",
    "# Only use complete cases\n",
    "df_complete = df[df['SRKT_Error_Bio'].notna()].copy()\n",
    "\n",
    "def objective_nc(nc_value):\n",
    "    \"\"\"Objective function to minimize MAE by optimizing nc\"\"\"\n",
    "    predictions = df_complete.apply(\n",
    "        lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Bio'], row['A-Constant'], nc=nc_value[0]), \n",
    "        axis=1\n",
    "    )\n",
    "    errors = predictions - df_complete['True_IOL']\n",
    "    # Remove any NaN values that might occur\n",
    "    valid_errors = errors[errors.notna()]\n",
    "    if len(valid_errors) == 0:\n",
    "        return 999  # Return large value if no valid predictions\n",
    "    return np.mean(np.abs(valid_errors))\n",
    "\n",
    "# Optimize nc\n",
    "if len(df_complete) > 0:\n",
    "    result_nc = minimize(objective_nc, x0=[1.333], bounds=[(1.330, 1.340)], method='L-BFGS-B')\n",
    "    optimal_nc = result_nc.x[0]\n",
    "    \n",
    "    # Recalculate with optimal nc\n",
    "    df_complete['SRKT_Optimized_nc'] = df_complete.apply(\n",
    "        lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Bio'], row['A-Constant'], nc=optimal_nc), \n",
    "        axis=1\n",
    "    )\n",
    "    df_complete['SRKT_Error_Optimized_nc'] = df_complete['SRKT_Optimized_nc'] - df_complete['True_IOL']\n",
    "    \n",
    "    print(f\"Optimal corneal refractive index: {optimal_nc:.4f}\")\n",
    "    print(f\"Original MAE: {df_complete['SRKT_Error_Bio'].abs().mean():.3f} D\")\n",
    "    print(f\"Optimized MAE: {df_complete['SRKT_Error_Optimized_nc'].abs().mean():.3f} D\")\n",
    "else:\n",
    "    print(\"Not enough complete cases for optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecaa26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.5: Missing Data Analysis and Imputation (CORRECTED)\n",
    "# Analyze missing data patterns\n",
    "print(\"MISSING DATA ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check missing values in ALL relevant columns\n",
    "all_columns = ['Bio-AL', 'Bio-Ks', 'Bio-Kf', 'K_avg_Bio', 'Posterior Km', 'CCT', \n",
    "               'A-Constant', 'Post_Ant_Ratio', 'K_Astigmatism_Bio',\n",
    "               'Keratometric Ks', 'Keratometric Kf', 'K_avg_Topo',\n",
    "               'Anterior Km', 'Anterior Ks', 'Anterior Kf']\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': all_columns,\n",
    "    'Missing': [df[col].isna().sum() for col in all_columns if col in df.columns],\n",
    "    'Percentage': [(df[col].isna().sum()/len(df)*100) for col in all_columns if col in df.columns]\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "print(missing_summary)\n",
    "\n",
    "# Create a copy for imputation\n",
    "df_imputed = df.copy()\n",
    "\n",
    "# STRATEGY 1: Impute Bio-Ks and Bio-Kf from Keratometric values\n",
    "print(\"\\nSTRATEGY 1: Imputing Bio-Ks and Bio-Kf from Topography\")\n",
    "# Check if we have topography values when biometry is missing\n",
    "bio_ks_missing = df_imputed['Bio-Ks'].isna()\n",
    "bio_kf_missing = df_imputed['Bio-Kf'].isna()\n",
    "topo_ks_available = df_imputed['Keratometric Ks'].notna()\n",
    "topo_kf_available = df_imputed['Keratometric Kf'].notna()\n",
    "\n",
    "# Calculate average differences for cases with both measurements\n",
    "complete_k_cases = df_imputed[(df_imputed['Bio-Ks'].notna()) & \n",
    "                               (df_imputed['Keratometric Ks'].notna())]\n",
    "if len(complete_k_cases) > 0:\n",
    "    ks_diff = (complete_k_cases['Bio-Ks'] - complete_k_cases['Keratometric Ks']).mean()\n",
    "    kf_diff = (complete_k_cases['Bio-Kf'] - complete_k_cases['Keratometric Kf']).mean()\n",
    "    print(f\"Average difference Bio-Ks - Keratometric Ks: {ks_diff:.3f} D\")\n",
    "    print(f\"Average difference Bio-Kf - Keratometric Kf: {kf_diff:.3f} D\")\n",
    "    \n",
    "    # Impute Bio-Ks\n",
    "    can_impute_ks = bio_ks_missing & topo_ks_available\n",
    "    if can_impute_ks.sum() > 0:\n",
    "        df_imputed.loc[can_impute_ks, 'Bio-Ks'] = df_imputed.loc[can_impute_ks, 'Keratometric Ks'] + ks_diff\n",
    "        print(f\"Imputed {can_impute_ks.sum()} Bio-Ks values\")\n",
    "    \n",
    "    # Impute Bio-Kf\n",
    "    can_impute_kf = bio_kf_missing & topo_kf_available\n",
    "    if can_impute_kf.sum() > 0:\n",
    "        df_imputed.loc[can_impute_kf, 'Bio-Kf'] = df_imputed.loc[can_impute_kf, 'Keratometric Kf'] + kf_diff\n",
    "        print(f\"Imputed {can_impute_kf.sum()} Bio-Kf values\")\n",
    "\n",
    "# Recalculate K_avg_Bio\n",
    "df_imputed['K_avg_Bio'] = (df_imputed['Bio-Ks'] + df_imputed['Bio-Kf']) / 2\n",
    "\n",
    "# STRATEGY 2: Impute remaining Bio-K values using anterior corneal power\n",
    "print(\"\\nSTRATEGY 2: Imputing remaining Bio-K from Anterior Corneal Power\")\n",
    "bio_k_still_missing = df_imputed['K_avg_Bio'].isna()\n",
    "anterior_available = df_imputed['Anterior Km'].notna()\n",
    "\n",
    "if bio_k_still_missing.sum() > 0 and (bio_k_still_missing & anterior_available).sum() > 0:\n",
    "    # Calculate relationship between anterior K and bio K\n",
    "    complete_anterior = df_imputed[(df_imputed['K_avg_Bio'].notna()) & \n",
    "                                   (df_imputed['Anterior Km'].notna())]\n",
    "    if len(complete_anterior) > 5:\n",
    "        k_anterior_diff = (complete_anterior['K_avg_Bio'] - complete_anterior['Anterior Km']).mean()\n",
    "        can_use_anterior = bio_k_still_missing & anterior_available\n",
    "        df_imputed.loc[can_use_anterior, 'K_avg_Bio'] = df_imputed.loc[can_use_anterior, 'Anterior Km'] + k_anterior_diff\n",
    "        print(f\"Imputed {can_use_anterior.sum()} K_avg_Bio values from Anterior K\")\n",
    "\n",
    "# STRATEGY 3: Regression imputation for Posterior Km\n",
    "print(\"\\nSTRATEGY 3: Regression for Posterior Corneal Power\")\n",
    "posterior_complete = df_imputed[['Anterior Km', 'CCT', 'Posterior Km']].dropna()\n",
    "if len(posterior_complete) > 10 and df_imputed['Posterior Km'].isna().sum() > 0:\n",
    "    X_post = posterior_complete[['Anterior Km', 'CCT']]\n",
    "    y_post = posterior_complete['Posterior Km']\n",
    "    reg_posterior = LinearRegression()\n",
    "    reg_posterior.fit(X_post, y_post)\n",
    "    \n",
    "    posterior_missing = df_imputed['Posterior Km'].isna()\n",
    "    anterior_cct_available = df_imputed['Anterior Km'].notna() & df_imputed['CCT'].notna()\n",
    "    can_impute_posterior = posterior_missing & anterior_cct_available\n",
    "    \n",
    "    if can_impute_posterior.sum() > 0:\n",
    "        X_pred = df_imputed.loc[can_impute_posterior, ['Anterior Km', 'CCT']]\n",
    "        df_imputed.loc[can_impute_posterior, 'Posterior Km'] = reg_posterior.predict(X_pred)\n",
    "        print(f\"Imputed {can_impute_posterior.sum()} Posterior Km values\")\n",
    "\n",
    "# STRATEGY 4: Simple imputation for remaining variables\n",
    "print(\"\\nSTRATEGY 4: Median/Mode imputation\")\n",
    "\n",
    "# CCT - median\n",
    "if df_imputed['CCT'].isna().sum() > 0:\n",
    "    cct_median = df_imputed['CCT'].median()\n",
    "    n_cct = df_imputed['CCT'].isna().sum()\n",
    "    df_imputed['CCT'].fillna(cct_median, inplace=True)\n",
    "    print(f\"Imputed {n_cct} CCT values with median: {cct_median:.0f} μm\")\n",
    "\n",
    "# A-Constant - mode\n",
    "if df_imputed['A-Constant'].isna().sum() > 0:\n",
    "    a_constant_mode = df_imputed['A-Constant'].mode()[0]\n",
    "    n_a = df_imputed['A-Constant'].isna().sum()\n",
    "    df_imputed['A-Constant'].fillna(a_constant_mode, inplace=True)\n",
    "    print(f\"Imputed {n_a} A-Constant values with mode: {a_constant_mode:.2f}\")\n",
    "\n",
    "# Bio-AL - NO imputation (too critical)\n",
    "if df_imputed['Bio-AL'].isna().sum() > 0:\n",
    "    print(f\"\\nWARNING: {df_imputed['Bio-AL'].isna().sum()} Bio-AL values are missing and will NOT be imputed\")\n",
    "\n",
    "# STRATEGY 5: Recalculate derived variables\n",
    "print(\"\\nSTRATEGY 5: Recalculating derived variables\")\n",
    "\n",
    "# K_Astigmatism_Bio\n",
    "df_imputed['K_Astigmatism_Bio'] = df_imputed['Bio-Ks'] - df_imputed['Bio-Kf']\n",
    "\n",
    "# Post_Ant_Ratio\n",
    "has_both = df_imputed['Posterior Km'].notna() & df_imputed['Anterior Km'].notna()\n",
    "df_imputed.loc[has_both, 'Post_Ant_Ratio'] = (\n",
    "    df_imputed.loc[has_both, 'Posterior Km'] / df_imputed.loc[has_both, 'Anterior Km']\n",
    ")\n",
    "\n",
    "# Recalculate SRK/T predictions with imputed data\n",
    "print(\"\\nRecalculating SRK/T with imputed data...\")\n",
    "df_imputed['SRKT_Prediction_Bio_Imputed'] = df_imputed.apply(\n",
    "    lambda row: calculate_SRKT(row['Bio-AL'], row['K_avg_Bio'], row['A-Constant']) \n",
    "    if pd.notna(row['Bio-AL']) and pd.notna(row['K_avg_Bio']) and pd.notna(row['A-Constant']) \n",
    "    else np.nan, axis=1\n",
    ")\n",
    "df_imputed['SRKT_Error_Bio_Imputed'] = df_imputed['SRKT_Prediction_Bio_Imputed'] - df_imputed['True_IOL']\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"IMPUTATION RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original complete cases: {len(df[df['SRKT_Error_Bio'].notna()])}\")\n",
    "print(f\"Complete cases after imputation: {len(df_imputed[df_imputed['SRKT_Error_Bio_Imputed'].notna()])}\")\n",
    "print(f\"Additional cases gained: {len(df_imputed[df_imputed['SRKT_Error_Bio_Imputed'].notna()]) - len(df[df['SRKT_Error_Bio'].notna()])}\")\n",
    "\n",
    "# Check which columns still have missing values for ML features\n",
    "ml_features = ['Bio-AL', 'K_avg_Bio', 'Posterior Km', 'CCT', 'Post_Ant_Ratio', 'K_Astigmatism_Bio', 'A-Constant']\n",
    "for feat in ml_features:\n",
    "    n_missing = df_imputed[feat].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"  - {feat}: still has {n_missing} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46fff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Optimization Approach 2 - Linear Correction Model (Using Imputed Data)\n",
    "# Use imputed data if available\n",
    "if 'df_imputed' in locals() and 'SRKT_Error_Bio_Imputed' in df_imputed.columns:\n",
    "    df_ml = df_imputed.copy()\n",
    "    # Use the imputed error column\n",
    "    df_ml['SRKT_Error_Bio'] = df_ml['SRKT_Error_Bio_Imputed']\n",
    "    df_ml['SRKT_Prediction_Bio'] = df_ml['SRKT_Prediction_Bio_Imputed']\n",
    "    print(\"Using imputed data for analysis\")\n",
    "else:\n",
    "    df_ml = df.copy()\n",
    "    print(\"Using original data for analysis\")\n",
    "\n",
    "# Prepare features for correction model (Age removed)\n",
    "feature_cols = ['Posterior Km', 'CCT', 'Post_Ant_Ratio', 'K_Astigmatism_Bio']\n",
    "\n",
    "# Ensure we have all necessary columns\n",
    "required_cols = feature_cols + ['SRKT_Error_Bio']\n",
    "df_ml = df_ml[df_ml[required_cols].notna().all(axis=1)].copy()\n",
    "\n",
    "print(f\"Complete cases for ML: {len(df_ml)} out of {len(df)}\")\n",
    "\n",
    "if len(df_ml) > 10:  # Need at least 10 cases for meaningful analysis\n",
    "    X = df_ml[feature_cols]\n",
    "    y = df_ml['SRKT_Error_Bio']\n",
    "    \n",
    "    # Split data for cross-validation\n",
    "    loo = LeaveOneOut()\n",
    "    predictions_linear = []\n",
    "    true_values = []\n",
    "    \n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train linear model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict correction\n",
    "        correction = model.predict(X_test)[0]\n",
    "        \n",
    "        # Apply correction to SRK/T prediction\n",
    "        srkt_pred = df_ml.iloc[test_index]['SRKT_Prediction_Bio'].values[0]\n",
    "        corrected_pred = srkt_pred - correction\n",
    "        \n",
    "        predictions_linear.append(corrected_pred)\n",
    "        true_values.append(df_ml.iloc[test_index]['True_IOL'].values[0])\n",
    "    \n",
    "    # Calculate performance\n",
    "    mae_original = df_ml['SRKT_Error_Bio'].abs().mean()\n",
    "    mae_linear = mean_absolute_error(true_values, predictions_linear)\n",
    "    \n",
    "    print(f\"Original SRK/T MAE: {mae_original:.3f} D\")\n",
    "    print(f\"Linear Correction Model MAE: {mae_linear:.3f} D\")\n",
    "    print(f\"Improvement: {mae_original - mae_linear:.3f} D\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    model_full = LinearRegression()\n",
    "    model_full.fit(X, y)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Coefficient': model_full.coef_,\n",
    "        'Abs_Coefficient': np.abs(model_full.coef_)\n",
    "    }).sort_values('Abs_Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance (Linear Model):\")\n",
    "    print(feature_importance)\n",
    "else:\n",
    "    print(\"Not enough complete cases for machine learning analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3954664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Machine Learning Models Comparison (Using Imputed Data)\n",
    "if len(df_ml) > 10:\n",
    "    # Prepare features (Age removed)\n",
    "    features_ml = ['Bio-AL', 'K_avg_Bio', 'Posterior Km', 'CCT', 'Post_Ant_Ratio', \n",
    "                   'K_Astigmatism_Bio', 'A-Constant']\n",
    "    \n",
    "    # Ensure complete cases\n",
    "    df_ml_full = df_ml[features_ml + ['True_IOL']].dropna()\n",
    "    X_ml = df_ml_full[features_ml]\n",
    "    y_ml = df_ml_full['True_IOL']\n",
    "    \n",
    "    print(f\"Cases for ML comparison: {len(X_ml)}\")\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Cross-validation results\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        \n",
    "        for train_idx, test_idx in loo.split(X_ml):\n",
    "            X_train, X_test = X_ml.iloc[train_idx], X_ml.iloc[test_idx]\n",
    "            y_train, y_test = y_ml.iloc[train_idx], y_ml.iloc[test_idx]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)[0]\n",
    "            \n",
    "            predictions.append(pred)\n",
    "            actuals.append(y_test.values[0])\n",
    "        \n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        results[name] = mae\n",
    "        print(f\"{name} MAE: {mae:.3f} D\")\n",
    "    \n",
    "    # Compare with original SRK/T\n",
    "    original_mae = df_ml_full.merge(df_ml[['SRKT_Error_Bio']], left_index=True, right_index=True)['SRKT_Error_Bio'].abs().mean()\n",
    "    print(f\"\\nOriginal SRK/T MAE: {original_mae:.3f} D\")\n",
    "    print(f\"Best ML Model: {min(results, key=results.get)} with MAE: {min(results.values()):.3f} D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Create Final Optimized Formula\n",
    "if len(df_ml) > 10:\n",
    "    # Train final model on all data\n",
    "    best_model = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "    best_model.fit(X_ml, y_ml)\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance_gb = pd.DataFrame({\n",
    "        'Feature': features_ml,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance_gb['Feature'], feature_importance_gb['Importance'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Feature Importance in Gradient Boosting Model')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Feature Importance:\")\n",
    "    print(feature_importance_gb)\n",
    "    \n",
    "    # Create simplified correction formula based on top 3 features\n",
    "    top_features = ['Posterior Km', 'CCT', 'Bio-AL']\n",
    "    \n",
    "    # Ensure we have complete data for these features\n",
    "    df_simple = df_ml[top_features + ['True_IOL', 'SRKT_Prediction_Bio']].dropna()\n",
    "    X_simple = df_simple[top_features]\n",
    "    y_correction = df_simple['True_IOL'] - df_simple['SRKT_Prediction_Bio']\n",
    "    \n",
    "    model_simple = LinearRegression()\n",
    "    model_simple.fit(X_simple, y_correction)\n",
    "    \n",
    "    print(f\"\\nSimplified Correction Formula:\")\n",
    "    print(f\"Correction = {model_simple.intercept_:.3f}\")\n",
    "    for feat, coef in zip(top_features, model_simple.coef_):\n",
    "        print(f\"           + {coef:.4f} × {feat}\")\n",
    "    \n",
    "    # Calculate final performance\n",
    "    df_simple['Predicted_Correction'] = model_simple.predict(X_simple)\n",
    "    df_simple['Final_Prediction'] = df_simple['SRKT_Prediction_Bio'] + df_simple['Predicted_Correction']\n",
    "    final_mae = mean_absolute_error(df_simple['True_IOL'], df_simple['Final_Prediction'])\n",
    "    \n",
    "    print(f\"\\nFinal simplified formula MAE: {final_mae:.3f} D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Final Validation and Results Summary\n",
    "if len(df_ml) > 10:\n",
    "    # Summary statistics\n",
    "    print(\"FINAL RESULTS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Original data points: {len(df)}\")\n",
    "    print(f\"Complete cases for analysis: {len(df_ml)}\")\n",
    "    print(f\"\\nOriginal SRK/T Performance:\")\n",
    "    print(f\"  MAE: {df_ml['SRKT_Error_Bio'].abs().mean():.3f} D\")\n",
    "    print(f\"  Mean Error: {df_ml['SRKT_Error_Bio'].mean():.3f} D\")\n",
    "    print(f\"  STD: {df_ml['SRKT_Error_Bio'].std():.3f} D\")\n",
    "    \n",
    "    if 'optimal_nc' in locals():\n",
    "        print(f\"\\nOptimized nc: {optimal_nc:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RECOMMENDED FORMULA FOR FACODMEK:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Modified_IOL = Standard_SRK/T + Correction\")\n",
    "    print(f\"\\nWhere Correction = {model_simple.intercept_:.3f} + \"\n",
    "          f\"{model_simple.coef_[0]:.4f}×Posterior_Km + \"\n",
    "          f\"{model_simple.coef_[1]:.4f}×CCT + \"\n",
    "          f\"{model_simple.coef_[2]:.4f}×AL\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = df_ml[['ID', 'Patient', 'Eye', 'Bio-AL', 'K_avg_Bio', 'IOL Power', \n",
    "                        'PostOP Spherical Equivalent', 'True_IOL', 'SRKT_Prediction_Bio', \n",
    "                        'SRKT_Error_Bio']].copy()\n",
    "    \n",
    "    results_df.to_excel('FacoDMEK_Optimization_Results.xlsx', index=False)\n",
    "    print(\"\\nResults saved to 'FacoDMEK_Optimization_Results.xlsx'\")\n",
    "else:\n",
    "    print(\"Insufficient data for complete analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
